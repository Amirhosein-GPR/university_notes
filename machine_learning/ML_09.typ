#import "../assets/typst/tools/tool.typ"
#import "../assets/typst/tools/tool.typ": *

= جلسه نهم
#tool.reminder()[
  همان طور که در جلسه قبلی گفته شد، پارامتر های مدل را از روی نمونه هایی که از جمعیت بر می داریم، می سازیم.
  #tool.custom_figure(
    image("../images/ML/09_01.png", width: 90%),
    caption: [نمونه های $S_1$ تا $S_N$ را از جمعیت انتخاب کرده و از روی آن ها پارامتر های $P_1$ تا $P_N$ را می سازیم.],
    inset: 1em,
  )
]
== Central Limit Theorem
#tool.definition()[
  قضیه حد مرکزی (Central Limit Theorem):
  اگر نمونه هایی که از جمعیت گرفته می شوند، IID باشند و به تعداد کافی زیاد باشند:
  $ N arrow infinity $
  آنگاه پارامتر های مدل، از یک توزیع نرمال پیروی می کنند:
  $ P_1, P_2, dots, P_N tilde N(mu_P, sigma_P) $
]

#tool.double_section()[
  #tool.tip()[
    در عمل، اگر:
    $ (N >= 33) $
    باشد، کافی است و بی نهایت بودن آن لزومی ندارد.
  ]
][
  // Is this true or false?
  #tool.tip()[
    در نمونه گیری فرقی نمی کند که از جمعیت نمونه گیری کنیم یا از یک ماشینی که رفتاری کاملاً IID دارد، نمونه گیری کنیم.
    #v(1em)
  ]
]

#tool.example()[
  فرض کنید دو مدل $M_1$ و $M_2$ را داریم.
  از جمعیتی دو بار نمونه گیری کرده و نام نمونه ها را $S_1$ و $S_2$ می گذاریم.
  برای تست مدل ها، $S_1$ را به هر دوی آن ها می دهیم.
  Accuracy مربوط به $M_1$ را $a_1$ و Accuracy مربوط به $M_2$ را $b_1$ می نامیم.
  همین فرآیند را برای $S_2$ تا $S_N$ تکرار می کنیم:
  $
    S_1 , S_2, dots, S_N cases(gap: #1em, M_1 arrow overbrace({a_1, a_2, a_3, dots, a_N}, display(N(mu_a, sigma_a))), M_2 arrow underbrace({b_1, b_2, b_3, dots, b_N}, display(N(mu_b, sigma_b))))
  $
  از آن جایی که تعداد زیادی نمونه ($N >= 33$) را به شکل IID انتخاب می کنیم و هیچ یک از دو مدل را تغییر نمی دهیم، بنابر قضیه حد مرکزی، توزیع های نرمالی به نام $N(mu_a, sigma_a)$ و $N(mu_b, sigma_b)$ خواهیم داشت.
]

#tool.tip()[
  فرض کنید مدل $M_1$ پارامتر های زیر را دارد:
  $ mu_a = 0.75, sigma_a = 0.01 $
  #tool.custom_figure(
    image("../images/ML/09_02.png", width: 80%),
    caption: [فاصله اطمینان ۹۵٪ توزیع نرمال مربوط به داده های این مثال. فاصله اطمینان ۹۵٪ یک توزیع نرمال، از $mu - 2 sigma$ تا $mu + 2 sigma$ را شامل می شود.],
    inset: 1em,
    refrence: <image_09_02>,
  )
  اگر متوسط دقت مدل $M_2$ برابر با ۰/۷۸ باشد، یعنی در ۹۵٪ موارد دقت بهتری از مدل $M_1$ دارد. به عبارت دیگر $M_2$ به صورت معنی داری دقت بهتری نسبت به $M_1$، دارد:
  $ mu_b = 0.78 >= mu_a + 2 sigma_a arrow M_2 "Is significantly better than" M_1 $
]

#tool.double_section()[
  #tool.tip()[
    وقتی می گوییم رویدادی به صورت معنی داری رخ داده است، یعنی حتماً دلیلی پشت آن بوده و به صورت شانسی رخ نداده است.
  ]
][
  #tool.definition()[
    برای بررسی و مقایسه مدل ها، می توان از فاصله اطمینان دقت یا فاصله اطمینان یک معیار کارکردی دیگر مدل (خطای مدل و #sym.dots) استفاده کرد.
  ]
]

#tool.example()[
  فرض کنیم مدلی با میانگین دقت ۰/۷۵۵ داریم (@image_09_02).
  این مدل ظاهراً بهتر از مدل $M_1$ (با میانگین دقت ۰/۷۵) است اما چون میانگین دقت آن به میزان کمی از میانگین دقت $M_1$ بالاتر است نمی توان به صورت قطعی نظر داد و شاید به دلیل داده ای که به آن داده شده چنین نتیجه ای را برگردانده است.
]

#tool.double_section()[
  #tool.question()[
    وقتی می گوییم دقت مدلی ۰/۷۵ است چه معنایی دارد؟
    #v(3.2em)
  ]
][
  #tool.true_answer()[
    یعنی اگر تک نمونه ای به سیستم بدهیم، به احتمال ۰/۷۵ آن را درست و به احتمال ۰/۲۵ آن را اشتباه تشخیص خواهد داد.
  ]
]

#tool.example()[
  یک توزیع باینری ساده به صورت زیر داریم:

  سکه ای داریم که دو روی A و B دارد:
  #align(center)[
    #box()[
      #circle("A")
    ]
    #h(1em)
    #box()[
      #circle("B")
    ]
  ]

  احتمال رخ دادن هر یک از دو روی آن به صورت زیر است:
  $ cases(p(A) = 0.75, p(B) = 1 - 0.75 = 0.25) $

  اگر این آزمایش باینری را $N$ بار تکرار کنیم، $mu_A$ و $sigma_A$ آن به صورت زیر خواهند بود:
  $ mu_A = p , sigma_A = sqrt(p(1 - p) / N) $

  این به این درد می خورد که صرفاً با یک Test Set، فاصله اطمینان را حساب کنیم.
  به این صورت که داده ها به دو بخش Train و Test تقسیم می شوند.
  بخش Test برای تست و مقایسه مدل ها استفاده می شود.
]

== Proof of Concept
#tool.tip()[
  در آمار بحثی به نام آزمون فرضیه (Proof of Concept) وجود دارد.
  این آزمون برای این استفاده می شود که بخواهیم ببینم با انجام یک آزمایش تغییری معنادار در جامعه ایجاد می شود یا نه.
  Proof of Concept انواع آزمون ها را دارد.
  مانند: فاصله اطمینان.
]
#tool.example()[
  می خواهیم بدانیم آیا شکلات خوردن دانشجویان بعد از شام تأثیر مثبتی در یادگیری شان دارد یا خیر.
  فرض می گیریم که این کار مثلاً تأثیر مثبتی دارد.
  سپس برای دانستن این که فرض ما درست یا نه، آزمونی را به مدت یک ماه می گیریم به گونه ای که در آن یک ماه، هر شب بعد از شام به آن ها شکلات می دهیم.
  پس از پایان یک ماه نتیجه را بررسی کرده و به درستی یا نادرستی فرضیه مان می رسیم.
]

=== Small Sample Problem
#tool.definition()[
  در بسیاری از مسائل یادگیری ماشینی با مشکلی به نام Small Sample Problem رو به رو می شویم.
  این مشکل به این اشاره دارد که در همه مسائل نمی توان راحت نمونه آموزشی را به دست آورد.
  مثلاً بعضی آزمایش های پزشکی روی انسان.
]

#tool.example()[
  فرض کنید برای یک مسأله، ۴۰ نمونه داریم.
  اگر بخواهیم به این روش عمل کنیم که در آن ۷۰٪ نمونه ها برای آموزش و ۳۰٪ برای تست استفاده شوند، به مشکل می خوریم.
  چرا که ۲۸ نمونه برای آموزش خواهیم داشت و با این تعداد نمونه نمی توان به توزیع نرمالی رسید.

  یکی از روش هایی که با آن می توان نشان داد مدل ما مدل خوبی است، استفاده از Proof of Concept است.

  در این مثال، نمونه ها را به دو گروه ۳۹ تایی و ۱ تایی تقسیم می کنیم تا بتوانیم از خواص توزیع نرمال استفاده کنیم.
  ابتدا مدلی را با ۳۹ نمونه آموزش می دهیم.
  این مدل را $M_1$ می نامیم.
  سپس با ۱ نمونه ای که برای تست کنار گذاشتیم، $M_1$ را تست می کنیم.
  $M_1$ در جواب، به ما $hat(y)_1$ را می دهد.
  سپس دوباره ۴۰ نمونه را به دو گروه ۳۹ تایی و ۱ تایی تقسیم می کنیم.
  به این صورت که این بار دومین نمونه از مجموعه ۴۰ تایی را به عنوان تک نمونه تست انتخاب می کنیم.
  این کار را تا ۴۰ امین نمونه انجام می دهیم:
  $
    40 cases("Train": 39 #h(0.5em) arrow.long #h(0.5em) M_1 arrow hat(y)_1, "Test": 1 (x^(<1>)) arrow.curve.t)
    \
    40 cases("Train": 39 #h(0.5em) arrow.long #h(0.5em) M_2 arrow hat(y)_2, "Test": 1 (x^(<2>)) arrow.curve.t)
    \
    dots.v
    \
    40 cases("Train": 39 #h(0.5em) arrow.long #h(0.5em) M_40 arrow hat(y)_40, "Test": 1 (x^(<40>)) arrow.curve.t)
  $
  #place(
    dx: -2em,
    dy: -10.5em,
    $lr(\}, size: #8.5em) "Test Results"$,
  )
  در نهایت به ۴۰ عدد Test Result خواهیم رسید.
  دقت شود که در هر یک از ۴۰ مرحله این روش، مدل عوض می شود اما الگوریتم ثابت است.

  به این ترتیب هم ۴۰ عدد Test Result داریم و هم مدل ما با بیش از ۳۳ نمونه آموزش داده شد که در نتیجه برای این مدل می توان بازه اطمینان را حساب کرد.
]

=== K-fold Cross Validation
#tool.example()[
  فرض کنید در این مثال، همان کاری که در مثال قبل انجام دادیم را انجام می دهیم اما با این تفاوت که این بار ۴۰ نمونه را به ۸ بلوک ۵ تایی تقسیم می کنیم:
  #tool.custom_figure(
    caption: "تقسیم ۴۰ نمونه به ۸ بلوک ۵ تایی",
    kind: table,
    inset: 1em,
  )[
    #table(
      columns: 8,
      inset: 1em,
      stroke: black,
      align: center + horizon,
      fill: (x, y) => if calc.even(x) {
        luma(230)
      },
      $F_1$, "5", $F_3$, "5", $F_5$, "5", $F_7$, "5",
      $F_2$, "5", $F_4$, "5", $F_6$, "5", $F_8$, "5",
    )
  ]
  بلوک $F_1$ را برای تست و ۷ بلوک باقی مانده را برای آموزش مدل استفاده می کنیم:
  $ 40 cases(#text(dir: ltr)[$"Train": F_2, F_3, F_4, F_5, F_6, F_7, F_8$], "Test": F_1) $
  تفاوت این دو دسته بندی در این است که مدل در دسته بندی قبلی ۴۰ بار و در این دسته بندی ۸ بار آموزش می بیند.
  البته در عمل معمولاً Dataset را به ۱۰ یا ۵ قسمت تقسیم می کنند.
  به این روش K-fold Cross Validation می گویند.
  این روش برای مواقعی که نمونه های کمی داریم کاربرد دارد.
]

#tool.tip()[
  برای محاسبه پارامتر ها و نتایج طبقه بند ها باید اندازه نمونه ها بزرگ باشد.
  اگر اینطور نبود با تکنیک های مهندسی Test Set ای می سازیم که با آن بتوان رفتار مدل را مطالعه کرد و Confidence Interval آن را به دست آورد.
]

== بررسی انواع طبقه بند ها
=== Linear Regression
#tool.example()[
  در جلسه ششم، @image_06_03 در صورت سؤالی آورده شد.
  در این مثال از آن شکل مجدداً استفاده می کنیم:
  #tool.custom_figure(
    image("../images/ML/06_03.png", width: 94%),
    caption: "شکل سؤال جلسه ششم که در آن ۶ نمونه داریم که در دو کلاس دسته بندی می شوند.",
    inset: 1em,
    refrence: <image_09_03>,
  )
  تعدادی نمونه داریم که در دو کلاس طبقه بندی می شوند.
  در این جا دو کلاس را به نام های ۰ و ۱ صدا می زنیم.

  فرض کنیم $y$ که بیانگر Label داده ها است، تابعی از $x$ ها است.
  $ y = f(x_0, x_1, x_2) $
  مثال ۱:
  $ y = w_0 x_0 + w_1 x_1 + w_2 x_2 $
  #tool.custom_figure(
    caption: [مقادیر تابع $y$ که از نمودار @image_09_03 به دست می آید.],
    kind: table,
    inset: 1em,
  )[
    #table(
      columns: 4,
      inset: 1em,
      stroke: black,
      align: center + horizon,
      $x_0$, $x_1$, $x_2$, $y$,
      "1", "-1", "-1", "0",
      "1", "-1", "0", "0",
      "1", "0", "-1", "0",
      "1", "0", "1", "1",
      "1", "1", "0", "1",
      "1", "1", "1", "1",
    )
  ]
  مثال ۲:
  $
    y = w_0 x_0 + w_1 x_1 + w_2 x_2 + w_3 x_1^2 + w_4 x_2^2 + w_5 x_1 x_2
  $

  در این حالت با تغییر متغیر آن را به یک تابع خطی تبدیل می کنیم:
  $
    \
    y &= w_0 underbrace(x_0, Z_0) + w_1 underbrace(x_1, Z_1) + w_2 underbrace(x_2, Z_2) + w_3 underbrace(x_1^2, Z_3) + w_4 underbrace(x_2^2, Z_4) + w_5 underbrace(x_1 x_2, Z_5) arrow.curve.b \
    y &= w_0 Z_0 + w_1 Z_1 + w_2 Z_2 + w_3 Z_3 + w_4 Z_4 + w_5 Z_5
  $

  #tool.custom_figure(
    caption: [مقادیر تابع $y$ که از نمودار @image_09_03 و تابعی از مقادیر $x_1$ و $x_2$ به دست می آید.],
    kind: table,
    inset: 1em,
  )[
    #table(
      columns: 7,
      inset: 1em,
      stroke: black,
      align: center + horizon,
      $Z_0$, $Z_1$, $Z_2$, $Z_3 \ (= x_1^2)$, $Z_4 \ (= x_2^2)$, $Z_5 \ (= x_1 x_2)$, $y$,
      "1", "-1", "-1", "1", "1", "1", "0",
      "1", "-1", "0", "1", "0", "0", "0",
      "1", "0", "-1", "0", "1", "0", "0",
      "1", "0", "1", "0", "1", "0", "1",
      "1", "1", "0", "1", "0", "0", "1",
      "1", "1", "1", "1", "1", "1", "1",
    )
  ]
]

#tool.definition()[
  رگرسیون خطی (Linear Regression): به این کار که تابعی به شکل مثال قبل تعریف کنیم و بگوییم $y$ تابعی خطی از متغیر ها است، رگرسیون خطی می گویند.

  تابعی خطی به صورت زیر داریم:
  $
    y = w_0 x_0 + w_1 x_1 + w_2 x_2
  $
  شکل برداری این تابع برای $y^(<1>)$ تا $y^(<N>)$ به صورت زیر است:
  $
    y^(<1>) = mat(w_0, w_1, w_2) mat(x_0^(<1>); x_1^(<1>); x_2^(<1>)) \
    y^(<2>) = mat(w_0, w_1, w_2) mat(x_0^(<2>); x_1^(<2>); x_2^(<2>)) \
    y^(<3>) = mat(w_0, w_1, w_2) mat(x_0^(<3>); x_1^(<3>); x_2^(<3>)) \
    dots.v \
    y^(<N>) = mat(w_0, w_1, w_2) mat(x_0^(<N>); x_1^(<N>); x_2^(<N>)) \
  $
  مجموعه توابع بالا را می توان به صورت زیر نوشت:
  $
    \
    overbrace(mat(y^(<1>), y^(<2>), y^(<3>), dots, y^(<N>)), display(Y_(1 times N))) &= overbrace(mat(w_0, w_1, w_2), display(W_(1 times 3)))
    overbrace(mat(
    x_0^(<1>), x_0^(<2>), x_0^(<3>), dots, x_0^(<N>);
    x_1^(<1>), x_1^(<2>), x_1^(<3>), dots, x_1^(<N>);
    x_2^(<1>), x_2^(<2>), x_2^(<3>), dots, x_2^(<N>)
  ), display(X_(3 times N))) \
    Y &= W X \
  $
  در معادله بالا تنها $W$ است که مجهول است. حال برای به دست آوردن $W$ مراحل زیر را انجام می دهیم ($X^T$ ترانهاده $X$ است):
  $
    Y_(1 times N) X_(N times 3)^T = W_(1 times 3) (X X^T)_(3 times 3)
  $
  ماتریس $X X^T$ یک ماتریس $3 times 3$ می باشد. یعنی یک ماتریس مربعی است و به همین دلیل به احتمال بسیار زیاد معکوس دارد:
  $
    Y X^T (X X^T)^(-1) &= W overbrace((X X^T) (X X^T)^(-1), "Identity Matrix (I)")
  $
  به این ترتیب، مقدار $W$ برابر است با:
  $
    Y X^T (X X^T)^(-1) = W arrow.curve.b \ #block(stroke: (paint: green_color, dash: "densely-dash-dotted"), inset: 1em)[$W = Y X^T (X X^T)^(-1)$]
  $
  در مثال قبل، کلاس های ما شامل ۰ و ۱ بودند اما مقدار $W$ پیوسته است، به همین دلیل، معمولاً برای آن یک Cutoff می گذارند.
  به این صورت که اگر بالای ۰/۵ بود آن را ۱ و اگر زیر ۰/۵ بود آن را ۰ در نظر می گیریم.
]

#tool.double_section()[
  #tool.tip()[
    با توجه به بخش قبل،
    ماتریس زیر که با ضرب آن در ماتریس $X$، باعث می شود که اثر $X$ خنثی شود را شبه معکوس ماتریس $X$ می گویند:
    $
      #h(1em) X times overbrace(underbrace(X^T (X X^T)^(-1), "شبه معکوس"), "Pseudo-inverse") = I
    $
    به این دلیل می گوییم شبه معکوس، چون $X^T (X X^T)^(-1)$ یک ماتریس مربعی نیست.
  ]
][
  #tool.tip()[
    ماتریس همانی، ماتریسی با الگوی زیر است که ضرب آن در هر ماتریس $X$ ای، خود $X$ را بر می گرداند.
    #v(2.2em)
    $
      I =
      mat(
      1, 0, 0, dots, 0;
      0, 1, 0, dots, 0;
      0, 0, 1, dots, 0;
      dots.v, dots.v, dots.v, dots.down, 0;
      0, 0, 0, 0, 1;
    )
    $
    #v(2.2em)
  ]
]
