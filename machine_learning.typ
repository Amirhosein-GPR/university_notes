#import "assets/typst/templates/note.typ": note
#import "assets/typst/tools/tool.typ"

#let red_color = rgb(200, 0, 0, 255)
#let orange_color = rgb(220, 100, 0, 255)
#let yellow_color = rgb(130, 130, 0, 255)
#let green_color = rgb(0, 120, 0, 255)
#let blue_color = rgb(0, 100, 200, 255)
#let dark_blue_color = rgb(0, 0, 200, 255)
#let purple_color = rgb(150, 0, 150, 255)
#let gold_color = rgb(255, 215, 0)
#let brown_color = rgb(125, 50, 0)

#let dir = rtl

#show: doc => note(
  doc,
  paper: "a4",
  black_and_white: false,
  flipped: true,
  first_page_font_size: 9pt,
  font_size: 8pt,
  image_path: "../../images/basu_logo_logosource.ir.svg",
  image_width: 12em,
  topic: "جزوه درس یادگیری ماشین",
  authors_name: "امیرحسین عسگری",
  professors_name: "دکتر محرم منصوری زاده",
  faculty: "مهندسی کامپیوتر",
  date: [
    نیم سال تحصیلی #text(dir: ltr)[۱۴۰۳-۱]
  ],
  version: "v0.15.0",
  progress_string: "15 / 22",
  info_color: blue_color,
  no_responsibility: true,
  font_attribution: true,
)

#tool.introduce_sections()

#colbreak()

#tool.title("درباره کلاس", color: blue_color)
- قواعد و مقررات:
  + حضور در کلاس اجباری است.
  + انجام تمرین ها و پروژه ها در زمان مشخص شده.
  + باید برایشان گزارش نوشته شود.
  + کزارش شامل موارد زیر است:
    + تعریف مسأله
    + پیاده سازی
    + اجرای نمونه
  + میان ترم و پایان ترم کتبی خواهیم داشت.

- راه های ارتباطی:

  - آیدی تلگرام: #text(dir: ltr)[mansoorm\@]

  - کانال تلگرام: #text(dir: ltr)[mansoorm\_courses\@]
  - ایمیل ها:
    + mansoorm\@basu.ac.ir
    + cse.teacher\@gmail.com

#colbreak()

#tool.title("فهرست مطالب", color: red_color)
#outline(title: none, indent: auto)

#colbreak()
#colbreak()
#colbreak()

= جلسه اول
== یادگیری ماشین
#tool.double_section()[
  #tool.simple_context()[
    یادگیری ماشین زیر شاخه ای از هوش مصنوعی است.
  ]
][
  #tool.tip()[
    ملاک درست بودن پاسخ، دادن جواب مورد انتظار کاربر است.
  ]
]

=== هوش
#tool.double_section()[
  #tool.definition()[
    هوش: معیار اندازه گیری میزان انطباق پاسخ با انتظار
    #v(2em)
  ]
][
  #tool.example()[
    دو عدد ادامه دنباله زیر را مشخص کنید.

    #text(dir: ltr)[۱, ۲, ۵, ۷, ۱۰, ..., ...]
  ]
]

#tool.true_answer()[
  در این مثال، معیار طراح سوال تعداد Ending point های هر عدد می باشد. بنابراین جواب به صورت زیر است:

  #text(dir: ltr)[۱, ۲, ۵, ۷, ۱۰, #text(fill: blue_color)[۱۲], #text(fill: blue_color)[۱۷]]
]

=== هوش مصنوعی
#tool.definition()[
  هوش مصنوعی: توانمندی کامپیوتر ها (ماشین ها) برای تولید پاسخ های مورد انتظار انسان.
]

#tool.double_section()[
  #tool.tip()[
    هوش مصنوعی از دید کاربر تعریف می شود.
  ]
][
  #tool.definition()[
    ماشین (کامپیوتر): به ابزاری که قابل برنامه ریزی است می گوییم.
  ]
]

=== رویکرد های هوش مصنوعی
==== مبتنی بر قانون (Rule based approach)
#tool.double_section()[
  #tool.definition()[
    در این روش مثلا از یک آدم متخصص در حوزه ای سوال می شود که چگونه کارش را انجام می دهد.
    بر این اساس یک سری پارامتر استخراج می کنیم و بر اساس آن ها برنامه ای را می نویسیم.
  ]
][
  #tool.example()[
    تشخیص انواع چند ضلعی ها #sym.arrow.l این که چند ضلعی مورد نظر مثلث متساوی الساقین است یا مربع است یا پنج ضلعی منتظم است یا ۱۰۰ ضلعی منتظم است یا #sym.dots .
  ]
]

#tool.true_answer()[
  روش تشخیص: به کمک اندازه زاویه ها و فاصله نقاط هر چند ضلعی، می توان نوع آن چند ضلعی را فهمید.

  مشکل روش: وقتی تعداد اضلاع و زاویه ها بالا رود، مشکل می شود.
]

==== مبتنی بر یادگیری (Learning based approach)
#tool.double_section()[
  #tool.definition()[
    در این روش الگوریتمی به کامپیوتر داده می شود تا خودش قاعده و قانون مسأله را به دست آورد.
  ]
][
  #tool.example()[
    تشخیص هواپیما #sym.arrow.l تعداد زیادی نمونه می آوریم.
    #v(1.55em)
  ]
]

#tool.true_answer()[
  #tool.custom_figure(
    image("images/ML/01_02.jpg", width: 92%),
    caption: "نقاط شکل هواپیما را به صورتی که مشخص شده است، شماره گذاری می کنیم.",
  )
  کد مرتبط:
  #tool.custom_figure(caption: "تشخیص هواپیما", kind: raw, inset: 1em)[
    ```
    R = {}
    for k = 1 to 16 {
        for j = k + 1 to 16 {
            flag = True
            for image = 1 to 10 {
                if d_k(image) != d_j(image) {
                    flag = false
                }
            }
            if flag == true {
                R = R U <d_k, d_j>
            }
        }
    }
    ```
  ]
]

#tool.tip()[
  یک مهندس یادگیری ماشین، دو مورد زیر را فراهم می کند:
  + نمونه ها (Examples)
  + الگوی قاعده (Rule template)
]

=== یادگیری (Training)
#tool.definition()[
  یادگیری (Training): فعالیتی که دو ورودی نمونه و الگو و همچنین خروجی قواعد را دارد، گویند.

  #tool.custom_figure(
    align(center)[
      #image("images/ML/01_01.png", width: 86%)
    ],
    caption: "گراف مربوط به فعالیت یادگیری",
    inset: 1em,
  )
]

= جلسه دوم
#tool.double_section()[
  #tool.tip()[
    کار هایی که مهندس یادگیری ماشین به همراه فرد خبره در حوزه مرتبطش انجام می دهند:
    ML engineer + Domain expert:
    #text(dir: ltr)[
      + Data collection
      + Template building
      + Training
    ]
  ]
][
  #tool.tip()[
    در Machine learning نقش اصلی را ML engineer بر عهده دارد.
    در حالی که در Data mining و Deep learning نقش اصلی بر عهده ماشین است.
    #v(4.8em)
  ]
]

#tool.definition()[
  یادگیری ماشین: یعنی به کامپیوتر ها یاد بدهیم تا مسائل را حل کنند.
]

== مسائل پایه ای یادگیری ماشین
=== Supervised learning
==== Classification

#tool.question()[
  Spam detection در ایمیل:
  فرض کنیم می خواهیم ایمیل های اسپم را از غیر اسپم برای فردی یا سازمانی تشخیص دهیم.
]

#tool.true_answer()[
  مراحل انجام این کار به صورت زیر است:
  + کلی ایمیل جمع می کنیم و آن ها را برچسب گذاری می کنیم.
    مثلا به صورت زیر:

    #tool.custom_figure(caption: "برچسب گذاری ایمیل ها", kind: table, inset: 1em)[
      #table(
        columns: 2,
        inset: 1em,
        stroke: black,
        align: center,
        "Message", "Label: Spam",
        "Message 1", "Yes",
        "Message 2", "No",
        "Message 3", "Yes",
        [#sym.dots], [#sym.dots],
        "Message N", "No",
      )
    ]

  + متن را بررسی می کنیم.
    مثلا به صورت زیر:

    #tool.custom_figure(caption: "بررسی لغت های درون ایمیل ها از نظر اسپم بودن یا نبودن", kind: table, inset: 1em)[
      #table(
        columns: 4,
        inset: 1em,
        stroke: black,
        align: center,
        "Word", "F_Yes", "F_No", "Difference",
        "Rich", "56", "73", "56 - 73 = -17 < 0",
        "Click", "123", "15", "108",
        [#sym.dots.v], [#sym.dots.v], [#sym.dots.v], [#sym.dots.v],
      )
    ]

  در جدول بالا، ستون F_Yes به تعداد ایمیل های اسپمی که در متن آن ها کلمه Rich وجود دارد اشاره می کند و ستون F_No، عکس این قضیه می باشد.

  در نهایت تمامی کلمات در قالب جدول بالا بررسی می شوند.
  این عمل را بار اول خودمان انجام می دهیم.

  توجه: اسپم بودن یا نبودن هر ایمیل مورد نظر است و نه هر کلمه هر ایمیل به صورت جداگانه.

  توجه: هر لغتی که در متن یک ایمیل داشته باشیم، همان یک بار برای متنش حساب می شود و نه بیشتر.
  مثلا یک ایمیلی ۱۰۰ عدد کلمه Click دارد.
  در این حالت می گوییم کلمه Click در این ایمیل آمده است و به تعدادش اشاره نمی کنیم.

  اما چرا اینگونه عمل کردیم؟ چون طبیعت، هموار (Smooth) است.

  در ادامه ۱۰۰ کلمه ای (تعداد دلخواه) که بیشترین تفاضل را دارند، انتخاب کرده و برای یک ایمیلی که می خواهیم بررسی اش کنیم، می گوییم اگر درون این ایمیل، مثلاً بیشتر از ۲۰ کلمه مجزا از این ۱۰۰ کلمه وجود داشت، آن ایمیل، یک ایمیل اسپم است.

  پس به صورت خلاصه به شکل زیر عمل می کنیم:
  #text(dir: ltr)[
    + Collect a set of spam and real (not-spam) messages.
    + Count words in the message.
    + Select top #text(stylistic-set: 2)[100] distincitve (Highly frequent in spams) spam words
    // For a new message or stage???
    + For a new message if M contains more than #text(stylistic-set: 2)[20] distincitve words, It is spam.
  ]

  در نهایت برنامه ای به شکل زیر ساخته خواهد شد:

  #tool.custom_figure(
    image("images/ML/02_01.png"),
    caption: "یک برنامه یادگیری ماشین که یک ورودی و دو خروجی به شکل بالا دارد.",
    inset: 1em,
  )

  به این نوع یادگیری ماشین، Classification می گوییم.
]

#tool.example()[
  مثالی در حوزه Classification به صورت زیر آمده است:
  ساخت یک برنامه یادگیری ماشین که Chest X-Ray را به عنوان ورودی بگیرد و بگوید ریه فرد، چقدر درگیر است.
  خروجی برنامه نیز یکی از موارد زیر است:
  #text(dir: ltr)[
    + None
    + Low
    + Mild
    + High
    + Severe
  ]
]

==== Regression
#tool.question()[
  پیش بینی کردن قیمت خانه
]

#tool.true_answer()[
  - گام اول: فرض کنیم قیمت خانه ها به شکل زیر است:

  #tool.custom_figure(caption: "قیمت خانه ها بر اساس مساحت آن ها", kind: table, inset: 1em)[
    #table(
      columns: 2,
      inset: 1em,
      stroke: black,
      align: center,
      "Area", "Price",
      [50 $m^2$], [100],
      [75 $m^2$], [105],
      [75 $m^2$], [150],
      [100 $m^2$], [220],
      [120 $m^2$], [240],
    )
  ]

  برای آن که درک بهتری از جدول بالا داشته باشیم به شکل زیر توجه کنید:

  #tool.custom_figure(
    image("images/ML/02_02.png", width: 85%),
    caption: "تلاش می کنیم معادله ای که تا جای ممکن تمامی نقاط نمودار را پوشش می دهد، پیدا کنیم.",
    inset: 1em,
  )

  بر اساس اصل پیوسته بودن طبیعت مشاهده می کنیم که نقاط شکل بالا گویی حول محور آبی حرکت می کنند.

  - گام دوم:

  معادله خط مربوط به خط آبی رنگ را پیدا می کنیم.
  مثلا:

  $ "Price = 2" "Area" + epsilon $

  به این گونه مسائل که به دنبال یافتن معادله ای همچون

  $ y = f(x) $

  برای حل شان می گردیم؛ مسائل Regression می گویند.
]

#tool.list()[
  مسائل پایه ای یادگیری ماشین:
  #text(dir: ltr)[
    + Supervised learning
      + Classification
      + Regression
    + Unsupervised learning
      + Association learning
      + Clustering
      + Distribution learning (Density estimation)
    + Reinforcement learning
      + Reward / Punishment
  ]
]

=== Unsupervised learning
==== Association learning

#tool.question()[
  فروشنده یک مغازه می خواهد به مشتری ای که مثلاً ۴ کالا خریده است، کالای پنجمی را پیشنهاد داده و آن را بفروشد.
  چگونه به او پیشنهاد بدهد؟
]

#tool.true_answer()[
  + داده های گذشته رو بررسی می کنیم.
    مثلا:
    #tool.custom_figure(caption: "کالا های خریده شده توسط مشتری ها", kind: table, inset: 1em)[
      #table(
        columns: 2,
        inset: 1em,
        stroke: black,
        align: center,
        "مشتری ۱", "پنیر - [شیر] - [نان]",
        "مشتری ۲", "<رب> - تخم مرغ - <نان>",
        "مشتری ۳", "[شیر] - رب> - [<نان>]>",
        [#sym.dots.v], [#sym.dots.v],
        "مشتری N", [#sym.dots],
      )
    ]

  + کالا های با بیشترین تکرار را پیدا می کنیم.
    مثلا:

    $ F_1 = "رب - شیر - نان" $

  + کد الگوریتم را به صورت زیر می نویسیم (برای آموزش یا همان Training)):
    #tool.custom_figure(caption: "آموزش مدل برای یافتن کالا های با بیشترین تکرار", kind: raw, inset: 1em)[
      ```
      F_1 = {} F_2 = {}

      for each x in F_1 {
          for each y in F_1 {
              if <x, y> is frequent {
                  F_2 = F_2 U {<x, y>}
              }
          }
      }
      ```
    ]

  + در آخر برنامه پیشنهاد کالا را با استفاده از داده هایی که در مرحله قبل به دست آوردیم به صورت زیر می نویسیم و اجرا می کنیم:
    #tool.custom_figure(caption: "برنامه پیشنهاد کالا که از مدل آموزش داده شده، استفاده می کند.", kind: raw, inset: 1em)[
      ```
      for each customer c {
          for each pair <x, y> in F_2 {
              if c buys x {
                  recommend y
              }
          }
      }
      ```
    ]

  این مسأله نوعی مسأله در حوزه Association learning می باشد.
]

==== Clustering
#tool.question()[
  در ادامه مسأله قبلی، حالا می خواهیم بدانیم که چگونه مشتری هایی داریم؟ (Grouping customers)
]

#tool.true_answer()[
  بر اساس سبد خرید مشتری ها، آن ها را دسته بندی می کنیم.

  + به صورت زیر سبد ها را دو به دو مقایسه کرده و دسته بندی می کنیم.

    داریم:
    $ B_1 , B_2 $

    به کمک فرمول زیر، شباهت بین دو سبد $B_1$ و $B_2$ را به دست می آوریم (علامت قدر مطلق به اندازه مجموعه ها اشاره می کند):
    $ S = abs(B_1 sect B_2) / abs(B_1 union B_2) $

    برای نمونه بین مشتری ۱ و مشتری ۲ داریم:
    $ S = abs("نان") / abs("رب - تخم مرغ - پنیر - شیر - نان") = ۱ / ۵ $

    #text(number-width: "proportional")[یعنی سبد خرید مشتری ۱ و مشتری ۲ به میزان ۲۰٪ به یکدیگر شباهت دارند.]

  + به تعداد دلخواه مثلاً ۵ عدد گروه در نظر می گیریم و به صورت زیر عمل می کنیم:

    + #text(number-width: "proportional")[فرض کنید ۱۰۰ تا مشتری داریم.
        این مشتری ها را به شکل تصادفی در ۵ گروه ۲۰ تایی تقسیم بندی می کنیم.]

    + سپس یکی از مشتری ها را از یک گروهی انتخاب کرده و با همه گروه ها مقایسه می کنیم.
      در نهایت مشتری به گروهی که بیشترین شباهت را با آن دارد، منتقل می شود.

    + #text(number-width: "proportional")[اگر این کار را بر روی مشتری ها ادامه دهیم بعد از مدتی به همگرایی خواهیم رسید و ۵ گروه ۲۰ تایی خواهیم داشت که اعضای درون هر گروه به یکدیگر شباهت دارند.]

    اما این دسته بندی چه فایده ای دارد؟

    یک نمونه مثال از فایده آن این است که مشتری هایی که در گروه مشترک هستند را بررسی می کنیم چه کالا هایی را خریدند تا آن کالا ها را در یک راهرو کنار هم قرار دهیم.

    این مسئله نمونه ای از مسائل Clustering می باشد.
]

=== Reinforcement learning
==== Reward / Punishment
#tool.question()[
  می خواهیم نحوه بازی کردن شطرنج را آموزش دهیم.
]

#tool.true_answer()[
  فرض کنیم دو بازیکن به نام های بازیکن ۱ و ۲ داریم.
  بازیکن ۲ می خواهد شطرنج را به بازیکن ۱ یاد بدهد.

  + #text(number-width: "proportional")[ابتدا حرکاتی که هر مهره می تواند انجام دهد به بازیکن ۱ گفته می شود.]
  + بازیکن ها شروع به بازی کردن می کنند.
  + #text(number-width: "proportional")[به صورت زیر هر دو بازیکن حرکاتی را انجام می دهند و در نهایت بازیکن ۲ می برد.]
    #tool.custom_figure(caption: "حرکت های بازیکن های ۱ و ۲", kind: table, inset: 1em)[
      #table(
        columns: 2,
        inset: 1em,
        stroke: black,
        align: center,
        "بازیکن ۱", "بازیکن ۲",
        [$W_1$], [$B_1$],
        [$W_2$], [$B_2$],
        [#sym.dots.v], [#sym.dots.v],
        [$W_7$], [$B_7$],
      )
    ]
  + #text(number-width: "proportional")[وقتی که بازیکن ۱ می بازد، می فهمد مجموعه حرکاتی که انجام داده، بد بوده است و بابت باخت مجازات می شود.]
  + #text(number-width: "proportional")[بازیکن ۱ اینقدر حرکات شانسی مختلف را امتحان می کند تا می برد و بابت برد امتیاز می گیرد.]

  به این صورت بازیکن ۱ بازی شطرنج را یاد می گیرد.

  به این روش که ماشین می تواند از شکست ها (جریمه ها) و برد ها (جایزه ها) یاد بگیرد روش Reward / Punishment می گویند که زیر مجموعه ای از Reinforcement learning می باشد.
]

= جلسه سوم
== مسائل پایه ای یادگیری ماشین (ادامه)
=== Unsupervised learning
==== Distribution learning (Density estimation)
#tool.question()[
  یک فرد سیگاری داریم. این فرد چند سال دارد؟
]

#tool.true_answer()[
  داده ها را جمع آوری کرده و معمولاً به صورت فراوانی نسبی نشان شان می دهیم.

  از تعداد جمعیت ۱۰۰ نفر، سن شان پرسیده می شود و به جدول زیر می رسیم.

  #tool.custom_figure(caption: "فراوانی سیگاری بودن افراد در سنین مختلف", kind: table, inset: 1em)[
    #table(
      columns: 3,
      inset: 1em,
      stroke: black,
      align: center,
      "سن\n(Age)", "فراوانی\n(Frequency)", "فراوانی نسبی\n(Relative frequency)",
      "1", "0", "0",
      "5", "0", "0",
      "10", "5", "0.05",
      "15", "15", "0.15",
      "20", "16", "0.16",
      "25", "16", "0.16",
      "30", "16", "0.16",
      "50", "15", "0.15",
      "60", "10", "0.10",
      "80", "5", "0.05",
      "90", "2", "0.02",
      "100", "0", "0",
      "---", "مجموع", "---",
      "---", "100", "---",
    )
  ]

  حالا می خواهیم به این برسیم که مثلاً احتمال اینکه یک آدم ۴۰ ساله سیگاری باشد چقدر است.
  یعنی:
  $ P("Smoking" | "Age" = 40) = space ? $

  راه حل این است که می آییم می بینیم که ۳۰ ساله ها احتمال ۰/۱۶ و ۵۰ ساله ها احتمال ۰/۱۵ را دارند.
  از آن جایی که سن ۴۰ سال بین این دو احتمال است، میانگین شان را برای آن در نظر می گیریم.
  یعنی:
  $ P("Smoking" | "Age" = 40) = 0.155 $

  پس اگر Data ما به صورت زیر باشد:
  $ X = {x_1, x_2, dots, x_n} $

  آنگاه به
  $ P(x in X) $
  می گویند Distribution و به پیدا کردنش می گویند Distribution learning.
  به عبارت دیگر Distribution learning یعنی اینکه توزیع داده ها را به دست آوریم.
  $ P(x in X): "Distribution learning" $

  اما گاهی مقادیری که یک متغیر می تواند اختیار کند، خیلی زیاد است یا بی نهایت است.
  در اینگونه موارد، معمولاً در آمار به جای کاری که کردیم، برای Distribution از Probability density function استفاده می کنیم که به صورت خلاصه به آن PDF می گویند:

  $
    \
    P( "Smoking" | x ) = cases(0 &"if" space.quad x < 10 &|space space| space.quad x > 90, 0.01 x &"if" space.quad x >= 10 &amp amp space.quad x < 20, 0.16 &"if" space.quad x >= 20 &amp amp space.quad x < 50, 0.16 - 0.01 x space.quad &"if" space.quad x >= 50 space.quad &amp amp space.quad x < 90)
  $

  به این ترتیب هدف ما در Distribution learning، پیدا کردن یک تابع توزیع است.
]

#tool.question()[
  همان سؤال قبلی با فرض این که داده ها توزیع نرمال داشته باشند.
  یعنی سن افراد سیگاری به صورت نرمال توزیع شده باشد.
]

#tool.true_answer()[
  در اصل ML engineer از سوادش به این موضوع پی می برد که داده ها نرمال هستند.
  مثلاً مشاهده می کند که ۵ فرد سیگاری ۱۰ ساله داریم و بعدش ۱۵ فرد سیگاری ۱۵ ساله داریم و به همین ترتیب متوجه می شود که داده ها شکلی نرمال دارند.

  با ضرب نظیر به نظیر هر عضو ستون سن در ستون فراوانی، و سپس تقسیم کردن حاصل آن بر تعداد جمعیت که ۱۰۰ می باشد به میانگین زیر می رسیم:
  $ mu = "Average" = 34 $
  و احتمالاً دارای انحراف معیار زیر می باشد:
  $ "Standard deviation" = 5 $

  و بر این اساس به نمودار زیر می رسیم:
  #tool.custom_figure(
    image("images/ML/03_01.png", width: 90%),
    caption: "با توجه به میانگین و انحراف معیار جمعیت، به نمودار بالا می رسیم.",
    inset: 1em,
  )
]

#tool.tip()[
  تفاوت روش Regression با Distribution learning: در Regression لزوماً متغیر خروجی مان یک متغیر احتمالاتی نیست.
  این دو روش از هم خیلی دور نیستند ولی به هر صورت تفاوت دارند.
]

== Classification
#tool.question()[
  می خواهیم یک ماشین مناسب خانواده بخریم (Family car detection).
  چه ماشینی مناسب خانواده است؟
]

#tool.true_answer()[
  دو نقش برای حل این مسأله داریم:
  + ML engineer: برنامه ای می سازد که بتواند ماشین مناسب برای خانواده را با توجه به قدرت موتور و قیمت آن، تشخیص دهد.
  + Domain expert: می گوید چه ماشینی مناسب خانواده است.
    با گفتن قدرت موتور و قیمت ماشین به او، به ما جواب خواهد داد.

  ML engineer داده های قدرت و قیمت ماشین ها را به Domain expert می دهد و از او سؤال می کند آیا با توجه به مقدار آن ها، ماشین مربوطه مناسب است یا خیر؟
  در جدول زیر اطلاعات ماشین ها و پاسخ او آمده است:
  #tool.custom_figure(
    caption: "مناسب بودن یا نبودن ماشین برای خانواده با توجه به قدرت موتور و قیمت ماشین",
    kind: table,
    inset: 1em,
  )[
    #table(
      columns: 3,
      inset: 1em,
      stroke: black,
      align: center,
      [Engine power ($X_1$)], [Price ($X_2$)], [Family car ($Y$)],
      "10", "1k", "No",
      "20", "1.2k", "No",
      "45", "5k", "Yes",
      "60", "10k", "Yes",
      "120", "15k", "Yes",
      "140", "30k", "No",
      "30", "100k", "No",
      "20", "200k", "No",
    )
  ]

  در ادامه مراحل زیر را انجام می دهیم:
  + Plot data:
    از آن جایی که انسان با دیدن نمودار داده ها درک بهتری از آن ها پیدا می کند، تا دیدن جدول، نمودار جدول بالا را رسم می کنیم.
    #tool.custom_figure(
      image("images/ML/03_02.png"),
      caption: "نمودار جدول بالا. دایره های منفی بیانگر ماشین های نامناسب و دایره های مثبت بیانگر ماشین های مناسب خانواده می باشند.",
      inset: 1em,
    )

  + Get an insight:
    #tool.custom_figure(
      image("images/ML/03_03.png"),
      caption: "با کمی نگاه به نموداری که رسم کردیم، به این دیدگاه می رسیم که ماشین های مناسب خانواده درون محدوده قرمز رنگ قرار می گیرند. گویی که توسط یک مستطیل (که با طول و عرض و مختصات نقطه پایین سمت چپش مشخص می شود) احاطه شده اند.",
      inset: 1em,
    )
    ما به عنوان ML engineer تصمیم می گیریم که محدوده ماشین های مناسب خانواده در نمودار بالا را به کمک شکلی نمایش دهیم.
    برای مثال به کمک یک مستطیل موازی محور های مختصات این محدوده را مشخص می کنیم.
    یکی از دلایل انتخاب مستطیل به جای مثلاً بیضی، ساده بودن رسم و تعریف آن است.

  + Make hypothesis and select a model:
    مهم ترین گام ما این گام است که در آن باید یک فرضیه خوب بسازیم.

    برای این مسأله فرضیه ما این است: ماشین های مناسب خانواده درون یک مستطیل موازی محور های مختصات هستند.
    در این جا مستطیلی که تعریف کردیم، همان Model برنامه ما می باشد که دارای ۴ پارامتر است و به صورت زیر تعریف می شود:

    #align(center)[
      #text(dir: ltr)[
        Model\<Left, Bottom, Width, Height\>
      ]
    ]

  + Train the model:
    یعنی یافتن بهترین مقادیر برای پارامتر های مدل.

    در این مرحله باید مدل خود را آموزش دهیم.
    از آنجایی که مدل پیشنهادی ما یک مستطیل است، برای آن که برنامه ما بتواند مشخصات این مستطیل را یاد بگیرد الگوریتم زیر را می نویسیم (الگوریتم Training):
    #tool.custom_figure(caption: "الگوریتم Training مدل.", kind: raw, inset: 1em)[
      ```
      // X is the data items consisting from only the first 2 columns of the former table (An N x 2 matrix)
      // Y is the data items consisting from only the last column of the former table (An N x 1 matrix)
      // N is the number of table rows (Here N = 8)

      Input: X, Y, N
      left = Infinity, bottom = Infinity
      width = -Infinity, height = -Infinity

      for k = 1 to N {
          // Poisitive example
          if Y[k] = True {
              if X[k, 1] < left {
                  left = X[k, 1]
              }
              if X[k, 2] < bottom {
                  bottom = X[k, 2]
              }
              if X[k, 1] - left > width {
                  width = X[k, 1] - left
              }
              if X[k, 2] - bottom > height {
                  height = X[k, 2] - bottom
              }
          }
      }
      ```
    ]

    پس از اجرای الگوریتم و آموزش دادن برنامه، باید برنامه را تست کنیم.
    برای مثال اگر ماشینی با مشخصات زیر به برنامه بدهیم:

    #align(center)[
      #text(stylistic-set: 2)[Engine power: 50, Price: 12k]
    ]

    برنامه به ما جواب
    Yes
    می دهد چون داخل مستطیل می افتد.
    فرآیندی که توضیح دادیم فرآیند Prediction می باشد.

    الگوریتم Prediction برای این مسأله به صورت زیر می باشد (Class label prediction):
    #tool.custom_figure(caption: "الگوریتم Prediction بر اساس مدل آموزش داده شده.", kind: raw, inset: 1em)[
      ```
      // e ---> Engine power
      // p ---> Price
      // M ---> Model
      // M[1] ---> Left,  M[2] ---> Bottom
      // M[3] ---> Width, M[4] ---> Height
      function Prediction(e, p, M) {
          if e >= M[1] and
          e <= M[1] + M[3] and
          p >= M[2] and
          p <= M[2] + M[4] {
              return "Yes"
          } else {
              return "No"
          }
      }
      ```
    ]

  #tool.list()[
    عبارت های مهم در این درس:
    - Classification
    - Plot: رسم کردن
    - Insight: بینش
    - Hypothesis: فرضیه
    - Model
    - Parameter
    - Train
    - Algorithm
    - Feature: در این جا همان ستون های مربوط به X می باشد.
    - Training set: در این جا همان مجموعه داده های X و Y می باشد.
    - Prediction (Recognition)
    - Inductive bias: هر دانسته ای غیر از اطلاعاتی که صورت مسأله داده و آن را به مسأله اضافه می کنیم، می گویند.
      مثلاً اینکه مدل مان مستطیل باشد یا بیضی، یک Inductive bias است.
  ]
]

= جلسه چهارم
== Smoothness
#tool.simple_context()[
  هدف در یادگیری ماشین (با کمی سهل گیری، هوش مصنوعی) این هست که دنیا را یک موجودیت پیوسته ببینیم، مدلش کنیم و این مدل را برای پیش بینی داده هایی که نداریم، استفاده کنیم.
  در دنیا موجودات مشابه هم، کنار هم هستند.
]

#tool.example()[
  Object زیر را داریم:
  $ "Object" cases("Attribute 1", "Attribute 2", "Attribute 3", dots.v, "Attribute N") $
]

#tool.double_section()[
  #tool.question()[
    دو Object ای که از یک جنس یا جمعیت هستند، انتظار داریم Attribute هاشون مشابه باشد یا نه؟
  ]
][
  #tool.true_answer()[
    انتظار داریم مشابه باشند.
    #v(3.2em)
  ]
]

#tool.double_section()[
  #tool.tip()[
    کل صحبتی که در یادگیری ماشین (با کمی سهل گیری، هوش مصنوعی) می شود، بر مبنای فرض Continuity یا Smoothness می باشد.
    #v(1.6em)
  ]
][
  #tool.example()[
    انتظار نداریم دیروز که هوا آفتابی بوده و امروز هم آفتابی هست فردا ناگهانی برفی بشود.
    حالت طبیعی این است که به تدریج هوا ابری شود و باد های سرد بوزد و به مرور هوا برفی شود.
  ]
]

#tool.reminder()[
  در مثال خرید ماشین خانواده، وقتی داده های مرتبطش را بر روی نمودار رسم کردیم، حدس زدیم که مستطیلی را می توان پیدا کرد که درون آن ماشین های مناسب خانواده قرار می گیرند. به این مستطیل، مدل می گویند. که به شکل زیر تعریف می شود:

  #align(center)[
    #text(dir: ltr)[
      Model\<Axis aligned rectangle\> = Model\<Left, Bottom, Width, Height\>
    ]
  ]

  #tool.custom_figure(
    image("images/ML/04_01.png", width: 67%),
    caption: "مثال خرید ماشین مناسب خانواده در جلسه سوم",
    inset: 1em,
  )

  بعد از انتخاب مدل، باید پارامتر های آن آموزش داده شوند که به کمک ابزار یادگیری انجام می شود.

  #tool.custom_figure(
    image("images/ML/04_02.png"),
    caption: "ابزار Learning که دو ورودی و یک خروجی به شکل بالا دارد.",
    inset: 1em,
  )

  در مدل آموزش داده شده، پارامتر های آن مقدار دهی شده اند.
]

== مفهوم مخفی و فرضیه سازگار
#tool.example()[
  فرض کنیم در مثال ماشین خانواده، ماشین های مناسب واقعا توسط یک مستطیل مشخص می شوند (مستطیل بزرگتر شکل زیر).

  #tool.custom_figure(
    image("images/ML/04_03.png", width: 79%),
    caption: "مستطیل بزرگتر چیزی است که واقعا وجود دارد و مستطیل کوچک تر مدلی است که از یادگیری از روی مثال های داده شده به دست آمده است.",
    inset: 1em,
  )

  فرض کنیم شروع به تست کردن برنامه می کنیم و پاسخ آن این است که ماشین مناسب خانواده نیست، در صورتی که در واقع مناسب است.
]

#tool.double_section()[
  #tool.definition()[
    Latent concept: به مستطیلی که (در مثال بالا مستطیل است) واقعا وجود دارد و اغلب از آن خبر نداریم، می گویند و آن را با C نمایش می دهیم.
  ]
][
  #tool.definition()[
    Consistent hypothesis: چیزی که مدل یاد گرفت، که با نمونه های مثبت مان سازگار است، می گویند.
    #v(1.6em)
  ]
]

== بررسی یک الگو
#tool.example(pause: true)[
  فرض کنیم مساحت مستطیل کوچک $S_2$ و مساحت مستطیل بزرگ $S_1$ باشد.
  همچنین فرض کنیم:
  $ S_1 = 1 $
  در نتیجه:
  $ S_2 < S_1 $

  حال فرض کنیم یک نفر یک ماشین خانواده مناسب (نمونه مثبت) پیدا کرده و به ما می دهد (یعنی از کل C انتخاب کرده است).
]

#tool.double_section()[
  #tool.question()[
    احتمال این که از $S_2$ انتخاب کند چقدر است؟
  ]
][
  #tool.true_answer()[
    $S_2$
    #v(1.7em)
  ]
]

#tool.double_section()[
  #tool.question()[
    احتمال این که بیرون از $S_2$ انتخاب کند چقدر است؟
  ]
][
  #tool.true_answer()[
    $S_1 - S_2$
    #v(1.7em)
  ]
]

#tool.example(continuation: true, pause: true)[
  اگر اسم نمونه مورد نظر را $x$ بگذاریم آن گاه:
  $ p(x in S_2) = S_2 $
  $ p(x in.not S_2) = S_1 - S_2 $

  پس احتمالی وجود دارد که نمونه جدید به بهتر شدن فرضیه ما کمک می کند.
  این اتفاق زمانی می افتد که نمونه جدید در ناحیه درون $S_1$ و بیرون از $S_2$ باشد.

  احتمال اینکه همه N عدد نمونه ما درون $S_2$ باشند به صورت زیر است:
  $ (S_2)^N $

  به این ترتیب احتمال اینکه نمونه اول ما درون $S_2$ باشد، به صورت زیر است:
  $ S_2 $

  فرض کنیم $S_2$ نصف $S_1$ است.
  به این ترتیب احتمال این که اولین نمونه داخل $S_2$ باشد، ۵۰٪ درصد است.

  به نمونه هایی که می گیریم می گویند:
  // در این درس فرض ما این است که نمونه هایمان به صورت زیر است:
  #align(center)[
    #text(dir: ltr)[
      Independently and Identically Distributed (IID)
    ]
  ]
]

#tool.definition()[
  IID Sample: نمونه هایی که مستقل از هم اند و توزیع یکسانی دارند (احتمال یکسانی دارند).

  یعنی اگر مثلا ترتیب نمونه ها را عوض کنیم، چیزی عوض نمی شود.
]

#tool.double_section()[
  #tool.example()[
    از یک بشکه آب برداریم آبش کم می شود اما از یک چشمه آب برداریم گویی آبی کم نمیشه.
    در این جا چشمه IID است ولی بشکه IID نیست.
    #v(4.8em)
  ]
][
  #tool.example()[
    تعدادی توپ با رنگ های مختلف داریم.
    وقتی توپ ها را بر می داریم و رنگشان را نگاه می کنیم.
    اگر:
    + توپ ها را سر جایشان برگردانیم: نمونه ها IID هستند.
    + توپ را نگه داریم (IID): نمونه ها IID نیستند.
  ]
]
#tool.example(continuation: true)[
  فرض کنیم $S_2 = 0.5$ و همه نمونه ها IID هستند.
  احتمال این که نمونه اول داخل $S_2$ باشد و کمکی به یادگیری و بهبود Hypothesis ما نکند، برابر زیر است:
  $ (0.5) $

  نمونه دوم:
  $ (0.5)(0.5) $

  نمونه سوم:
  $ (0.5)(0.5)(0.5) $

  نمونه N ام:
  $ (0.5)^N $

  اگر بخواهیم احتمال بد شانسی ما کمتر از ۰/۰۱ باشد، (یعنی به احتمال ۰/۹۹ خوش شانس باشیم):
  $ P_"بد شانسی" = (0.5)^N <= 0.01 $
  $
    \
    (0.5)^N <= 0.01 arrow N log 0.5 <= log 0.01 arrow N >= (log 0.01) / (log 0.5) arrow N >= 6.7 tilde.eq 7
  $

  یعنی به ۷ نمونه نیاز داریم تا به احتمال ۰/۹۹ خوش شانس باشیم (مدل مان چیز جدید یاد بگیرد).

  در ادامه احتمال های بد شانسی مختلف به همراه تعداد نمونه لازم برای رسیدن به آن ها، آورده شده است:
  #tool.custom_figure(caption: [رابطه بین احتمال بد شانسی $S_2$ و تعداد نمونه ها], kind: table, inset: 1em)[
    #table(
      columns: 4,
      inset: 1em,
      stroke: black,
      align: center + horizon,
      fill: (x, y) => if calc.even(x) {
        luma(230)
      },
      [$S_2$ (بد شانسی)], "Samples\ncount", [$S_2$ (بد شانسی)], "Samples\ncount",
      "0.01", "1", "0.9", "43",
      "0.1", "2", "0.99", "458",
      "0.5", "7",
    )
  ]

  با دقت به جدول بالا به این نتیجه می رسیم که $S_2$ زمانی کوچکتر است که تعداد نمونه ها کم تر است.
]

#tool.tip()[
  هر چقدر در فرآیند آموزش از نمونه های جدید بیش تری استفاده می کنیم، از خوش شانسی به سمت بد شانسی می رویم.
  یعنی مثلاً اگر احتمال بد شانسی ما ۰/۹۹ است، با توجه به جدول قبلی، حداقل باید ۴۵۸ نمونه اضافه کنیم تا مدل مان بهتر شود.
  به عبارت دیگر یادگیری در ابتدا خیلی سریع است و به مرور کند تر می شود.

  #tool.custom_figure(
    image("images/ML/04_04.png", width: 53%),
    caption: "اغلب نمودار های یادگیری به صورت بالا هستند. افت خطا در ابتدای آموزش که تعداد کمی نمونه دریافت می شود، زیاد است. اما از جایی به بعد نمونه های جدید خیلی کمکی نمی کنند.",
    inset: 1em,
  )
]

#tool.tip()[
  یادگیری ماشین را نمی توان بدون استفاده از نمونه انجام داد.
]

#tool.tip()[
  حجم نمونه آموزشی برای یادگیری مناسب، مهم است. نیاز است تعداد نمونه آموزشی مان از حداقل خاصی بیشتر باشد تا بتوان با کیفیت مد نظرمان یادگیری انجام شود.
]

== خطا و انواع آن
#tool.example()[
  فرض کنید Concept واقعی به صورت زیر است اما الگوریتم یادگیری به جای آن که از نمونه های مثبت یاد بگیرد از نمونه های منفی یاد بگیرد.
  #tool.custom_figure(
    image("images/ML/04_05.png", width: 72%),
    caption: "در شکل بالا، مدل ما به صورت مستطیل چسبیده به نمونه های منفی تعریف می شود.",
    inset: 1em,
  )

  تفاوتی که مدل بالا با مدل قبلی دارد، به جز اینکه از نمونه های منفی برای آموزش استفاده می کند، این است که h ما به صورت کامل درون C قرار ندارد.

  ابتدا خطایی برای h تعریف می کنیم.
]

#tool.definition()[
  خطا: تعداد تشخیص های غلط برای نمونه های تستی مدل.

  انواع خطا ها شامل موارد زیر است:
  + خطای مطلق (Absolute error):
    این خطا در ریاضی کاربرد دارد و شامل مجموع همه خطا های موجود بر روی کل دامنه است.

  + خطای تجربی (Emprical error): تعداد خطا در مجموعه نمونه های کوچک و محدودی که داریم.
    شکل ریاضی این خطا به صورت زیر است:
    $ x, y: "Testing set" $
    $ E(h, x) = sum_(k = 1)^(abs(x)) 1(h(x^(<k>)) eq.not y^(<k>)) $
    در عبارت بالا $y$ برچسب تک تک $x$ ها است.
    مثلاً به صورت زیر:
    #tool.custom_figure(caption: "برچسب مرتبط با هر نمونه (هر نمونه فقط یک ویژگی x را دارد).", kind: table, inset: 1em)[
      #table(
        columns: 2,
        inset: 1em,
        stroke: black,
        align: center + horizon,
        [$x$], [$y$],
        [$x^(<1>)$], "Yes",
        [$x^(<2>)$], "No",
        [#sym.dots.v], [#sym.dots.v],
      )
    ]

    همچنین $h(x^(<k>)) eq.not y^(<k>)$ به معنای این است که Label ای که Hypothesis ما به $k$ امین نمونه آزمایش داده است، با Label واقعی مان متفاوت باشد.

  + خطای تجربی میانگین (Average emprical error):
    خطای تجربی تقسیم بر اندازه نمونه.
    این خطا برای مقایسه مدل ها به کار می رود چرا که مستقل از مجموعه Emprical شان است (بر خلاف Emprical error که قابل مقایسه نیست).
    شکل ریاضی این خطا به صورت زیر است:
    $ E_"Average" = 1 / (abs(x) + 1) sum_(k=1)^abs(x) 1(h(x^(<k>)) eq.not y^(<k>)) $
]

== انواع پاسخ های برنامه
#tool.definition()[
  انواع پاسخ هایی که برنامه ما می تواند تولید کند شامل موارد زیر است:
  + True Poisitive (TP)
  + True Negative (TN)
  + False Poisitive (FP)
  + False Negative / False Reject (FN / FR)
  که به صورت شهودی در شکل زیر آمده است:
  #tool.custom_figure(
    image("images/ML/04_06.png", width: 55%),
    caption: "انواع پاسخ های برنامه ما",
    inset: 1em,
  )
]

== قاعده Maximum Entropy
#tool.tip()[
  تا اینجا دو مدل یاد گرفتیم.
  یک مدل بر پایه داده های مثبت به دست می آمد و مدل دیگر بر پایه داده های منفی.
  قاعده Maximum Entropy به ما می گوید مستطیلی (مدل ما در اینجا) را پیدا کنیم که دقیقا وسط دو مستطیل دیگر (دو مدل دیگر) باشد.
  #tool.custom_figure(
    image("images/ML/04_07.png", width: 85%),
    caption: "مستطیل کوچک مدلی است که از نمونه داده های مثبت و مستطیل بزرگ مدلی است که از نمونه داده های منفی به دست آوردیم. مستطیلی که از قاعده Maximum Entropy به دست می آید، همان مستطیلی است که دقیقا وسط دو مستطیل دیگر قرار دارد.",
    inset: 1em,
  )

  این قاعده در همه جا ما را به نتایج خوبی می رساند.
]

#tool.example()[
  فرض کنید یک مسأله ای به شکل زیر داریم. چه چیزی نمونه های مثبت و منفی را از هم جدا می کند؟ بی نهایت خط.
  اما طبق قاعده Maximum Entropy مرز وسط به دست می آید.
  #tool.custom_figure(
    image("images/ML/04_08.png", width: 60%),
    caption: "مرز بین دو گروه به وسیله خط وسطی مشخص شده است که از قاعده Maximum Entropy به دست می آید.",
    inset: 1em,
  )
]

#tool.tip()[
  یک Classifier محدود به یک Model نیست.
]

== VC-Dimension
#tool.double_section()[
  #tool.question()[
    فرض کنید کلاً یک نمونه مثبت داریم.
    با چه چیزی جداسازی را انجام می دهیم؟
  ]
][
  #tool.true_answer()[
    هیچ چیز.
    چون همه چیز مثبت است.
    #v(1.6em)
  ]
]

#tool.double_section()[
  #tool.question()[
    فرض کنید کلاً ۲ نمونه مثبت داریم.
    با چه چیزی جداسازی را انجام می دهیم؟
  ]
][
  #tool.true_answer()[
    هیچ چیز.
    چون همه چیز مثبت است.
    #v(1.6em)
  ]
]

#tool.double_section()[
  #tool.question()[
    فرض کنید کلاً ۲ نمونه داریم که یکی مثبت و دیگری منفی است.
    با چه چیزی جداسازی را انجام می دهیم؟
  ]
][
  #tool.true_answer()[
    با چیز های زیادی از جمله مستطیل، دایره، مثلث و ... اما ساده ترین شکل ممکن برای آن، خط است.
  ]
]

#tool.double_section()[
  #tool.tip()[
    اولین قاعده در یادگیری ماشین این است که مسأله ای که می خواهیم حل کنیم با ساده ترین مدل ممکن حل کنیم.
  ]
][
  #tool.question()[
    فرض کنید کلاً ۳ نمونه داریم که یکی مثبت و دو مورد دیگر منفی است (و یا بر عکس).
    با چه چیزی جداسازی را انجام می دهیم؟
  ]
]

#tool.true_answer()[
  با یک خط می توان جدا سازی را انجام داد.
]

#tool.double_section()[
  #tool.question()[
    فرض کنید کلاً ۴ نمونه داریم که غیر واقع بر یک خط راست هستند که دو مورد آن ها مثبت و دو مورد دیگر منفی هستند (و یا بر عکس).
    با چه چیزی جداسازی را انجام می دهیم؟
  ]
][
  #tool.true_answer()[
    نمی توان ۴ نقطه ای را پیدا کرد که یک خط بتواند همه جور برچسب زنی هایش را جدا کند.
    #v(3.2em)
  ]
]

#tool.double_section()[
  #tool.definition()[
    VC-Dimension یک Model: حداکثر تعداد نمونه هایی که مدل همه نوع برچسب گذاری آن ها را به درستی تفکیک می کند.
  ]
][
  #tool.example()[
    VC-Dimension یک خط برابر است با ۳.
    چرا که اگر بیش از ۳ نقطه داشته باشیم احتمال این که خط اشتباه کند وجود دارد.
  ]
]

#tool.double_section()[
  #tool.example()[
    VC-Dimension دو خط برابر است با ۵.
    چرا که اگر بیش از ۵ نقطه داشته باشیم احتمال این که دو خط اشتباه کنند وجود دارد.
  ]
][
  #tool.tip()[
    در یادگیری ماشین خطا اجتناب ناپذیر است.
    #v(3.2em)
  ]
]

#tool.double_section()[
  #tool.question()[
    مثال هایی وجود دارند که با وجود این که ۱۰۰۰ نمونه داریم به راحتی از یک خط استفاده می کنیم. چرا؟
    #v(1.6em)
  ]
][
  #tool.true_answer()[
    بنا به اصل پیوستگی انتظار چینش های عجیب و غریب نداریم و جاهایی که خط نمی تواند جدا کند حالت های بسیار خاص و بسیار نادر هستند.
  ]
]

#tool.tip()[
  تعداد نمونه های آموزشی مورد نیاز برای این که مدل خوب یاد بگیرد به لگاریتم معکوس خطا ربط دارد:
  $ N space alpha space log(1 / "error") $
  $N$ تعداد نمونه های آموزشی می باشد.
]

= جلسه پنجم
#tool.simple_context()[
  اگر با هر الگوریتم دلخواه h را یادگیری بکنیم، بر اساس این که Hypothesis ما چه مقدار از C را پوشش می دهد، می توان کیفیت مدل را بررسی کرد.
]

#tool.reminder()[
  #tool.custom_figure(
    image("images/ML/05_01.png"),
    caption: "یادآوری از جلسه قبل.",
    inset: 1em,
  )
]

#tool.reminder()[
  #text(dir: ltr)[
    ML Elements:
    + Examples
    + Model
    + Training Algorithm
  ]
]

== S, G and Version Space
#tool.definition()[
  در جلسات قبل یک مدل از نمونه های مثبت (S در شکل زیر) و یک مدل از نمونه های منفی (G در تصویر زیر) ساختیم که در شکل زیر آمده اند:
  #tool.custom_figure(
    image("images/ML/05_02.png"),
    caption: [به مدل S، #box[Most specific hypothesis] و به مدل G، #box[Most general hypothesis] می گویند.],
    inset: 1em,
  )
  S کوچکترین Hypothesis سازگار با نمونه های آموزشی و G بزرگترین Hypothesis سازگار با نمونه های آموزشی می باشد.
  در شکل بالا هر مستطیلی که بین S و G باشد، جزو مجموعه جواب های ما است.

]

#tool.double_section()[
  #tool.definition()[
    Version Space: به فضایی که از S شروع و به G ختم می شود، که همان مجموعه جواب های بین S و G است، می گوییم #box[Version Space] می گویند.
  ]
][
  #tool.definition()[
    مسائل خوش ریخت: مسائلی که دانسته های مسأله برای تعیین جواب دقیق کافی است.
    #v(1.6em)
  ]
]

#tool.double_section()[
  #tool.definition()[
    مسائل بد ریخت: مسائلی که دانسته های مسأله برای تعیین جواب دقیق کافی نیست.
    در این مسائل، تعداد معادله ها از تعداد مجهول ها کمتر است.
    #v(1.6em)
  ]
][
  #tool.tip()[
    یادگیری (ماشین) یک مسأله بد ریخت (ill-posed problem) می باشد.
    مثلاً در شکل پیشین بی نهایت مستطیل به عنوان جواب بین S و G وجود دارد و مسأله آن یک مسأله ill-posed می باشد.
  ]
]

#tool.tip()[
  نمونه های بیشتر در فرآیند یادگیری مسأله را به سمت well-posed بودن می برد.
  #v(1.6em)
]

== انتخاب از درون Version Space
#tool.question()[
  در شکل پیشین از S تا G کدام مستطیل را اتنخاب کنیم؟
  (می خواهیم یک مورد از درون Version Space را انتخاب کنیم).
]

#tool.true_answer(pause: true)[
  1. می توان وسط آن را انتخاب کرد که این روش بر مبنای فرض Max Margin می باشد.
]

#tool.example()[
  با توجه به شکل زیر، فرض کنید نیاز های خانواده ها برای ماشین تغییر کند. این باعث می شود که تعریف ماشین خانواده کمی دچار تفاوت شود.
  مثلاً از این به بعد ماشین های خانواده نیاز است فضایی برای قرار دادن ماهواره برای اینترنت ماهواره ای داشته باشند.

  #tool.custom_figure(
    image("images/ML/05_03.png"),
    caption: "قاعده Max Margin",
    inset: 1em,
  )

  بنابراین برای آن که مدل مان به تغییرات کوچک حساس نشود، مستطیلی را انتخاب می کنیم که با هر دو مستطیل S و G، مرز زیادی داشته باشد.
]

#tool.true_answer(continuation: true)[
  2. اگر مسأله طوری است که در آن مثلاً بیشترین ماشین ممکن را باید در گردونه ماشین های خانواده قرار دهیم، آن گاه باید طوری عمل کنیم که h به G نزدیکتر شود.

  3. اگر مسأله طوری است که در آن مثلاً ماشین خانواده یک چیز مشخص و معینی است، آن گاه باید طوری عمل کنیم که ماشین هایی که تفاوت کوچکی با مشخصات تعریف شده دارند، در دسته ماشین خانواده قرار نگیرند.
    در این حالت سعی می شود h به S نزدیک شود.
]

#tool.simple_context()[
  بعضی وقت ها برای انتخاب یک مورد از Version Space راهنمایی هایی همچون بالا را نداریم.
  در این صورت از قاعده کلی زیر (که می توان به دو صورت آن را پیاده سازی کرد) استفاده می شود.
]

#tool.definition(pause: true)[
  قاعده کلی انتخاب یک مورد از Version Space: معمولاً اگر از تعدادی Domain Expert که IID هستند (از هم مستقل هستند و با احتمال یکسان به طور تصادفی انتخاب می شوند)، سؤال بپرسیم، آنگاه رأی اکثریت به واقعیت نزدیک تر است.

  به دو صورت زیر این قاعده را با توجه به مثال شکل پیشین پیاده سازی می کنیم:

  می خواهیم مستطیلی را به صورت تصادفی بین S و G انتخاب کنیم. چگونه این کار را انجام می دهیم؟
  ۴ نقطه تصادفی بین S و G را به شکل زیر انتخاب می کنیم:
  #tool.custom_figure(
    image("images/ML/05_04.png", width: 77%),
    caption: "مختصات ۴ نقطه درون ۴ بازه بالا که بین S و G هستند، به صورت تصادفی ساخته می شود.",
    inset: 1em,
  )
  از آن جایی که مستطیل مورد نظر بین مستطیل S و G می باشد، با نمونه های آموزشی مان سازگار است.
  دقت شود که در مثال بالا S و G از نمونه ها و h بین این دو به صورت تصادفی ساخته می شود.
]

#tool.question()[
  در روش بالا، چند مستطیل تصادفی باید بسازیم؟
]

#tool.true_answer()[
  $ N >= 33 $
  یعنی حداقل ۳۳ عدد.
  به دلیل قضیه حد مرکزی این عدد انتخاب می شود.
  حداقل تعداد نمونه های لازم در نمونه برداری از توزیع نرمال برای آن که توزیع به دست آمده از نمونه ها توزیع درستی باشد، ۳۳ (در اصل ۳۲ ولی در اینجا همان ۳۳ را در نظر بگیرید) عدد است.

  بنابراین از میان S و G (که همان Version Space مان است) N عدد مستطیل به صورت تصادفی انتخاب می کنیم.

  (برای فهم آنکه چرا N باید حداقل ۳۳ باشد به Normal Distribution Estimation و Central Limit Theorem مطالعه شود.)
]

#tool.definition(continuation: true)[
  پس از انتخاب N مستطیل به صورت توضیح داده شده، الگوریتم Voting را اجرا می کنیم.
  به این صورت که وقتی نمونه جدیدی به ما داده شود، Label آن Label ای است که اکثریت این N مستطیل اعلام می کنند.
]

#tool.tip()[
  قاعده Max Margin در کنار خوبی ای که دارد، دو عیب زیر را دارد:
  + باید بتوانیم برای هر Classifier، #box[Margin] را حساب کرد.
    این در حالی است که برای خیلی از Classifier ها به راحتی نمی توان Margin را حساب کرد.
  + این روش همیشه به ما کمک نمی کند.
    به این صورت که بعضی وقت ها یک Class مهم تر از یک Class دیگر است و باید Margin را کمی به این طرف و آن طرف هول داد.
]

== تقلید در یادگیری ماشین
#tool.tip()[
  در یادگیری ماشین با پشت صحنه پدیده ها کاری نداریم.
  بلکه با نمایش بیرونی آن ها کار داریم.
]

#tool.tip()[
  در یادگیری ماشین در اغلب اوقات برای ما مهم نیست که فرضیه ای که درباره موضوع مورد نظر می سازیم چقدر درست و چقدر غلط است.
  بلکه این مهم است که آن فرضیه چقدر مشاهدات ما را خوب توضیح می دهد.
]

#tool.example()[
  در زمان قدیم این فرضیه وجود داشت که زمین صاف است چرا که با استفاده از این فرضیه می توانستند شب و روز را مدل کنند، تقویم بسازند و جهت یابی کنند.
  بعداً مردم متوجه شدند که این فرضیه اشتباه است اما چیزی که باعث شد این فرضیه تا مدت ها پابرجا بماند این بود که برای مردم آن زمان کار می کرد و نیازشان را برطرف می کرد.
]

#tool.definition()[
  Digital Twin: برنامه ای کامپیوتری است که تلاش می کند رفتار یک سیستم واقعی را تقلید کند.

  #tool.custom_figure(
    image("images/ML/05_05.png", width: 62%),
    caption: "Digital Twin سعی می کند رفتار Real System را تقلید کند.",
    inset: 1em,
  )

  دقت شود که درون Real System و Digital Twin لزوماً مانند یکدیگر نیست اما ورودی و خروجی یکسانی دارند.

  یکی از کاربرد های Digital Twin زمانی است که Real System گران قیمتی داریم و نمی توانیم هر کاری را با آن انجام دهیم.
]

== PAC Learning
#tool.definition()[
  #tool.custom_figure(
    image("images/ML/05_06.png"),
    caption: "Probably Approximately Correct (PAC) Learning",
    inset: 1em,
  )
  فرض کنید C همان مفهومی است که واقعا وجود دارد و مساحت آن ۱ است.
  ما می خواهیم h را بسازیم.

  طبق شکل بالا خطای h شامل ۴ قسمت بالا، پایین، چپ و راستی است که بیرون از h و درون C قرار دارند.
  خطای h را $epsilon$ در نظر می گیریم.
  فرض کنیم مساحت ناحیه خطای شکل بالا $epsilon$ است و مساحت ۴ ناحیه با هم برابر است هر چند که اندازه شان متفاوت است.
  به این ترتیب مساحت هر یک از آن ها $epsilon \/ 4$ می باشد.

  احتمال این که یکی از ۴ نوار بالا به درون h بیافتد به صورت زیر است:
  $ 1 - epsilon / 4 $
  اگر N نمونه جدید پشت سر هم انتخاب کنیم، احتمال آن که همه این N نمونه از یک نوار خاص به درون h بیافتند، به صورت زیر است: $ (1 - epsilon / 4)^N arrow "Because samples are IID" $

  اگر N نمونه جدید پشت سر هم انتخاب کنیم، احتمال آن که همه این N نمونه از ۴ نوار به درون h بیافتاند، به صورت زیر است: $ 4 (1 - epsilon / 4)^N $

  احتمال بد شانسی را $delta$ در نظر می گیریم.
  اگر بخواهیم احتمال بد شانسی از یک $delta$ ای کمتر باشد، از رابطه زیر استفاده می کنیم:
  $ 4 (1 - epsilon / 4)^N <= delta $
  $delta$ کمیتی است که خودمان انتخاب می کنیم.
  مثلاً می خواهیم احتمال بد شانسی کمتر از ۰/۰۱ باشد.

  در ادامه به رابطه های آخر شکل بالا می رسیم که رابطه نهایی آن شکل، در زیر آورده شده است:

  $ N >= (4 / epsilon) log(4 / delta) $

  رابطه بالا تعیین می کند که برای یادگیری مستطیل سازگار با نمونه های آموزشی، باید حداقل چه تعداد نمونه داشته باشیم.

  به این تحلیل تئوریک، Probably Approximately Correct (PAC) Learning می گویند.

  $epsilon$: خطای نمونه

  $delta$: احتمال یادگیری مدل با استفاده از N نمونه آموزشی که خطای آن از $epsilon$ بیشتر باشد. $arrow.l$ احتمال بد شانسی
]

#tool.tip()[
  PAC Learning تکنیکی است برای تعیین حداقل تعداد نمونه های آموزشی برای آن که مدل خوب یاد گرفته شود و احتمال بد شانسی کم شود.
]

#tool.list()[
  در تکنیک PAC Learning دو مورد را مشخص می کنیم:
  + $epsilon$ (خطای قابل تحمل)
  + $delta$
  که در پاسخ، حداقل تعداد نمونه های آموزشی به دست می آید.
]

#tool.tip()[
  تحلیل هایی که در آن ها می خواهیم یک Boundry یا بازه را پیدا کنیم، اهمیت ندارند که دقیق باشند.
  این گونه تحلیل ها را تحلیل بد بینانه (Pessimistic) می گویند.
]

== مدل های یادگیری ماشین
#tool.double_section()[
  #tool.question()[
    چه مدلی بهتر است؟
    #v(3.6em)
  ]
][
  #tool.true_answer()[
    خبر بد:
    کسی نمی داند.

    خبر خوب:
    مجموعه ای از مدل های خوب برای مسائل عام شناسایی شدند.
  ]
]


#tool.tip()[
  مسأله ای که با یک مدل ساده تر حل می شود را با مدل پیچیده حل نمی کنند، چرا که:
  #tool.double_section()[
    + استفاده از آن ساده تر است.
    + Train کردن آن راحت تر است.
  ][
    3. توضیح دادن آن راحت تر است.
    + بهتر تعمیم می یابد.
  ]

  #tool.custom_figure(
    image("images/ML/05_07.png", width: 86%),
    caption: "دلایل استفاده از مدل ساده تر",
    inset: 1em,
  )
]

#tool.list()[
  Classifier Models:
  + Basic Classifier: مدل هایی که با یک رابطه ریاضی یا یک ساختمان داده قابل توصیف اند.
    مانند:

    #text(dir: ltr)[Line, Polynomial, Decision Tree, Naive Bayes, Axis Aligned Rectangle, #sym.dots]
  + Ensemble Models (مدل های مرکب):
    مدل هایی هستند که چندین Basic Model درون خود دارند.
    مانند یک خط با یک مستطیل و یا مانند مثالی که مستطیل S و G را داشتیم و تعدادی مستطیل بین آن ها به طور تصادفی انتخاب کردیم و هنگام تولید Label از آن ها رأی گیری کردیم.
  + Neural Network & Deep Models: (فکر کنم یک جور هایی در هر دو گروه بالا می توانند قرار بگیرند)
]

=== Ensemble Models
#tool.example()[
  نمونه ای دیگر از یک Ensemble Model:

  می خواهیم دو گروه مثبت و منفی را از یکدیگر جدا کنیم که در شکل زیر آمده اند:
  #tool.custom_figure(
    image("images/ML/05_08.png", width: 90%),
    caption: "جدا سازی دو گروه به کمک یک Ensemble Model",
    inset: 1em,
  )

  این کار در مراحل زیر انجام می گیرد:
  + جمع آوری نمونه ها #sym.arrow.l نمونه های مثبت و منفی
  + انتخاب مدل #sym.arrow.l خط
  + آموزش مدل #sym.arrow.l با کمک الگوریتم عمود منصف

  در این مثال الگوریتم یادگیری مورد استفاده الگوریتم عمود منصف است.
  این الگوریتم به این صورت کار می کند که مرکز جرم نمونه های مثبت و نمونه های منفی را پیدا کرده، سپس یک پاره خط که دو سر آن همان مرکز این دو گروه می باشد رسم می کنیم.
  عمود منصف این پاره خط، خطی است که این دو گروه را از یک دیگر جدا می کند.


  حال می خواهیم Ensemble ای از درخت های تصمیم بسازیم.
  این کار به این شکل انجام می شود که چندین بار از هر گروه تعدادی نمونه انتخاب کرده و مرکز آن نمونه ها را در هر گروه پیدا می کنیم.
  در ادامه طبق الگوریتم عمود منصف، خط جدا کننده این دو گروه پیدا می شود.
  در نهایت چندین خط جدا کننده به این روش تولید خواهند شد.
]

= جلسه ششم
== Probabilistic Classifiers
#tool.tip()[
  در این طبقه بند ها ما اطلاعی نداریم که نمونه به کدام کلاس تعلق دارد اما سعی می کنیم بر اساس شواهدی آن را به کلاسی تخصیص دهیم.
]

#tool.double_section()[
  #tool.question()[
    اگر یک تاس ساده را بیاندازیم، احتمال آن که عدد ۳ بیاید چقدر است؟
  ]
][
  #tool.true_answer()[
    #v(0.9em)
    #align(center)[
      $display(1 / 6)$
    ]
    #v(0.57em)
  ]
]

#tool.double_section()[
  #tool.question()[
    اگر یک تاس ساده را بیاندازیم و بدانیم که عددی فرد آمده است، احتمال آن که مقدار آن ۳ باشد چقدر است؟
  ]
][
  #tool.true_answer()[
    #v(1.73em)
    #align(center)[
      $display(1 / 3)$
    ]
    #v(1.35em)
  ]
]

#tool.double_section()[
  #tool.tip()[
    در مواقعی دانسته هایی داریم که ما را در رسیدن به احتمال مورد نظر کمک می کنند و آن را کمتر یا بیشتر می کنند.
  ]
][
  #tool.definition()[
    Evidence (مشاهده): چیزی است که ذهنیت ما را به یک سمت می برد.
    #v(1.6em)
  ]
]

#tool.double_section()[
  #tool.question()[
    فردی وارد کلاس می شود.
    احتمال آن که اهل فرانسه باشد و احتمال آن که اهل ایران باشد چقدر است؟
    #v(3.2em)
  ]
][
  #tool.true_answer()[
    احتمال زیاد ایرانی است چرا که ذهن ما به سمت حقیقتی Bias شده و آن این است که احتمال دیدن شخصی فرانسوی در این جا خیلی خیلی کمتر از احتمال دیدن شخصی ایرانی است.
  ]
]

#tool.tip()[
  بعضی اوقات بدون این که درباره Class یک نمونه اطلاعاتی داشته باشیم، ذهن ما سراغ دانش خاصی می رود.
]

=== Prior, Posterio and Marginal Probability
#tool.definition()[
  Prior Probability (احتمال پیشین): به اینکه بدون این که درباره موضوع مورد نظر Evidence خاصی داشته باشیم، ذهن ما به دلیل خاصی به یک جهت خاصی گرایش پیدا کرده است.

  به عبارتی دیگر احتمال Prior به احتمالی می گویند که بدون داشتن اطلاعاتی راجع به پیش آمد بیان می شود.
]

#tool.double_section()[
  #tool.definition()[
    Posterio Probability (احتمال پسین): احتمالی است که با داشتن اطلاعاتی راجع به پیش آمد بیان می شود.
    #v(3.2em)
  ]
][
  #tool.definition()[
    Marginal Probability (احتمال حاشیه ای): احتمال حاشیه ای به احتمال مشاهده یک مقدار خاص از یک متغیر، ادغام شده روی تمام مقادیر ممکن سایر متغیرها اشاره دارد.
  ]
]

#tool.double_section()[
  #tool.tip()[
    از Evidence به Probability می رسیم.
    #v(1.6em)
  ]
][
  #tool.example()[
    اگر بدانیم که بعد از انداختن تاس عددی که آمده فرد است، احتمال آمدن عدد ۳ بیشتر می شود.
  ]
]

#tool.definition()[
  در بسیاری از موارد
  $p(x)$
  را داریم که احتمال رخ دادن متغیر $x$ می باشد.
  برای نمونه در مثال تاس بدون داشتن دانش قبلی به صورت زیر است:
  $ p(1) = 1 / 6 = p(2) = dots = p(6) $

  اما مواردی وجود دارند که اطلاع قبلی ای در مورد موضوع مورد نظر داریم.
  این موارد به صورت احتمال شرطی بیان می شوند.
  این گونه احتمالات شبیه زیر بیان می شوند:
  $ "Likelihood" arrow p("evidence" | "class") $
  مانند زیر که $x$ را به یک کلاس مشروط کردیم:
  #text(size: 1em)[
    $ p(underbrace(x, "مشاهده") | x in underbrace({1, 3, 5}, "گروه یا کلاس")) = 1 / 3 $
  ]
]

#tool.tip()[
  Likelihood معمولا با یک Probability Density Function یا همان PDF بیان می شود.
  #h(10.5em) $p(x | c): "pdf"$
]

#tool.example(pause: true)[
  در یک آزمایش پزشکی، تعداد گلبول های سفید در واحد خون تعدادی آدم شمرده می شود.
  اگر بدن درگیر مهاجمی شده باشد، تعداد گلبول های سفید افزایش می یابد.

  #tool.custom_figure(
    image("images/ML/06_01.png"),
    caption: "تعداد گلبول های سفید در واحد خون و فراوانی افراد مرتبط با این تعداد گلبول سفید",
    inset: 1em,
  )

  #tool.custom_figure(
    image("images/ML/06_02.png"),
    caption: "تعداد گلبول های سفید در واحد خون و احتمال داشتن این تعداد از گلبول های سفید برای یک فرد با توجه به اینکه مریض است یا سالم است.",
    inset: 1em,
  )

  از آن جایی که این پدیده، پدیده ای پیوسته و طبیعی است، می توان آن را با یک توزیع نرمال مدل کرد.
  جمعیت بالا را خودمان نمونه گیری کردیم.

  پزشک با داشتن تعداد گلبول های سفید، می خواهد بداند احتمال بیمار بودن فرد چقدر است؟ یعنی مثلا:
  $ p("disease" | x = 15) $
]

=== Chain Rule of Probability
#tool.definition()[
  قاعده زنجیره احتمالات توأمان (Chain rule of probability):
  $ p(A, B) = p(A) times p(B | A) = p(B) times p(A | B) = p(B, A) $
  $ P(A, B, C) = p(A) times p(B | A) times p(C | A, B) $
  $
    \
    P(A, B, C, D) = p(A) times p(B | A) times p(C | A, B) times p(D | A, B, C)
  $
]

#tool.example(continuation: true)[
  #text(fill: red_color)[$C_1$] نمایانگر بیمار بودن و #text(fill: green_color)[$C_2$] نمایانگر سالم بودن است.

  $ p(x_1, C_1) = p(x) times p(C_1 | x) = p(C_1) times p(x | C_1) $

  همانطور که گفتیم پزشک می خواهد احتمال بیمار بودن فرد را بداند:
  $
    overbrace(p(C_1 | x), "Posterio") = (overbrace(p(C_1), "Prior") times overbrace(p(x | C_1), "Likelihood")) / (p( x ) = underbrace(p(x | C_1) + p(x | C_2), "Marginal probability of x"))
  $
  $p(C_1)$ یعنی احتمال بیمار بودن یک آدم در یک جمعیت، بدون اینکه Evidence ای داشته باشیم.

  $p(x)$ یعنی احتمال اینکه تعداد گلبول های سفید در یک جمعیت، مقدار $x$ باشد، بدون اینکه Evidence ای داشته باشیم.

  همچنین چون فقط $C_1$ و $C_2$ هستند که فضا را افراز می کنند، $p(x)$ را در مخرج معادله بالا برابر با مقدار زیر قرار دادیم:
  $ p(x) = p(x | C_1) + p(x | C_2) $
  که به آن Marginal probability مربوط به $x$ می گویند.
]

#tool.question()[
  شخصی با WBC = 14 به پزشک مراجعه کرده است.
  آیا بیمار است؟
]

#tool.true_answer()[
  برای این که پزشک بیمار بودن فرد را تشخیص دهد، مقدار دو احتمال زیر را حساب کرده و مقدار هر کدام که بیشتر بود یعنی فرد در آن وضعیت (سالم یا بیمار) قرار دارد.
  $ p("بیمار" | "wbc" = 14) space.quad , space.quad p("سالم" | "wbc" = 14) $

  بنابراین فرد در صورت زیر بیمار است:
  $
    \
    "Type of a preson" == "بیمار" "iff" p("بیمار" | "wbc" = 14) > p("سالم" | "wbc" = 14)
  $
]

=== Bayesian Learning
#tool.definition()[
  Bayesian Learning:
  $
    x in C_1 "iff" p(C_1 | x) > p(C_2 | x) \
    = (p(C_1) times p(x | C_1)) / cancel(p(x)) > (p(C_2) times p(x | C_2)) / cancel(p(x)) \
    = p(C_1) times p(x | C_1) > p(C_2) times p(x | C_2)
  $
]

#tool.question()[
  مقدار $p(C_1)$ را از کجا می آوریم و چقدر است؟
]

#tool.true_answer()[
  از Domain Knowledge می آوریم.

  در مسائل Machine Learning همان اول روی Train Data معادله زیر را اعمال کرده و با این معادله مقدار $p(C_1)$ را حساب می کنیم:
  $ p(C_1) = n(C_1) / (n(C_1) + n(C_2) = N) $
]

=== به دست آوردن $p(x | C_1)$ و $p(x | C_2)$
#tool.question()[
  مقدار $p(x | C_1)$ و $p(x | C_2)$ را چگونه به دست آوریم؟
]

#tool.true_answer()[
  این موارد نیز از روی Train Data، حساب می شوند.

  فرض کنید Train Data ای به شکل زیر داریم:
  #tool.custom_figure(
    caption: [Train Data ما دارای تعدادی m ویژگی و دو کلاس $C_1$ و $C_2$ است.],
    kind: table,
    inset: 1em,
  )[
    $#stack(
            v(2.5em),
            $"Number of rows" arrow.l N lr(\{, size: #21em)$,
        )
        #table(
            columns: 2,
            inset: 1em,
            stroke: black,
            align: center,
            $x_1 x_2 dots x_m$,
            $y$,
            line(),
            $C_1$,
            line(),
            $C_1$,
            $dots.v$,
            $dots.v$,
            line(),
            $C_1$,
            line(),
            $C_2$,
            line(),
            $C_2$,
            line(),
            $C_2$,
            line(),
            $C_2$
        )
        #stack(
            v(2.75em),
            $lr(}, size: #10em) C_1$,
            v(2em),
            $lr(}, size: #10em) C_2$,
        )$
  ]

  با استفاده از یک جدول احتمالاتی ساده $p(C_1)$ و $p(C_2)$ که در پاسخ سؤال قبلی فرمول آن آورده شد، به دست می آیند.

  $p(x | C_1)$ و $p(x | C_2)$ نیز به صورت یک Probability Distribution نوشته می شوند که معمولاً دو حالت دارد زیر را دارد:
  + Tabular: یعنی به صورت جدولی نوشته می شود.
    مانند جدول زیر:
    #tool.custom_figure(caption: "نمونه ای از نوشته شدن یک توزیع احتمالاتی به شکل جدول.", kind: table, inset: 1em)[
      #table(
        columns: 2,
        inset: 1em,
        stroke: black,
        align: center,
        $x$, $p(x)$,
        $1$, $0.1$,
        $2$, $0.002$,
        $dots.v$, $dots.v$,
        $100$, $0.0003$,
      )
    ]
  + PDF: یک تابع ریاضی می نویسیم که $x$ را به احتمالش نگاشت می کند.
    مثلاً برای خیلی از پدیده هایی که با آن ها سر و کار داریم، یک تابع توزیع احتمال نرمال می نویسیم.
    فرمول تابع توزیع نرمال برای $C_1$ به صورت زیر است:
    $ p(x | C_1): "Normal"(underbrace(mu_1, "Mean"), underbrace(sigma_1, "Standard deviation")) arrow.curve.b $
    $ p(x | C_1) = 1 / (sqrt(2 pi sigma_1^2)) e^display((-(x - mu_1)^2) / (2 sigma_1^2)) $
    $ mu_1 = (sum_display(x in C_1)x) / (n(C_1)) $
    $ sigma_1 = sqrt((sum_display(x in C_1)(x - mu_1)^2) / (N - 1)) $
]

#tool.tip()[
  برای توزیع های کوچک Tabular و برای توزیع های بزرگ PDF خوب است.
]

=== احتمال شرطی دو متغیره

#tool.question()[
  ۶ نمونه که هر یک، دو Feature دارند و در کل به دو کلاس تقسیم بندی می شوند، به شکل زیر داریم:
  #tool.custom_figure(
    image("images/ML/06_03.png", width: 77%),
    caption: "۶ نمونه داریم که به شکل بالا توزیع شده اند.",
    inset: 1em,
    refrence: <image_06_03>,
  )

  نمونه ای داریم که ویژگی های آن به صورت $x_1 = -1$ و $x_2 = 0$ است.
  این نمونه متعلق به کلاس $C_1$ است یا $C_2$؟
]

#tool.true_answer()[
  برای حل این مسأله هر دو احتمال زیر را حساب می کنیم:
  $
    \
    p(C_1 | < x_1 = -1, x_2 = 0 >) = space ? space.quarter , space.quarter p(C_2 | < x_1 = -1, x_2 = 0 >) = space ?
  $
  این مسأله را به کمک جدول حل می کنیم.
  ابتدا نمودار را به صورت جدول زیر در می آوریم:
  #tool.custom_figure(caption: [جدول مربوط به نمودار @image_06_03], kind: table, inset: 1em)[
    #table(
      columns: 3,
      inset: 1em,
      stroke: black,
      align: center,
      $x_1$, $x_2$, $y$,
      $-1$, $0$, $C_1$,
      $-1$, $-1$, $C_1$,
      $0$, $-1$, $C_1$,
      $1$, $0$, $C_2$,
      $1$, $1$, $C_2$,
      $0$, $1$, $C_2$,
    )
  ]

  سپس احتمالات شرطی (Posterio های) مربوط به $x_1$ را به صورت جدول زیر می نویسیم:
  #tool.custom_figure(caption: [احتمالات شرطی (Posterio های) مربوط به $x_1$], kind: table, inset: 1em)[
    #table(
      columns: 3,
      inset: 1em,
      stroke: black,
      align: center + horizon,
      $x_1$, $p(x_1 | C_1)$, $p(x_1 | C_2)$,
      $-1$, $display(2 / 3)$, $0$,
      $0$, $display(1 / 3)$, $display(1 / 3)$,
      $1$, $0$, $display(2 / 3)$,
    )
  ]

  برای $x_2$ نیز به همین صورت عمل می کنیم:
  #tool.custom_figure(caption: [احتمالات شرطی (Posterio های) مربوط به $x_2$], kind: table, inset: 1em)[
    #table(
      columns: 3,
      inset: 1em,
      stroke: black,
      align: center + horizon,
      $x_2$, $p(x_2 | C_1)$, $p(x_2 | C_2)$,
      $-1$, $display(2 / 3)$, $0$,
      $0$, $display(1 / 3)$, $display(1 / 3)$,
      $1$, $0$, $display(2 / 3)$,
    )
  ]

  همچنین خود Prior ها را نیز می نویسیم:
  $ p(C_1) = p(C_2) = 0.5 $

  فرض کنید برای تست از همان داده های Training استفاده می کنیم (در اینجا برای سادگی این کار را می کنیم و گرنه کار خوبی نیست).
  در ادامه جواب دو احتمال شرطی ای که در ابتدا آورده شدند را محاسبه می کنیم:
  $
    \
    p(C_1 | < x_1 = -1, x_2 = 0 >) = space ? space.quarter , space.quarter p(C_2 | < x_1 = -1, x_2 = 0 >) = space ?
  $

  به کمک قاعده بیز ساده (Naive Bayes Assumption) می توان احتمال های بالا را حساب کرد.
  این قاعده می گوید که فرض کنیم $x_1$ و $x_2$ از هم مستقل هستند.
  این قاعده برای احتمال های بالا به صورت زیر نوشته می شود:
  $ p(C_1 | < x_1 = -1, x_2 = 0 >) = \ p(C_1 | x_1 = -1) times p(C_1 | x_2 = 0) $

  از آن جایی که $p(x)$ مساوی است، به آن نیازی نداریم و مخرج کسر را حساب نمی کنیم.
  در ادامه به صورت زیر معادله بالا را حل می کنیم:
  $
    p(C_1 | < x_1 = -1, x_2 = 0 >) = \ p(C_1 | x_1 = -1) times p(C_1 | x_2 = 0) = \
    cancel(p(C_1)) times p(x_1 = -1 | C_1) times cancel(p(C_1)) times p(x_2 = 0 | C_1) = \ 2 / 3 times 1 / 3 = 2 / 9 arrow star star #text(dir: ltr)[Wins] star star
  $
  $
    p(C_2 | < x_1 = -1, x_2 = 0 >) = \ p(C_2 | x_1 = -1) times p(C_2 | x_2 = 0) = \
    cancel(p(C_2)) times p(x_1 = -1 | C_2) times cancel(p(C_2)) times p(x_2 = 0 | C_2) = \ 0 times 1 / 3 = 0
  $
]

=== ترتیب استفاده از Classifier ها
#tool.tip()[
  Naive Bayes طبقه بند خیلی ساده ای است.
  به همین دلیل به عنوان Baseline یا مبنای پایه برای محاسبات استفاده می شود.
  اگر Naive Bayes در حد ۶۰٪ یا ۷۰٪ خوب جواب داد، آن گاه سراغ روش های دیگر برای بهتر کردن مدل می رویم.

  باید بقیه روش هایی که بعد از Naive Bayes استفاده می کنیم از آن بهتر باشند به جز Random Assignment.
  یعنی عملکرد روش های مختلف و ترتیب به کار گیری آن ها (از چپ به راست) به شکل زیر است:
  #align(center)[
    Random Assignment < Naive Bayes < Other Methods
  ]

  روش Random Assignment به این صورت کار می کند که به صورت تصادفی به نمونه ها Label می زنیم.
  مثلاُ این روش در یک مسأله دو کلاسه دارای دقت ۵۰٪ است.
]

#tool.example()[
  مسأله ای درباره طبقه بندی زعفران داریم.
  زعفران ها در ۵ کلاس طبقه بندی می شوند:
  #grid(
    columns: (1fr, 1fr, 1fr, 1fr, 1fr),
    align: center,
    [1. عالی], [2. بسیار خوب], [3. خوب], [4. متوسط], [5. بد],
  )
  روش Random Assignment برای این مسأله دارای دقت ۲۰٪ است.
  یعنی احتمال این که کلاس نمونه ای درست تشخیص داده شود، ۲۰٪ است.
  در ادامه طبقه بند Naive Bayes می سازیم.
  اگر دقت Naive Bayes بالای ۲۰٪ شد، به سراغ حل مسأله با روش های یادگیری ماشین می رویم.
  چرا که تجربه نشان می دهد اگر Naive Bayes خیلی بهتر از Random Assignment کار نکرد، اول به Dataset مسأله مان باید شک کنیم و به این گمان بیافتیم که در یک جای مسأله اشتباهی کرده ایم.
]

= جلسه هفتم
#tool.reminder()[
  در جلسه قبل یاد گرفتیم که احتمال این که $x$ عضو کدام کلاس باشد به صورت زیر تعیین می شود:
  $ x in C_(i^*) , i^* = "argmax"_i p(C_i) p(x | C_i) $
  یعنی احتمال $P(C_i | x)$ را به ازای تمامی $i$ کلاسی که داریم حساب می کنیم.
  $x$ عضو کلاسی است که بیشترین مقدار را در این احتمال دارد.
  خود $P(C | x)$ نیز به صورت زیر محاسبه می شود:
  $
    underbrace(p(
      C | x
    ), "Posterior") = (overbrace(p(C), "Prior") overbrace(p(x | C), "Likelihood")) / underbrace(p(underbrace(x, "Evidence")), "Marginal probability of evidence")
  $
  لازم به ذکر است که اگر بخواهیم $P(C | x)$ را برای $C$ های مختلف با یکدیگر مقایسه کنیم، نیازی به دانستن $p(x)$ نیست.
  چرا که مقدار آن بین همه $P(C | x)$ ها مشترک است.
]

== حل احتمال شرطی با PDF
#tool.simple_context()[
  در این جلسه به نمونه ای از حل یک سؤال با استفاده از PDF می پردازیم.
]

#tool.question()[
  دو گروه آدم های سیگاری و غیر سیگاری داریم که هر یک از افراد این دو گروه بعد از مدتی پیاده روی خسته می شوند.
  فردی بعد از ۱۹ دقیقه خسته می شود.
  این فرد سیگاری است یا غیر سیگاری؟
]

#tool.true_answer(pause: true)[
  تعدادی نمونه به صورت جدول زیر تهیه می کنیم:
  #tool.custom_figure(
    caption: "نمونه هایی از میزان خسته شدن بعد از N دقیقه پیاده روی در افراد سیگاری و غیر سیگاری.",
    kind: table,
    inset: 1em,
  )[
    #table(
      columns: 4,
      inset: 1em,
      stroke: black,
      align: center,
      fill: (x, y) => if calc.even(x) {
        luma(230)
      },
      "Smokers", "Non-smokers", "Smokers", "Non-smokers",
      "10", "30", "10", "30",
      "5", "45", "11", "35",
      "12", "25", "9", "25",
      "13", "20", "5", "18",
      "15", "5", "7", "38",
    )
  ]

  گروه های مختلف داده ها توزیع های مرتبط با خودشان را دارند.
  \ \
]

#tool.list()[
  تعدادی از توزیع های پیوسته مربوط به Feature ها عبارتند از:
  + Uniform:
    در این توزیع، مقدار $p(x)$ به ازای تمامی $x$ ها یکسان است.
  #grid(columns: 3, gutter: 1em)[
    2. Gaussian
  ][
    3. Rayleigh
  ][
    4. Cauchy
  ]

  توزیعی به نام Poisson نیز وجود دارد که جزو توزیع های پر کاربرد گسسته است.
  توزیع Normal که نوع خاصی از توزیع Gaussian می باشد توزیعی ساده و محبوب است.
  در بحث های Epidemic ها توزیع Rayleigh بهتر از توزیع Normal عمل می کند.
]

#tool.true_answer(pause: true, continuation: true)[
  پس ما در اغلب اوقات فرض می کنیم که نمونه های ما از توزیع های مشخصی می آیند.
]

#tool.double_section()[
  #tool.example()[
    برای استفاده از یک توزیع، مثلاً توزیع نرمال، به صورت زیر عمل می کنیم:
    $ P(x | C_1) tilde N(mu_1, sigma_1) $
  ]
][
  #tool.tip()[
    هر کلاس می تواند توزیع مخصوص خود را داشته باشد.
    #v(2.2em)
  ]
]


#tool.simple_context()[
  در آمار بحثی به نام Stochastic Processes وجود دارد که یکی از محصولات آن Maximum Likelihood Estimation (MLE) می باشد.
  MLE یک نظریه است و در این درس ما از نتایج آن استفاده می کنیم.
]

#tool.definition()[
  بر اساس MLE اگر فرض کنیم Population یا Sample مان از یک توزیع نرمال آمده است، اگر Sample Size مان به صورت زیر باشد:

  $ |"Sample"| >= 33 $
  می توان گفت که:
  $
    mu &tilde.equiv hat(mu) = (sum_display(x in "Sample") x) / (|"Sample"|) \ sigma &tilde.equiv hat(sigma) = sqrt((sum_display(x in "Sample") (
      x - hat(mu)
    )^2) / (|"Sample"| - 1))
  $
  بر این اساس می توانیم در یک مسأله ای که دو کلاس داریم، میانگین و انحراف معیار هر یک از کلاس ها را حساب کرده و سپس بر اساس این میانگین و انحراف معیار بگوییم که هر نمونه ای به چه کلاسی تعلق دارد.
]

#tool.true_answer(continuation: true)[
  برای راحتی کار در این پاسخ تعداد نمونه ما کمتر از ۳۳ شد و گرنه طبق قاعده ای که توضیح داده شد باید حداقل ۳۳ نمونه تهیه می کردیم.

  در ادامه میانگین و انحراف معیار دو کلاس Smoker و Non-smoker را حساب می کنیم که مقدار آن ها در جدول زیر آمده است:
  #tool.custom_figure(caption: "میانگین و انحراف معیار مربوط به دو کلاس Smoker و Non-smoker", kind: table, inset: 1em)[
    #table(
      columns: 3,
      inset: 1em,
      stroke: black,
      align: center,
      "Class", $mu$, $sigma$,
      $C_1: "Smoker"$, "9.7", "3.13",
      $C_2: "Non-smoker"$, "27.1", "10.72",
    )
  ]

  در این سؤال فرض کردیم که توزیع داده های هر دو کلاس توزیع Gaussian است و بر همین اساس با استفاده از فرمول توزیع Gaussian می توانیم احتمال مربوط به $x$ را به صورت زیر حساب کنیم:
  $
    p("Smoker" | x = 19) &= (p("Smoker") times p(x = 19 | "Smoker")) / p(x) \
    p("Non-smoker" | x = 19) &= (p("Non-smoker") times p(x = 19 | "Non-smoker")) / p(x)
  $

  از آن جایی که از هر کلاس ۱۰ نمونه داریم پس احتمال پیشین آن ها یکسان است:
  $ p("Smoker") = p("Non-smoker") = 0.5 $

  از طرفی $p(x)$ نیز بین هر دو کلاس مشترک است و به این ترتیب فقط نیاز است که $p(x = 19 | "Smoker")$ و $p(x = 19 | "Non-smoker")$ را حساب کنیم.

  برای مثال $x$ در صورتی عضو کلاس Smoker است که رابطه زیر برقرار باشد:

  $ x in "Smoker" "iff" p("Smoker" | x) > p("Non-smoker" | x) $

  که با توجه به توضیحاتی که داده شد در نهایت به شکل زیر در می آید:
  $ p(x | "Smoker") > p(x | "Non-smoker") $

  فرمول تابع توزیع Gaussian به صورت زیر است:
  $
    p(x ; mu , sigma) = 1 / (sqrt(2 pi sigma^2)) e^display((-(x - mu)^2) / (2 sigma^2))
  $

  با استفاده از فرمول بالا مقدار دو احتمال زیر به دست می آید و از این دو احتمال نتیجه می گیریم که احتمال غیر سیگاری بودن فردی که پس از ۱۹ دقیقه خسته شود بیشتر از احتمال سیگاری بودنش است.

  $ p(x | "Non-smoker") = 0.028 > p(x | "Smoker") = 0.001 arrow x in "Non-smoker" $

]

== Approach, Model and Method
#tool.double_section()[
  #tool.definition()[
    Model: تابعی ریاضی است که تعدادی پارامتر دارد و توزیع داده یا مرز را معرفی می کند.

    Approach: رویکرد کلی یا روش کلی است.
  ]
][
  #tool.simple_context()[
    برای به دست آوردن خروجی یک مدل باید ابتدا مقدار پارامتر های آن را حساب کرد.
    این کار را با روش Maximum Likelihood Estimation انجام می دهیم.
    #v(0.4em)
  ]
]

#tool.double_section()[
  #tool.tip()[
    Approach یک فرآیند بالاسری است که در آن کار های مختلفی را انجام می دهیم.
    داخل هر تکه کار ممکن است از تعدادی Model و برای محاسبه پارامتر های Model از Method های خاصی استفاده کنیم.
    #v(1.2em)
  ]
][
  #tool.example()[
    Model #sym.arrow.l تابع توزیع Gaussian

    Method #sym.arrow.l روش محاسبه یا همان فرمول $mu$ و $sigma$

    Variable or Feature #sym.arrow.l $x$

    Approach #sym.arrow.curve.l #box[Bayesian Learning Approach]
  ]
]


=== Parametric and Non-parametric Models
#tool.definition()[
  Model ها دو نوع اند:
  + Parameteric Models: مدل هایی که تعداد پارامتر هایشان از قبل مشخص و ثابت است و ربطی به تعداد Train Data ندارند.
  + Non-parameteric Models: مدل هایی که تعداد پارامتر هایشان از قبل مشخص نیست و وابسته به Train Data است.
    مانند وقتی که مدل یا توزیع احتمال مان را به صورت جدولی نشان می دهیم.
]

#tool.double_section()[
  #tool.tip()[
    مدل های Non-parameteric نیز پارامتر دارند و اتفاقاً پارامتر های زیادی نسبت به مدل های Parameteric دارند اما چون تعداد پارامتر هایشان مشخص و ثابت نیست به آن ها Non-parametric می گویند.
  ]
][
  #tool.definition()[
    Latent: موضوعی که واقعا در پس یک پدیده رخ می دهد.

    Model: برداشت و تصویری که ما از روی Latent می سازیم و به کمک آن، Latent را شرح می دهیم.

    #v(1.2em)
  ]
]

#tool.double_section()[
  #tool.tip()[
    مدلی خوب است که بر اساس آن بتوانیم پیش بینی دقیق تری از Latent داشته باشیم.
    #v(4.8em)
  ]
][
  #tool.example()[
    بالا رفتن دلار دلایل مختلفی می تواند داشته باشد:
    + نزدیک شدن به کریسمس
    + Black Friday
    + تقدیم بودجه کشور و احتمال کسری بودجه
  ]
]


== Model Paramters Variance
#tool.example()[
  فرض کنید در سؤال پیاده روی به جای برداشتن ۱۰ نمونه برای کلاس Smokers، تنها ۳ نمونه بر می داریم. یعنی:
  $ "Sample Size" = 3 $
  این کار را چند سری انجام می دهیم.
  به این صورت که ابتدا ۳ نمونه اول (نمونه اول تا سوم)، سپس ۳ نمونه بعدی (نمونه دوم تا چهارم) و به همین ترتیب تا آخر نمونه گیری ۳ تایی را انجام می دهیم و برای هر دسته از این نمونه ها، میانگین شان را به دست می آوریم.
  این کار را برای حالت ۵ نمونه ای و ۷ نمونه ای نیز انجام می دهیم و در نهایت به اعداد زیر می رسیم. (فکر کنم عدد آخر در جدول که مقدارش ۷ هست رو برای حالت ۵ نمونه ای و ۷ نمونه ای حساب نمی کنیم):
  //TODO
  $
    3 "Instances" &arrow 9, 10, 13, 13, 12, 9, 8, 7 \
    5 "Instances" &arrow 11, 11, 12, 10, 8 \
    7 "Instances" &arrow 11, 10, 10
  $

  با نگاه به اعداد بالا متوجه می شویم که هرچه اندازه نمونه ها بیشتر شود، داده ها به یکدیگر نزدیک تر می شوند. یعنی تنوع آن ها کمتر می شود. تنوع نیز با واریانس نشان داده می شود.
]

#tool.tip()[
  ML Engineer مدل را می سازد و مشتری از آن استفاده می کند.
  مدل هایی خوب هستند که واریانس پایینی دارند چرا که باعث می شود که نتایجی که ML Engineer گرفته است را مشتری نیز بگیرد.
  واریانس نیز زمانی کمتر می شود که تعداد نمونه هایی که می گیریم بیشتر شوند.

  مثلاً برای توزیع نرمال به همین دلیل بود که گفتیم حداقل ۳۳ نمونه گیری باید انجام شود.
]

#tool.definition()[
  نوعی Variance برای تغییرات پارامتر های مدلی که می سازیم، وجود دارد.
  #tool.custom_figure(
    image("images/ML/07_01.png"),
    caption: [نمونه برداری هایی که از دامنه انجام می دهیم و در ادامه از آن ها برای Estimate کردن پارامتر های مدل استفاده می کنیم. $theta_1$ تا $theta_k$ پارامتر های مدل هستند.],
    inset: 1em,
  )
  اگر واریانس پارامتر های بالا بزرگ باشد نتیجه ای که ML Engineer و مشتری خواهند دید، متفاوت از یکدیگر خواهد بود.
]

#tool.tip()[
  Model Parameters Variance به دو مورد زیر ربط دارد:
  + Model
  + Sample Size
]

#tool.double_section()[
  #tool.tip()[
    با کمی سهل انگاری بزرگی مدل را معادل با تعداد پارامتر های آن در نظر می گیریم.
    مثلاً مدلی که ۵ پارامتر دارد بزرگ تر از مدلی است که ۳ پارامتر دارد یا شبکه عصبی ای که یک لایه دارد، کوچک تر از شبکه عصبی ای است که ۲۰ لایه دارد.
  ]
][
  #tool.tip()[
    وقتی مدل ما کوچک تر باشد نیاز به Sample Size کمتری خواهد بود تا به Variance مطلوب برسیم.
    مثلاً مدل Poisson نسبت به مدل Normal پارامتر کمتری دارد و کوچک تر است.
    #v(3.2em)
  ]
]

#tool.tip()[
  پیچیدگی مدل باید در حدی باشد که خطای آن قابل تحمل باشد.
  #tool.custom_figure(
    image("images/ML/07_02.png", width: 70%),
    caption: "مرز دو کلاس بالا به وسیله یک معادله درجه دو به خوبی مشخص می شود. اما اگر مدل ساده ای مثل یک خط استفاده کنیم، خطای مدل زیاد می شود.",
    inset: 1em,
  )
]

== Sample Size
#tool.tip()[
  برای کنترل واریانس پارامتر های مدل، ساده ترین مدلی که بتواند مسأله را به خوبی حل کند انتخاب کرده و سپس متناسب با آن مدل Sample Size درست را انتخاب می کنیم.
]

#tool.definition()[
  Sample Size مناسب برای Parameteric Model ها و Non-parameteric Model ها
  به صورت زیر است:
  + Parameteric Models:
    آماری ها جدول هایی تهیه کرده اند که در آن ها Sample Size مناسب برای هر توزیع، مشخص شده است.
  + Non-parameteric Models:
    قاعده ای سر انگشتی به صورت زیر تعریف شده است:
  $ 3 times "max"("parameters#", "features#") <= "Sample Size" \ <= 10 times "max"("parameters#", "features#") $
]

#tool.example()[
  مدل پارامتری ساده ای به صورت زیر داریم:
  $ theta_0 + theta_1 x_1 + theta_2 x_2 = 0 $
  تعداد Parameter و Feature های این مدل به صورت زیر است:
  $ "Parameters" = 3 space.quarter space.quarter space.quarter , space.quarter "Features" = 2 $
  ماکزیمم دو مقدار بالا عدد ۳ می باشد.
  بنابراین از هر کلاس باید حداقل ۹ نمونه داشته باشیم.
  یعنی برای یک مسأله دو کلاسه اگر بخواهیم یک خط را یاد بگیریم، برای آن که مطمئن شویم که خطی که ما پیدا می کنیم مشابه خطی است که دوست مان پیدا می کند، از هر کلاس باید حداقل ۹ نمونه داشته باشیم که یعنی مجموعاً ۱۸ نمونه باید داشته باشیم.
  #tool.custom_figure(
    image("images/ML/07_03.png", width: 50%),
    caption: "مدل خطی این مثال که در آن باید برای هر کلاسی حداقل ۹ نمونه وجود داشته باشد.",
    inset: 1em,
  )
]

= جلسه هشتم
== Estimation (تخمین)
#tool.simple_context()[
  سعی می کنیم با نمونه هایی که از جمعیت بر می داریم مقدار میانگین و واریانس جمعیت را حدس بزنیم.
  $
    hat(mu)_1 tilde.equiv mu #h(0.5em) , #h(0.5em) hat(sigma)_1 tilde.equiv sigma #h(2em) mu , sigma arrow "Latent" #h(0.5em) , #h(0.5em) hat(mu)_1 , hat(sigma)_1 arrow "Estimated"
  $

  $hat(mu)_1$ و $hat(sigma)_1$ میانگین و انحراف معیار مربوط به نمونه ها و $mu$ و $sigma$ میانگین و انحراف معیار مربوط به جمعیت (واقعی) هستند.
]

#tool.double_section()[
  #tool.simple_context()[
    از Maximum Likelihood برای Estimation استفاده می کنیم.
  ]
][
  #tool.tip()[
    نمونه یک مجموعه است و یک تک دانه نیست.
  ]
]

#tool.tip()[
  از یک جمعیت می توان به تعداد دلخواه نمونه برداری کرد و برای هر نمونه، $hat(mu)$ و $hat(sigma)$ آن را حساب کرد.
  زمانی نمونه برداری و Estimation خوب است که $hat(mu)$ و $hat(sigma)$ ها به $mu$ و $sigma$ نزدیک شوند.
]

#tool.question()[
  از کجا بفهمیم که $hat(mu)$ و $hat(sigma)$ ها به مقدار $mu$ و $sigma$ نزدیک اند؟
]

#tool.true_answer()[
  درست است که مقدار $mu$ و $sigma$ را نداریم اما Estimated ها ($hat(mu)_i$ و $hat(sigma)_i$ ها) را داریم.
  به این صورت که از $i$ عدد Sample ای که داریم $hat(mu)_i$ و $hat(sigma)_i$ ها را طی فرآیند Estimation به دست می آوریم.
  $
    <S_1, hat(mu)_1, hat(sigma)_1> \ <S_2, hat(mu)_2, hat(sigma)_2> \ <S_3, hat(mu)_3, hat(sigma)_3> \ dots.v \ <S_k, hat(mu)_k, hat(sigma)_k>
  $
  اگر Estimator ها و Sample ها خوب باشند، باید مقادیر $hat(mu)_i$ و $hat(sigma)_i$ ها به یکدیگر نزدیک باشند:
  $
    hat(mu)_1 tilde.equiv hat(mu)_2 tilde.equiv dots tilde.equiv hat(mu)_k #h(1em) , #h(1em) hat(sigma)_1 tilde.equiv hat(sigma)_2 tilde.equiv dots tilde.equiv hat(sigma)_k
  $
  چرا که اگر به یکدیگر نزدیک نباشند یعنی توزیع های مختلفی داریم و نمی دانیم کدام درست است.
]

#tool.tip()[
  برای ارزیابی خوب بودن Estimate، باید Variance مقادیر $hat(mu)_i$ و $hat(sigma)_i$ ها کم باشد. (با واریانس توزیع اشتباه گرفته نشود)
]

=== Estimator
#tool.definition()[
  Estimator: تکنیکی است که جمعیتی را می گیرد و پارامتر های مولد (پارامتر های مدل) آن جمعیت را Estimate (پیش بینی) می کند.
  $ "Estimator"("Population", "Model Parameters") = \ "Estimated Value of Model Paremeters" $
]

#tool.list()[
  برای Estimator ها دو کمیت رو به رو تعریف می شوند:
  ۱) Variance
  #box[۲) Bias]
]

#tool.example()[
  فرض کنید ترازویی داریم که به شکل زیر وزن کالا ها را به اشتباه نشان می دهد:
  #tool.custom_figure(caption: "وزن هایی که یک ترازو به اشتباه نشان می دهد.", kind: table, inset: 1em)[
    #table(
      columns: 2,
      inset: 1em,
      stroke: black,
      align: center,
      "وزن واقعی", "وزن نشان داده شده",
      "1", "3",
      "2", "5",
      "3", "7",
      "4", "9",
    )
  ]
  با نگاه به جدول بالا متوجه می شویم که وزنی که ترازو نشان می دهد، الگوی زیر را دارد:
  $ m arrow 2 m + 1 $

  در این حالت می گویند ترازو Bias (میل) دارد.
]

#tool.double_section()[
  #tool.tip()[
    Maximum Likelihood برای بسیاری از Estimation ها Unbiased است.
    به این صورت که سعی می کند هر پارامتر $hat(theta)$ ای را از روی جمعیت دست آورد به گونه ای که:
    $ hat(theta) tilde.equiv theta $
    #v(1.6em)
  ]
][
  #tool.tip()[
    اگر انحراف معیار را با فرمولی که توضیح داده شده حساب کنیم و از جمعیت تعداد زیادی نمونه برداریم، انحراف معیار نمونه به صورت زیر خواهد بود:
    $ hat(sigma) tilde.equiv N / (N - 1) sigma $
    #v(0.5em)
  ]
]

#tool.double_section()[
  #tool.tip()[
    Estimator هایی خوب اند که Unbiased باشند.
    #v(1.6em)
  ]
][
  #tool.tip()[
    بر روی MLE می توان متدی را تعریف کرد که Biased باشد یا Unbiased باشد.
  ]
]

#tool.simple_context()[
  در نمودار توزیع نرمال می توان از احتمال به مقدار عددی متناظر آن رسید.

  #tool.custom_figure(
    image("images/ML/08_01.png", width: 60%),
    caption: "از احتمال ۰/۰۷ به عدد متناظر آن می رسیم.",
    inset: 1em,
  )
]

//TODO: MAYBE SHOULD BE MOVED -> 31:53
#tool.tip()[
  Maximum Likelihood Estimation به ما می گوید که اگر میانگین جمعیت را برداریم به میانگین توزیع نزدیک خواهد بود.
]

#tool.example(pause: true)[
  فرض کنیم دو جعبه داریم که یکی مربوط به Smoker ها و دیگری مربوط به Non-smoker ها است.
  همچنین هر یک از آن ها توزیع نرمال مربوط به خود را دارند که با دیگری متفاوت است.
  اگر این توزیع نرمال ها را بر روی محور رسم کنیم، به شکل زیر می رسیم:

  #tool.custom_figure(
    image("images/ML/08_02.png", width: 81%),
    caption: "توزیع های دو کلاس Smoker و Non-smoker. محور x بیانگر تعداد دقیقه های پیاده روی است.",
    inset: 1em,
    refrence: <image_08_02>,
  )

  احتمال این که $x$ عضو کلاس $C_1$ باشد به صورت زیر است:
  $
    x in C_1 "iff" p(C_1 | x) > p(C_2 | x) arrow.curve.b \ (p(C_1) times p(x | C_1)) / p(x) > (p(C_2) times p( x | C_2 )) / p(x)
  $
  همچنین از مثال پیاده روی داشتیم که:
  $ p(C_1) tilde.equiv p(C_2) $
  بنابراین:
  $
    p(x | C_1) > p(x | C_2)
  $
  بر اساس فرضی که داشتیم، اگر به تعداد کافی نمونه برداری کنیم می توان فرض کرد که توزیع نمونه ها نیز نرمال است و از PDF توزیع نرمال استفاده کرد:
  $
    1 / (sqrt(2 pi) sigma_1) e^display((-(x - mu_1)^2) / (2 sigma_1^2)) > 1 / (sqrt(2 pi) sigma_2) e^display((-(
      x - mu_2
    )^2) / (2 sigma_2^2))
  $

  در فرمول بالا تنها $x$ است که مجهول است و $sigma$ و $mu$ ها را با استفاده از تکنیک های Estimation، می توان از روی داده ها به دست آورد.

  // فرض کنیم در مثال پیاده روی جلسه قبل توزیع کلاس Smoker از یک توزیع نرمال و کلاس Non-smoker از یک توزیع نرمال دیگر می آید.
]

#tool.tip()[
  Estimation به درد این می خورد که پارامتر های مورد نیاز را از روی داده ها به دست آورد.
]

#tool.example(continuation: true)[
  فرض کنید از خوش شانسی، انحراف معیار ها مثل هم است:
  $ sigma_1 tilde.equiv sigma_2 $
  آن گاه با لگاریتم گیری (بر مبنای $e$) از نامعادله ای که پیش تر آمد، به نامعادله زیر می رسیم:
  $ -(x - mu_1)^2 > -(x - mu_2)^2 arrow (x - mu_1)^2 < (x - mu_2)^2 arrow.curve.b \ |x - mu_1| < |x - mu_2| $

  بنابراین:
  $ x in C_1 "iff" |x - mu_1| < |x - mu_2| $

  در نامعادله بالا، $|x - mu_1|$ یعنی فاصله $x$ از $mu_1$.
  نکته جالب این است که بر اساس نامعادله بالا، دیگر کاری با توزیع ها نداریم و کافی است میانگین ها را به دست آوریم.

  مرز بین دو کلاس با توجه به این فرض که $x$ کوچک تر از $mu_2$ است (@image_08_02)، به صورت زیر تعیین می شود:
  $
    |x - mu_1| = |x - mu_2| arrow x - mu_1 = mu_2 - x arrow x = (mu_1 + mu_2) / 2
  $

  به این ترتیب بر اساس فرض هایمان به طبقه بند ساده ای که تنها بر اساس فاصله کار می کند می رسیم.
]

==== ارزیابی Estimator
#tool.double_section()[
  #tool.question()[
    آیا Classifier مان خوب است یا بد؟
  ]
][
  #tool.true_answer()[
    برای ارزیابی آن باید معیار تعریف کنیم.
  ]
]

#tool.definition()[
  Accuracy: معیاری برای ارزیابی مدل است که به صورت زیر تعریف می شود:
  $ "Accuracy" = (n_(1,1) + n_(2,2)) / (n_(1,1) + n_(1,2) + n_(2,1) + n_(2,2)) $
]

#tool.example()[
  فرض کنید داده های مثال پیاده روی را داریم و پس از آموزش مدل، می خواهیم آن را تست کنیم.
  پس از تست مدل، جدول زیر به دست می آید:

  #tool.custom_figure(
    caption: [۷ مورد برای کلاس $C_1$ و ۶ مورد برای کلاس $C_2$ درست تشخیص داده شده است. $n_(2,1)$ یعنی داده در اصل متعلق به کلاس ۲ بوده اما به اشتباه در کلاس ۱ طبقه بندی شده است. به این جدول، Confusion Matrix می گویند.],
    kind: table,
    inset: 1em,
  )[
    #table(
      columns: 3,
      inset: 1em,
      stroke: black,
      align: center,
      "", $C_1$, $C_2$,
      $C_1: 10$, $n_(1,1): 7$, $n_(1,2): 3$,
      $C_2: 10$, $n_(2,1): 4$, $n_(2,2): 6$,
    )
  ]
]

#tool.question()[
  فرض کنید توزیع داده ها نرمال است.
  اگر نمونه کوچک باشد و با آن پارامتر های مدل را بسازیم، به چه نتیجه ای می رسیم؟
]

#tool.true_answer()[
  وقتی اندازه نمونه به اندازه کافی بزرگ نباشد، پارامتر های مدل زیاد و متنوع می شوند (Variance آن ها زیاد می شود) و به شکل زیر می رسیم:
  #tool.custom_figure(
    image("images/ML/08_03.jpg"),
    caption: "توزیع های واقعی در پایین و توزیع هایی که از روی نمونه ها می سازیم، در بالای محور x رسم شده اند.",
  )
]

#tool.tip()[
  برای یک مسأله، مدل های مختلف پارامتر های مختلفی دارند و به این ترتیب Accuracy شان نیز با یکدیگر متفاوت است.
]

===== Variance of Accuracy (واریانس عملکردی)
#tool.definition()[
  Variance of Accuracy (واریانس عملکردی): وقتی تعداد زیادی مدل داریم که با Dataset های کوچک آموزش یافته اند، یعنی تعداد زیادی مدل با پارامتر های مختلف داریم که هر یک دقت مربوط به خودشان را دارند.
  به تنوعی که در این دقت ها وجود دارد، واریانس عملکردی می گویند.
]

#tool.example()[
  می خواهیم دو کلاس زیر را از یکدیگر جدا کنیم:
  #tool.custom_figure(
    image("images/ML/08_04.png", width: 60%),
    caption: "هیچ تک خطی پیدا نمی شود که این دو کلاس را از یکدیگر جدا کند و مسأله به مدلی پیچیده تر از یک خط (به یک سهمی) نیاز دارد.",
    inset: 1em,
  )
  مدل های تصویر بالا ($d_1$ تا $d_3$) در ارور $E_0$ مشترک اند که به آن Bias مدل می گویند:
  $
    \
    "Error"(d_1) , "Error"(d_2) , "Error"(d_3) = underbrace(E_0, "Bias") + "Minimum Achievable Error"
  $
  در این مثال، Bias محصول خط بودن مدل ها است.

]

#tool.definition()[
  Error به صورت رو به رو تعریف می شود:
  #h(2.7em)
  $"Error" = 1 - "Accuracy"$
]

#tool.definition()[
  Minimum Achievable Error: کمترین خطای ممکن برای هر مدل.
  مثلاً در مثال بالا، سهمی دارای Minimum Achievable Error صفر است.
]

#tool.tip()[
  مدل هایی خوب اند که Low Bias و Low Variance هستند.
  چرا که اگر پیچیدگی مدل را افزایش دهیم Bias آن کم می شود و تا یک جایی Variance اش متعادل می ماند اما از یک جایی به بعد، Bias کم و Variance زیاد می شود.
  مدل هایی خوب اند که Bias و Variance شان متعادل باشند.
]

#tool.tip()[
  Bias بالا و Variance بالا، دقت را تخریب می کنند و با یکدیگر Tradeoff دارند.
]

= جلسه نهم
#tool.reminder()[
  همان طور که در جلسه قبلی گفته شد، پارامتر های مدل را از روی نمونه هایی که از جمعیت بر می داریم، می سازیم.
  #tool.custom_figure(
    image("images/ML/09_01.png", width: 90%),
    caption: [نمونه های $S_1$ تا $S_N$ را از جمعیت انتخاب کرده و از روی آن ها پارامتر های $P_1$ تا $P_N$ را می سازیم.],
    inset: 1em,
  )
]
== Central Limit Theorem
#tool.definition()[
  قضیه حد مرکزی (Central Limit Theorem):
  اگر نمونه هایی که از جمعیت گرفته می شوند، IID باشند و به تعداد کافی زیاد باشند:
  $ N arrow infinity $
  آنگاه پارامتر های مدل، از یک توزیع نرمال پیروی می کنند:
  $ P_1, P_2, dots, P_N tilde N(mu_P, sigma_P) $
]

#tool.double_section()[
  #tool.tip()[
    در عمل، اگر:
    $ (N >= 33) $
    باشد، کافی است و بی نهایت بودن آن لزومی ندارد.
  ]
][
  // Is this true or false?
  #tool.tip()[
    در نمونه گیری فرقی نمی کند که از جمعیت نمونه گیری کنیم یا از یک ماشینی که رفتاری کاملاً IID دارد، نمونه گیری کنیم.
    #v(1em)
  ]
]

#tool.example()[
  فرض کنید دو مدل $M_1$ و $M_2$ را داریم.
  از جمعیتی دو بار نمونه گیری کرده و نام نمونه ها را $S_1$ و $S_2$ می گذاریم.
  برای تست مدل ها، $S_1$ را به هر دوی آن ها می دهیم.
  Accuracy مربوط به $M_1$ را $a_1$ و Accuracy مربوط به $M_2$ را $b_1$ می نامیم.
  همین فرآیند را برای $S_2$ تا $S_N$ تکرار می کنیم:
  $
    S_1 , S_2, dots, S_N cases(gap: #1em, M_1 arrow overbrace({a_1, a_2, a_3, dots, a_N}, display(N(mu_a, sigma_a))), M_2 arrow underbrace({b_1, b_2, b_3, dots, b_N}, display(N(mu_b, sigma_b))))
  $
  از آن جایی که تعداد زیادی نمونه ($N >= 33$) را به شکل IID انتخاب می کنیم و هیچ یک از دو مدل را تغییر نمی دهیم، بنابر قضیه حد مرکزی، توزیع های نرمالی به نام $N(mu_a, sigma_a)$ و $N(mu_b, sigma_b)$ خواهیم داشت.
]

#tool.tip()[
  فرض کنید مدل $M_1$ پارامتر های زیر را دارد:
  $ mu_a = 0.75, sigma_a = 0.01 $
  #tool.custom_figure(
    image("images/ML/09_02.png", width: 80%),
    caption: [فاصله اطمینان ۹۵٪ توزیع نرمال مربوط به داده های این مثال. فاصله اطمینان ۹۵٪ یک توزیع نرمال، از $mu - 2 sigma$ تا $mu + 2 sigma$ را شامل می شود.],
    inset: 1em,
    refrence: <image_09_02>,
  )
  اگر متوسط دقت مدل $M_2$ برابر با ۰/۷۸ باشد، یعنی در ۹۵٪ موارد دقت بهتری از مدل $M_1$ دارد. به عبارت دیگر $M_2$ به صورت معنی داری دقت بهتری نسبت به $M_1$، دارد:
  $ mu_b = 0.78 >= mu_a + 2 sigma_a arrow M_2 "Is significantly better than" M_1 $
]

#tool.double_section()[
  #tool.tip()[
    وقتی می گوییم رویدادی به صورت معنی داری رخ داده است، یعنی حتماً دلیلی پشت آن بوده و به صورت شانسی رخ نداده است.
  ]
][
  #tool.definition()[
    برای بررسی و مقایسه مدل ها، می توان از فاصله اطمینان دقت یا فاصله اطمینان یک معیار کارکردی دیگر مدل (خطای مدل و #sym.dots) استفاده کرد.
  ]
]

#tool.example()[
  فرض کنیم مدلی با میانگین دقت ۰/۷۵۵ داریم (@image_09_02).
  این مدل ظاهراً بهتر از مدل $M_1$ (با میانگین دقت ۰/۷۵) است اما چون میانگین دقت آن به میزان کمی از میانگین دقت $M_1$ بالاتر است نمی توان به صورت قطعی نظر داد و شاید به دلیل داده ای که به آن داده شده چنین نتیجه ای را برگردانده است.
]

#tool.double_section()[
  #tool.question()[
    وقتی می گوییم دقت مدلی ۰/۷۵ است چه معنایی دارد؟
    #v(3.2em)
  ]
][
  #tool.true_answer()[
    یعنی اگر تک نمونه ای به سیستم بدهیم، به احتمال ۰/۷۵ آن را درست و به احتمال ۰/۲۵ آن را اشتباه تشخیص خواهد داد.
  ]
]

#tool.example()[
  یک توزیع باینری ساده به صورت زیر داریم:

  سکه ای داریم که دو روی A و B دارد:
  #align(center)[
    #box()[
      #circle("A")
    ]
    #h(1em)
    #box()[
      #circle("B")
    ]
  ]

  احتمال رخ دادن هر یک از دو روی آن به صورت زیر است:
  $ cases(p(A) = 0.75, p(B) = 1 - 0.75 = 0.25) $

  اگر این آزمایش باینری را $N$ بار تکرار کنیم، $mu_A$ و $sigma_A$ آن به صورت زیر خواهند بود:
  $ mu_A = p , sigma_A = sqrt(p(1 - p) / N) $

  این به این درد می خورد که صرفاً با یک Test Set، فاصله اطمینان را حساب کنیم.
  به این صورت که داده ها به دو بخش Train و Test تقسیم می شوند.
  بخش Test برای تست و مقایسه مدل ها استفاده می شود.
]

== Proof of Concept
#tool.tip()[
  در آمار بحثی به نام آزمون فرضیه (Proof of Concept) وجود دارد.
  این آزمون برای این استفاده می شود که بخواهیم ببینم با انجام یک آزمایش تغییری معنادار در جامعه ایجاد می شود یا نه.
  Proof of Concept انواع آزمون ها را دارد.
  مانند: فاصله اطمینان.
]
#tool.example()[
  می خواهیم بدانیم آیا شکلات خوردن دانشجویان بعد از شام تأثیر مثبتی در یادگیری شان دارد یا خیر.
  فرض می گیریم که این کار مثلاً تأثیر مثبتی دارد.
  سپس برای دانستن این که فرض ما درست یا نه، آزمونی را به مدت یک ماه می گیریم به گونه ای که در آن یک ماه، هر شب بعد از شام به آن ها شکلات می دهیم.
  پس از پایان یک ماه نتیجه را بررسی کرده و به درستی یا نادرستی فرضیه مان می رسیم.
]

=== Small Sample Problem
#tool.definition()[
  در بسیاری از مسائل یادگیری ماشینی با مشکلی به نام Small Sample Problem رو به رو می شویم.
  این مشکل به این اشاره دارد که در همه مسائل نمی توان راحت نمونه آموزشی را به دست آورد.
  مثلاً بعضی آزمایش های پزشکی روی انسان.
]

#tool.example()[
  فرض کنید برای یک مسأله، ۴۰ نمونه داریم.
  اگر بخواهیم به این روش عمل کنیم که در آن ۷۰٪ نمونه ها برای آموزش و ۳۰٪ برای تست استفاده شوند، به مشکل می خوریم.
  چرا که ۲۸ نمونه برای آموزش خواهیم داشت و با این تعداد نمونه نمی توان به توزیع نرمالی رسید.

  یکی از روش هایی که با آن می توان نشان داد مدل ما مدل خوبی است، استفاده از Proof of Concept است.

  در این مثال، نمونه ها را به دو گروه ۳۹ تایی و ۱ تایی تقسیم می کنیم تا بتوانیم از خواص توزیع نرمال استفاده کنیم.
  ابتدا مدلی را با ۳۹ نمونه آموزش می دهیم.
  این مدل را $M_1$ می نامیم.
  سپس با ۱ نمونه ای که برای تست کنار گذاشتیم، $M_1$ را تست می کنیم.
  $M_1$ در جواب، به ما $hat(y)_1$ را می دهد.
  سپس دوباره ۴۰ نمونه را به دو گروه ۳۹ تایی و ۱ تایی تقسیم می کنیم.
  به این صورت که این بار دومین نمونه از مجموعه ۴۰ تایی را به عنوان تک نمونه تست انتخاب می کنیم.
  این کار را تا ۴۰ امین نمونه انجام می دهیم:
  $
    40 cases("Train": 39 #h(0.5em) arrow.long #h(0.5em) M_1 arrow hat(y)_1, "Test": 1 (x^(<1>)) arrow.curve.t)
    \
    40 cases("Train": 39 #h(0.5em) arrow.long #h(0.5em) M_2 arrow hat(y)_2, "Test": 1 (x^(<2>)) arrow.curve.t)
    \
    dots.v
    \
    40 cases("Train": 39 #h(0.5em) arrow.long #h(0.5em) M_40 arrow hat(y)_40, "Test": 1 (x^(<40>)) arrow.curve.t)
  $
  #place(
    dx: -2em,
    dy: -10.5em,
    $lr(\}, size: #8.5em) "Test Results"$,
  )
  در نهایت به ۴۰ عدد Test Result خواهیم رسید.
  دقت شود که در هر یک از ۴۰ مرحله این روش، مدل عوض می شود اما الگوریتم ثابت است.

  به این ترتیب هم ۴۰ عدد Test Result داریم و هم مدل ما با بیش از ۳۳ نمونه آموزش داده شد که در نتیجه برای این مدل می توان بازه اطمینان را حساب کرد.
]

=== K-fold Cross Validation
#tool.example()[
  فرض کنید در این مثال، همان کاری که در مثال قبل انجام دادیم را انجام می دهیم اما با این تفاوت که این بار ۴۰ نمونه را به ۸ بلوک ۵ تایی تقسیم می کنیم:
  #tool.custom_figure(
    caption: "تقسیم ۴۰ نمونه به ۸ بلوک ۵ تایی",
    kind: table,
    inset: 1em,
  )[
    #table(
      columns: 8,
      inset: 1em,
      stroke: black,
      align: center + horizon,
      fill: (x, y) => if calc.even(x) {
        luma(230)
      },
      $F_1$, "5", $F_3$, "5", $F_5$, "5", $F_7$, "5",
      $F_2$, "5", $F_4$, "5", $F_6$, "5", $F_8$, "5",
    )
  ]
  بلوک $F_1$ را برای تست و ۷ بلوک باقی مانده را برای آموزش مدل استفاده می کنیم:
  $ 40 cases(#text(dir: ltr)[$"Train": F_2, F_3, F_4, F_5, F_6, F_7, F_8$], "Test": F_1) $
  تفاوت این دو دسته بندی در این است که مدل در دسته بندی قبلی ۴۰ بار و در این دسته بندی ۸ بار آموزش می بیند.
  البته در عمل معمولاً Dataset را به ۱۰ یا ۵ قسمت تقسیم می کنند.
  به این روش K-fold Cross Validation می گویند.
  این روش برای مواقعی که نمونه های کمی داریم کاربرد دارد.
]

#tool.tip()[
  برای محاسبه پارامتر ها و نتایج طبقه بند ها باید اندازه نمونه ها بزرگ باشد.
  اگر اینطور نبود با تکنیک های مهندسی Test Set ای می سازیم که با آن بتوان رفتار مدل را مطالعه کرد و Confidence Interval آن را به دست آورد.
]

== بررسی انواع طبقه بند ها
=== Linear Regression
#tool.example()[
  در جلسه ششم، @image_06_03 در صورت سؤالی آورده شد.
  در این مثال از آن شکل مجدداً استفاده می کنیم:
  #tool.custom_figure(
    image("images/ML/06_03.png", width: 94%),
    caption: "شکل سؤال جلسه ششم که در آن ۶ نمونه داریم که در دو کلاس دسته بندی می شوند.",
    inset: 1em,
    refrence: <image_09_03>,
  )
  تعدادی نمونه داریم که در دو کلاس طبقه بندی می شوند.
  در این جا دو کلاس را به نام های ۰ و ۱ صدا می زنیم.

  فرض کنیم $y$ که بیانگر Label داده ها است، تابعی از $x$ ها است.
  $ y = f(x_0, x_1, x_2) $
  مثال ۱:
  $ y = w_0 x_0 + w_1 x_1 + w_2 x_2 $
  #tool.custom_figure(
    caption: [مقادیر تابع $y$ که از نمودار @image_09_03 به دست می آید.],
    kind: table,
    inset: 1em,
  )[
    #table(
      columns: 4,
      inset: 1em,
      stroke: black,
      align: center + horizon,
      $x_0$, $x_1$, $x_2$, $y$,
      "1", "-1", "-1", "0",
      "1", "-1", "0", "0",
      "1", "0", "-1", "0",
      "1", "0", "1", "1",
      "1", "1", "0", "1",
      "1", "1", "1", "1",
    )
  ]
  مثال ۲:
  $
    y = w_0 x_0 + w_1 x_1 + w_2 x_2 + w_3 x_1^2 + w_4 x_2^2 + w_5 x_1 x_2
  $

  در این حالت با تغییر متغیر آن را به یک تابع خطی تبدیل می کنیم:
  $
    \
    y &= w_0 underbrace(x_0, Z_0) + w_1 underbrace(x_1, Z_1) + w_2 underbrace(x_2, Z_2) + w_3 underbrace(x_1^2, Z_3) + w_4 underbrace(x_2^2, Z_4) + w_5 underbrace(x_1 x_2, Z_5) arrow.curve.b \
    y &= w_0 Z_0 + w_1 Z_1 + w_2 Z_2 + w_3 Z_3 + w_4 Z_4 + w_5 Z_5
  $

  #tool.custom_figure(
    caption: [مقادیر تابع $y$ که از نمودار @image_09_03 و تابعی از مقادیر $x_1$ و $x_2$ به دست می آید.],
    kind: table,
    inset: 1em,
  )[
    #table(
      columns: 7,
      inset: 1em,
      stroke: black,
      align: center + horizon,
      $Z_0$, $Z_1$, $Z_2$, $ Z_3 \ (= x_1^2) $, $ Z_4 \ (= x_2^2) $, $ Z_5 \ (= x_1 x_2) $, $y$,
      "1", "-1", "-1", "1", "1", "1", "0",
      "1", "-1", "0", "1", "0", "0", "0",
      "1", "0", "-1", "0", "1", "0", "0",
      "1", "0", "1", "0", "1", "0", "1",
      "1", "1", "0", "1", "0", "0", "1",
      "1", "1", "1", "1", "1", "1", "1",
    )
  ]
]

#tool.definition()[
  رگرسیون خطی (Linear Regression): به این کار که تابعی به شکل مثال قبل تعریف کنیم و بگوییم $y$ تابعی خطی از متغیر ها است، رگرسیون خطی می گویند.

  تابعی خطی به صورت زیر داریم:
  $
    y = w_0 x_0 + w_1 x_1 + w_2 x_2
  $
  شکل برداری این تابع برای $y^(<1>)$ تا $y^(<N>)$ به صورت زیر است:
  $
    y^(<1>) = mat(w_0, w_1, w_2) mat(x_0^(<1>); x_1^(<1>); x_2^(<1>)) \
    y^(<2>) = mat(w_0, w_1, w_2) mat(x_0^(<2>); x_1^(<2>); x_2^(<2>)) \
    y^(<3>) = mat(w_0, w_1, w_2) mat(x_0^(<3>); x_1^(<3>); x_2^(<3>)) \
    dots.v \
    y^(<N>) = mat(w_0, w_1, w_2) mat(x_0^(<N>); x_1^(<N>); x_2^(<N>)) \
  $
  مجموعه توابع بالا را می توان به صورت زیر نوشت:
  $
    \
    overbrace(mat(y^(<1>), y^(<2>), y^(<3>), dots, y^(<N>)), display(Y_(1 times N))) &= overbrace(mat(w_0, w_1, w_2), display(W_(1 times 3)))
    overbrace(mat(
    x_0^(<1>), x_0^(<2>), x_0^(<3>), dots, x_0^(<N>);
    x_1^(<1>), x_1^(<2>), x_1^(<3>), dots, x_1^(<N>);
    x_2^(<1>), x_2^(<2>), x_2^(<3>), dots, x_2^(<N>)
  ), display(X_(3 times N))) \
    Y &= W X \
  $
  در معادله بالا تنها $W$ است که مجهول است. حال برای به دست آوردن $W$ مراحل زیر را انجام می دهیم ($X^T$ ترانهاده $X$ است):
  $
    Y_(1 times N) X_(N times 3)^T = W_(1 times 3) (X X^T)_(3 times 3)
  $
  ماتریس $X X^T$ یک ماتریس $3 times 3$ می باشد. یعنی یک ماتریس مربعی است و به همین دلیل به احتمال بسیار زیاد معکوس دارد:
  $
    Y X^T (X X^T)^(-1) &= W overbrace((X X^T) (X X^T)^(-1), "Identity Matrix (I)")
  $
  به این ترتیب، مقدار $W$ برابر است با:
  $
    Y X^T (X X^T)^(-1) = W arrow.curve.b \ #block(stroke: (paint: green_color, dash: "densely-dash-dotted"), inset: 1em)[$W = Y X^T (X X^T)^(-1)$]
  $
  در مثال قبل، کلاس های ما شامل ۰ و ۱ بودند اما مقدار $W$ پیوسته است، به همین دلیل، معمولاً برای آن یک Cutoff می گذارند.
  به این صورت که اگر بالای ۰/۵ بود آن را ۱ و اگر زیر ۰/۵ بود آن را ۰ در نظر می گیریم.
]

#tool.double_section()[
  #tool.tip()[
    با توجه به بخش قبل،
    ماتریس زیر که با ضرب آن در ماتریس $X$، باعث می شود که اثر $X$ خنثی شود را شبه معکوس ماتریس $X$ می گویند:
    $
      #h(1em) X times overbrace(underbrace(X^T (X X^T)^(-1), "شبه معکوس"), "Pseudo-inverse") = I
    $
    به این دلیل می گوییم شبه معکوس، چون $X^T (X X^T)^(-1)$ یک ماتریس مربعی نیست.
  ]
][
  #tool.tip()[
    ماتریس همانی، ماتریسی با الگوی زیر است که ضرب آن در هر ماتریس $X$ ای، خود $X$ را بر می گرداند.
    #v(2.2em)
    $
      I =
      mat(
      1, 0, 0, dots, 0;
      0, 1, 0, dots, 0;
      0, 0, 1, dots, 0;
      dots.v, dots.v, dots.v, dots.down, 0;
      0, 0, 0, 0, 1;
    )
    $
    #v(2.2em)
  ]
]

= جلسه دهم
== روش تحلیلی حل معادلات رگرسیون خطی
<section_10_01>
#tool.reminder()[
  روشی تحلیلی برای حل معادلات رگرسیون خطی:
  $
    overbrace(Y, "True Labels") = overbrace(W, "Parameters") underbrace(X, "Features Values")
    \
    W = Y underbrace(X^T (X X^T)^(-1), "شبه معکوس X")
  $
]

== روشی دیگر برای حل معادلات رگرسیون خطی
#tool.definition()[
  فرض کنید معادله ای به شکل زیر داریم:
  $
    y^(<k>) = w_0 x_0^(<k>) + w_1 x_1^(<k>) + dots + w_n x_n^(<k>) = sum_(j=0)^n w_n x_n^(<k>)
  $
  آن گاه می توان تابع خطا را به شکل زیر تعریف کرد:
  $
    E_arrow(w) = sum_(k=1)^N (y^(<k>) - hat(y)^(<k>))^2 , arrow(w) = [w_0, w_1, dots, w_n]
  $
  $
    E = sum_(k=1)^N (y^(<k>) - sum_(j=0)^n w_j x_j^(<k>))^2
  $
  همانطور که مشاهده می شود، تابع بالا یک تابع درجه دو است که به این معناست که همواره $E >= 0$.
  حالت ایده آل این است که مینیمم این تابع را پیدا کنیم.
  مینیمم تابع هم با مشتق گرفتن از آن و برابر قرار دادنش با مقدار ۰ به دست می آید.
  در ادامه مشتق این تابع نسبت به $w_0$ را می گیریم:
  $
    (partial E) / (partial w_0) = sum_(k=1)^N 2 (y^(<k>) - sum_(j=0)^n w_j x_j^(<k>)) (-x_0^(<k>))
  $
  و آن را برابر با ۰ قرار می دهیم:
  $
    -2 sum_(k=1)^N (y^(<k>) - sum_(j=0)^n w_j x_j^(<k>)) x_0^(<k>) = 0
  $
  با ساده سازی معادله بالا، در نهایت تعدادی معادله برای $w_0$ تا $w_n$ به دست می آید.
]
=== خطای جمعی مجموعه ای از پارامتر های $w$
#tool.definition()[
  این خطا مستقل از تعداد نمونه ها است و رسیدن به مینیمم این خطا، به جای مشتق گرفتن و برابر ۰ قرار دادن، با روشی Iterative انجام می شود:
  $
    E_arrow(w) = 1 / (2 N) sum_(k=1)^N (y^(<k>) - sum_(j=0)^n w_j x_j^(<k>))^2
  $
]

#tool.tip()[
  حرکت در جهت مشتق یا حرکت در جهت گرادیان تابع، مقدار آن را بهبود می بخشد.
]

#tool.example()[
  در تصویر زیر، اگر از نقطه $x^(<4>)$ به سمت نقطه $x^(<4>) + epsilon f^' (x^(<4>)) $ حرکت کنیم:
  $
    x^(<4>) arrow x^(<4>) + epsilon f^' (x^(<4>)) arrow.curve.b
    \
    f(x^(<4>)) <= f(x^(<4>) + epsilon underbrace(f^' (x^(<4>)), > 0))
  $
  و برای نقطه $x^(<2>)$ نیز:
  $
    x^(<2>) + epsilon underbrace(f^' (x^(<2>)), < 0) < x^(<2>)
  $
  #tool.custom_figure(
    image("images/ML/10_01.jpg"),
    caption: [اگر به مقدار کمی $x^(<4>)$ را با مشتق آن جمع کنیم، حاصل جمع، بزرگتر از مقدار $x^(<4>)$ خواهد بود و اگر به مقدار کمی $x^(<2>)$ را با مشتق آن جمع کنیم، حاصل جمع، کوچک تر از مقدار $x^(<2>)$ خواهد بود.],
    inset: 1em,
  )
]

#tool.tip()[
  با توجه به مثال قبل، اگر مشتق مقداری مثبت باشد:

  اگر در جهت آن حرکت کنیم، به سمت ماکزیمم تابع و اگر در خلاف جهت آن حرکت کنیم، به سمت مینیمم تابع خواهیم رفت.
]

=== الگوریتم Gradient Descent
#tool.definition()[
  الگوریتم گرادیان کاهشی (Gradient Descent): الگوریتمی است Iterative که بر اساس مشتق تابع خطا کار می کند و مسیر حرکت به سمت نقطه مینیمم را تعیین می کند.
  اگر پارامتر تابع خطا، $w$ باشد، می توانیم از یک $w_0$ ای به صورت تصادفی شروع به حرکت کنیم.
  $
    E #h(0.5em) alpha #h(0.5em) w
  $
  قاعده به روز رسانی این الگوریتم به صورت زیر می باشد:
  $
    w^(<t+1>) = w^(<t>) - eta (partial E) / (partial w)
  $

  که در بالا $eta$ (اتا) همان سرعت یا نرخ یادگیری (Learning Rate) می باشد.

  #tool.custom_figure(
    image("images/ML/10_02.png", width: 70%),
    caption: [ابتدا $w$ ای را به صورت تصادفی انتخاب کرده، سپس مشتق آن را حساب می کنیم و بر اساس مثبت یا منفی بودن آن حرکت می کنیم.],
    inset: 1em,
  )

  $
    (partial E) / (partial w_j) = - 1 / N sum_(k=1)^N x_j^(<k>) ( y^(<k>) - overbrace(sum_(j=0)^N w_j x_j^(<k>), display(hat(y)^(<k>))) )
  $
  $
    (partial E) / (partial w_j) = - 1 / N sum_(k=1)^N x_j^(<k>) (y^(<k>) - hat(y)^(<k>))
  $
  $y^(<k>)$ مقدار واقعی مربوط به یک نمونه و $hat(y)^(<k>)$ مقداری است که برای آن حساب کردیم.
]

==== پیاده سازی الگوریتم Gradient Descent
#tool.definition()[
  پیاده سازی این الگوریتم به صورت زیر است:
  #tool.custom_figure(
    caption: "پیاده سازی الگوریتم Gradient Descent",
    kind: raw,
    inset: 1em,
  )[
    ```
    // Gradient Descent Algorithm
    function GD(Input: X, Y; Output: W) {
      m, n = size(X) // X_(m x n)
      iteration = 0, max_iteration = 1000
      [w_0, w_1, w_2, ..., w_n] = small random values

      Repeat {
        dw = [0, 0, ..., 0]_(1 x n), eta = 0.0001
        for k = 1 to m {
          // Calcualting x and w vectors' dot products
          // yhat is a scalar
          yhat = x^(<k>) . w
          dw = dw + x^(<k>) . (y^(<k>) - yhat)
        }
        dw = dw / m
        w = w + eta * dw
        iteration = iteration + 1
        // tau is the threshold
        // ||dw|| is the norm of dw
      } Until E(w) <= tau || iteration >= max_teration || ||dw|| >= epsilon
      return w
    }
    ```
  ]

  #tool.custom_figure(
    caption: [ابعاد ماتریس ورودی $X$ که با $m$ و $n$ نشان داده می شوند.],
    kind: table,
    inset: 1em,
  )[
    \
    #place(dx: 12.85em, dy: -1.7em, $n$)
    #v(0.5em)
    #place(dx: 12.7em, dy: -4.25em, $#rotate(90deg, $lr(\{, size: #9em)$)$)
    #table(
      columns: 4,
      inset: 1em,
      stroke: black,
      align: center + horizon,
      $x_0$, $x_1$, $x_2$, $y$,
      "", "", "", "",
      "", "", "", "",
      "", "", "", "",
    )
    #place(dx: 6.5em, dy: -7.5em, $m lr(\{, size: #8em)$)
  ]
]

==== خوبی ها و بدی های Gradient Descent
#tool.tip()[
  الگوریتم Gradient Descent برای رگرسیون خطی، بهترین نقطه ممکن را پیدا می کند.
]

#tool.list()[
  ایراد های الگوریتم Gradient Descent:
  + اندازه گام های آن متناسب با مشتق تعیین می شود.
  + الگوریتمی حریصانه است و لزوماً Global Minimum را پیدا نمی کند.
  + تابع خطای مدل که الگوریتم بر روی این تابع اجرا می شود، باید پیوسته و مشتق پذیر باشد.
]

#tool.example()[
  الگوریتم Gradient Descent را بر روی تابع خطایی به دو حالت شکل زیر می توان اعمال کرد:
  #tool.custom_figure(
    image("images/ML/10_03.png", width: 70%),
    caption: "الگوریتم Gradient Descent لزوماً Global Minimum را پیدا نمی کند چرا که وابسته به مکانی است که حرکت از آن شروع می شود.",
    inset: 1em,
  )
]

#tool.tip()[
  مشکل Local Minimum الگوریتم Gradient Descent را می توان با شروع دوباره آن، تا حدی حل کرد.
  چرا که هر بار از نقطه ای تصادفی شروع به حرکت می کند و در نهایت به بهترین Minimum ای که با N بار اجرای الگوریتم می توان به آن رسید، می رسد که در مواردی *ممکن است* همان Global Minimum باشد.
]

#tool.list()[
  روش های کم اثر کردن مسأله Local Minimum:
  + تست چندین نقطه شروع و انتخاب بهترین جواب Minimum بین آن ها.
  + الگوریتم مورد نظر را به رگرسیون خطی تبدیل کرده و Global Minimum را پیدا می کنیم.
]

#tool.comparision()[
  در مقایسه الگوریتم Gradient Descent و روشی که در @section_10_01[بخش] یادآوری شد، روش @section_10_01[بخش] روشی Deterministic است.
  چرا که زمان ضرب و جمع های این الگوریتم توسط CPU را تحت شرایطی می توان حساب کرد.
  اما روش Gradient Descent روشی Stochastic و Iterative می باشد و همگرایی آن وابسته به انتخاب پارامتر ها و مقدار تصادفی اولیه است.
  بنابراین الگوریتم Gradient Descent، زمان بر تر و پر هزینه تر از الگوریتم @section_10_01[بخش] است.
]

#tool.tip()[
  با وجود زمان بر تر و پر هزینه تر بودن الگوریتم Gradient Descent، به دلیل این که برای همه مدل ها و تابع خطاهایی که پیوسته و مشتق پذیر اند، قابل استفاده است، از آن استفاده می کنیم.
  البته حتی در صورتی که از تابع خطا به صورت مستقیم نتوان مشتق گرفت، مشتق عددی آن را حساب می کنیم.
  اما الگوریتم @section_10_01[بخش] برای رگرسیون خطی استفاده می شود.
]

#tool.tip()[
  به طور خلاصه الگوریتم Gradient Descent، الگوریتمی عمومی تر و قابل تعمیم تر است و برای هر نوع مدلی قابل استفاده است.
]

== Logistic Regression Model
#tool.reminder()[
  Linear Regression به صورت زیر تعریف می شد:
  $
    y^(<k>) = sum_(j=0)^n w_j x_j^(<k>)
  $
]

#tool.definition()[
  Logistic Regression به صورت زیر تعریف می شود:
  $
    y^(<k>) = 1 / (1 + e^display(-sum_(j=0)^n w_j x_j^(<k>)))
  $ <equation_10_14>
  در این مدل:
  $
    y^(<k>) in (0, 1)
  $
  یعنی $y^(<k>)$ هیچ گاه خود ۱ یا خود ۰ نمی شود.

  اگر:
  $
    sum_(j=0)^n w_j x_j^(<k>)
  $
  را معادل $v$ در نظر بگیریم، به معادله و نمودار زیر می رسیم:
  $
    y^(<k>) = 1 / (1 + e^(-v))
  $
  #tool.custom_figure(
    image("images/ML/10_04.png"),
    caption: [اگر $v$ به بی نهایت میل کند، $y$ به یک میل می کند؛ و اگر $v$ به منفی بی نهایت میل کند، $y$ به صفر میل می کند.],
    inset: 1em,
    refrence: <image_10_04>,
  )
  //TODO:
  با مشتق گرفتن از @equation_10_14، به معادله زیر می رسیم:
  $
    \
    (partial y) / (partial w_j) &= (0 times dots - 1 times (x_j^(<k>) e^display(-sum_(j=0)^n w_j x_j^(<k>)))) / (
      1 + e^display(-sum_(j=0)^n w_j x_j^(<k>))
    )^2
    \
    &= -x_j^(<k>) #h(1em) times #h(1em) 1 / (1 + e^display(-sum_(j=0)^n w_j x_j^(<k>))) #h(1em) times #h(1em) (e^display(-sum_(j=0)^n w_j x_j^(<k>))) / (1 + e^display(-sum_(j=0)^n w_j x_j^(<k>)))
  $
  #place(dx: -12em, dy: -5.75em, rect(width: 9em, height: 5em, stroke: (dash: "densely-dash-dotted"), radius: 0.5em))
  #place(dx: -0.9em, dy: -7.8em, rect(width: 9em, height: 7em, stroke: (dash: "densely-dash-dotted"), radius: 0.5em))
  #v(2em)
  #place(dx: -15em, dy: -2em, $y^(<k>)$)
  #place(dx: -3em, dy: -2em, $1 - y^(<k>)$)
  $
    (partial y) / (partial w_j) = -x_j y (1- y)
  $
  با نگاه به فرمول بالا می توان فهمید که مشتق تابع $y$، با خود تابع $y$ بیان می شود.
]

#tool.definition()[
  تابع خطای Logistic Regression به صورت زیر تعریف می شود (RMS Error for Logistic Regression):
  $
    E = 1 / (2 N) sum_(k=1)^N (y^(<k>) - hat(y)^(<k>))^2
  $
  $
    w arrow.l w - eta (partial E) / (partial w)
  $
  <equation_10_22>
  $
    (partial E) / (partial w) &= 1 / N sum_(k=1)^N (y^(<k>) - hat(y)^(<k>)) (partial ( y^(<k>) - hat(y)^(<k>) )) / (partial w)
    \
    &= -1 / N sum_(k=1)^N (y^(<k>) - hat(y)^(<k>)) (partial hat(y)^(<k>)) / (partial w)
    \
    &= -1 / N sum_(k=1)^N (y^(<k>) - hat(y)^(<k>)) x_j hat(y)^(<k>)(1 - hat(y)^(<k>))
  $
  <equation_10_23>
  $
    0 < hat(y)^(<k>)(1 - hat(y)^(<k>)) < 0.25
  $
  با توجه به @equation_10_23، @equation_10_22 به شکل زیر در می آید:
  $
    w arrow.l w + eta / N sum_(k=1)^N (y^(<k>) - hat(y)^(<k>)) x_j^(<k>) (hat(y)^(<k>))(1 - hat(y)^(<k>))
  $
  از آن جایی که $(hat(y)^(<k>))(1 - hat(y)^(<k>))> 0$ است، می توان آن را به عنوان یک ضریب مثبت در نظر گرفت.
  اگر این ضریب را برداریم گویی که $eta$ را بزرگ تر کرده ایم.
  به همین دلیل می توان $w$ ای به نام $"Polished" w$ به شکل زیر تعریف کرد:
  $
    "Polished" w: w arrow.l w + eta 1 / N sum_(k=1)^N x_j^(<k>) (y^(<k>) - hat(y)^(<k>))
  $
  با نگاه به فرمول بالا می توان فهمید که این فرمول، همان قاعده به روز رسانی $w$ در رگرسیون خطی می باشد.
  تنها فرق آن این است که $hat(y)$ در رگرسیون خطی، از تابع خطی به دست می آید اما در رگرسیون لاجستیک از تابع لاجستیک به دست می آید.
]

= جلسه یازدهم
== ساده یا پیچیده؟ مسأله این است! #emoji.face.think
#tool.tip()[
  گاهی نیاز است که برای حل بهینه مسأله، مدل خود را کمی پیچیده تر کنیم.
  مانند تصویر زیر:
  #tool.custom_figure(
    image("images/ML/11_01.png", width: 58.5%),
    caption: "حل بهینه این مسأله کلاس بندی، نیازمند معادله ای درجه دو است.",
    inset: 1em,
  )
  اما گاهی اوقات افزایش پیچیدگی نتیجه عکس می دهد:
  #tool.custom_figure(
    image("images/ML/11_02.png", width: 58.5%),
    caption: [در این جا مرز بندی دقیق باعث می شود تا نمونه تست به اشتباه در کلاس $C_2$ طبقه بندی شود. در حالی که اگر از مدل ساده تر خط استفاده می کردیم، با وجود خطاهای احتمالی، نمونه ما درست طبقه بندی می شد.],
    inset: 1em,
  )
]

#tool.question()[
  با توجه به بخش قبل، از کجا بفهمیم چه مدلی را باید انتخاب کنیم؟
]

#tool.true_answer()[
  + روش اول:
    قاعده ساده ای وجود دارد که بر اساس آن از ساده ترین مدل شروع می کنیم به امتحان کردن مدل.
    پیچیدگی مدل را تا زمانی افزایش می دهیم که به میزان خطای قابل قبول مد نظرمان برسیم.
  + روش دوم:
    از تکنیک Regularization استفاده می کنیم.
]

== Regularization
#tool.example()[
  مجموعه داده هایی با ویژگی ها و برچسب زیر داریم:
  $
    "Features": <x_0, x_1, x_2, dots, x_n> , "Label": y
  $
  این داده ها را می توان با مدل های مختلفی تحلیل کرد.

  معادله مدل خطی:
  $
    hat(y)^(<k>) = h(arrow(x)^(<k>)) = sum_(j=0)^n w_j x_j^(<k>)
  $
  معادله مدل غیر خطی:
  $
    hat(y) = h_2(arrow(x)) = sum_(j=0)^n w_j x_j + sum_(j=0)^n u_j x_j^2
  $
  برای مثال اگر داده ما ۳ ویژگی داشته باشد، معادله بالا به صورت زیر در می آید:
  $
    hat(y) = h_2(x) = w_0 x_0 + w_1 x_1 + w_2 x_2 + u_0 x_0^2 + u_1 x_1^2 + u_2 x_2^2
  $
  $
    E = underbrace(1 / (2 N) sum_(k=1)^N (y^(<k>) - hat(y)^(<k>))^2, display(E_1)) + underbrace(lambda sum_(j=0)^n u_j^2, display(E_2)) #h(1em) , #h(1em) lambda >= 100
    \
    (partial E) / (partial w) = (partial E_1) / (partial w) + (partial E_2) / (partial u)
  $
  در بالا، $lambda$ توسط ML Engineer تعیین می شود.
]

#tool.definition()[
  Regularization (تنظیم):
  به تنطیم کردن تأثیر جملات تابع خطای مدل که در اغلب مدل های یادگیری کاربرد دارد، Regularization می گوییم که ضریبی به نام $lambda$ دارد.
  $lambda$ عدد بزرگی است.
  مثلاً: $lambda >= 100$ به این معنا است که جمله با ضریب $lambda$، ۱۰۰ برابر تأثیر بیشتری در تابع خطا دارد نسبت به جمله ای که این ضریب را ندارد.
]

#tool.tip()[
  هر جایی که Gradient Descent وجود داشته باشد می توان از Regularization استفاده کرد.
]

== Hyper Parameters
#tool.list()[
  Hyper Parameter های زیر برای Train کردن، توسط ML Engineer تعیین می شوند:
  + Max-iteration
  + Learning Rate ($eta, alpha$)
  + Regularization Coefficient ($lambda_i$)
]

== Initial Momentum
#tool.reminder()[
  تابع به روز رسانی ای که در جلسه قبل تعریف کردیم، به شکل زیر بود:
  $
    w = w + overbrace(alpha (1 / N) sum_(k=1)^N (y^(<k>) - hat(y)^(<k>)) x^(<k>), display(Delta w))
    \
    w = w + Delta w
  $
]

#tool.definition()[
  فرض کنید مدلی به صورت زیر داریم:
  $
    y = w x
  $
  مقدار اولیه $w$ به صورت تصادفی تعیین می شود.
  فرض کنید مقدار اولیه آن ۰ باشد:
  $
    w = 0
  $
  در مرحله های بعدی با توجه به $Delta w$ ای که خواهیم داشت، $w$ جدید را تعیین می کنیم:
  $
    Delta w = 1 arrow w^("New") = 1
    \
    Delta w = 2 arrow w^("New") = 3
    \
    Delta w = 5 arrow w^("New") = 8
    \
    Delta w = -1 arrow w^("New") = 7
  $
  همان طور که در بالا مشاهده می شود، روند کلی $Delta w$ صعودی است.
  در گام آخر، شاید Data ما دچار Noise شده باشد یا Selection خوبی نداشته ایم که باعث شده $Delta w$ مقداری منفی و کاهشی به ما بدهد که باعث بر هم زدن روند کلی می شود.

  راه حل این است که از روش Initial Momentum استفاده کنیم که در آن $Delta w$ به صورت زیر محاسبه می شود:
  $
    Delta w_"Average"^(<t>) = (Delta w_"Average"^(<t - 1>) + Delta w^(<t>)) / 2
  $
]

#tool.example()[
  جدول زیر را در نظر بگیرید:
  #tool.custom_figure(
    caption: [همان گونه که مشاهده می شود، $w$ ای که با $Delta w_"Average"$ به دست می آید، تأثیر کمتری از تغییرات شدید می گیرد و پایدار تر است],
    kind: table,
    inset: 1em,
  )[
    #table(
      columns: 5,
      inset: 1em,
      stroke: black,
      align: center + horizon,
      table.cell(fill: luma(230), $t$), table.cell(fill: luma(230), $Delta w$), table.cell(
        fill: luma(230),
        $Delta w_"Average"$,
      ), table.cell(fill: luma(230), $w$), table.cell(fill: luma(230), $w_"Old(بدون استفاده از میانگین گیری)"$),
      $0$, $0$, $0$, $0$, $0$,
      $1$, $1$, $display(1 / 2)$, $display(1 / 2)$, $1$,
      $2$, $2$, $1.25$, $1.75$, $3$,
      $3$, $5$, $3.12$, $4.9$, $8$,
      $4$, $-1$, $1.06$, $5.96$, $7$,
      table.cell(fill: luma(230), $t$), table.cell(fill: luma(230), $Delta w$), table.cell(
        fill: luma(230),
        $Delta w_"Average"$,
      ), table.cell(fill: luma(230), $w$), table.cell(fill: luma(230), $w_"Old(بدون استفاده از میانگین گیری)"$),
      $0$, $0$, $0$, $0$, $0$,
      $1$, $1$, $display(1 / 2)$, $display(1 / 2)$, $1$,
      $2$, $-1$, $display((-1) / 4)$, $display(1 / 4)$, $0$,
      $3$, $1$, $display(3 / 8)$, $display(5 / 8)$, $1$,
      $4$, $-1$, $display((-5) / 16)$, $display(5 / 16)$, $0$,
    )
  ]
  با توجه به جدول بالا، در می یابیم که زمانی که از $Delta w_"Average"$ استفاده می کنیم، نمودار هموار تر (Smooth تر) می شود.
  #tool.custom_figure(
    image("images/ML/11_03.png", width: 53%),
    caption: [استفاده از $Delta w_"Average"$، حساسیت به تغییرات شدید را کمتر و نمودار را هموار تر می کند.],
    inset: 1em,
  )
]

== Non-parameteric Models
#tool.definition()[
  در این مدل ها، برای مدل سازی $hat(y)$ از یک مدل دارای پارامتر های مشخص (مانند: Bayesian، خط، Logistic Regression و مواردی همچون این ها)، استفاده *نمی شود*.
]
=== k-Nearest Neighbour (k-NN)
#tool.definition()[
  وقتی می خواهیم یک نمونه را کلاس بندی کنیم و نمی دانیم که به کدام کلاس تعلق دارد.
  می توانیم تعداد فردی از نزدیک ترین نمونه ها به آن را انتخاب کرده و آن را در کلاسی که اکثریت شان در آن قرار دارند، قرار دهیم.
  این روش، k-NN نام دارد.
  #tool.custom_figure(
    image("images/ML/11_04.png", width: 60%),
    caption: "نمونه در کلاس مثبت طبقه بندی می شود. چرا که در نزدیکی آن ۳ نمونه با کلاس مثبت، در مقایسه با ۲ نمونه با کلاس منفی، وجود دارد.",
    inset: 1em,
  )
]

#tool.double_section()[
  #tool.tip()[
    خوبی روش k-NN آن است که ساده است و نتیجه خوبی می دهد.
    بدی روش k-NN سنگین بودن آن است.
    چرا که برای طبقه بندی نمونه تست، باید تمامی نمونه های آموزشی را در حافظه داشته باشیم.
    بر خلاف روش های پارامتری که بعد از آموزش، تنها پارامتر های آن ها را نگه می داشتیم.
  ]
][
  #tool.example()[
    برای مدل های زیر، نیاز به نگهداری موارد زیر است:
    #set text(dir: ltr)
    #set math.equation(numbering: none)
    + Bayes Gaussian:
      $ | mu_1, mu_2, sigma_1, sigma_2 | = 4 $
    + k-NN:
      $ &| x^(<1>), x^(<2>), x^(<3>), dots, x^(<N>) | \ &= "Sample Size" $
    #v(0.2em)
  ]
]

#tool.tip()[
  به روش k-NN، روش Lazy Learning نیز می گویند.
  چرا که در این روش، گام Training وجود ندارد و تمامی کار هایش را زمانی که نمونه تست را باید بررسی کند، انجام می دهد.
]

=== r-NN
#tool.definition()[
  روشی شبیه به k-NN به نام r-NN وجود دارد که در آن دایره ای به شعاع r رسم می شود و هر آن چه درون این دایره بیافتد، برای کلاس بندی بررسی می شود.
]

#tool.tip()[
  مشکلی که در روش r-NN وجود دارد این است که تعداد نمونه هایی که درون دایره می افتند دیگر دست ما نیست و ممکن است تعداد آن ها زوج شود و اگر مثلاً دو کلاس داشته باشیم که نصف نمونه های آموزشی درون دایره به یک کلاس و نصف دیگر به کلاس دیگر تعلق داشته باشد، نمی توانیم تشخیص دهیم که نمونه تست به کدام کلاس تعلق دارد.
]

=== Case-Based Reasoning (1NN)
#tool.definition()[
  الگوریتمی منشعب از k-NN است که معادل 1NN می باشد.
  به این معنا که نزدیک ترین همسایه خود را پیدا کرده و Label آن را به عنوان پاسخ بر می گرداند.
]

== کم کردن هزینه k-NN
=== الگوریتم Quad Tree Decomposition
#tool.definition()[
  برای کم کردن هزینه روش k-NN (در حالت دو بعدی)، کل داده های آموزشی را به شکل یک ماتریس در می آوریم (@image_11_02).
  سپس این ماتریس را به دو بخش افقی تقسیم می کنیم. بخش پایین کاملاً مثبت است و تنها به کلاس مثبت تعلق دارد.
  به همین دلیل به جای آن که کل بخش پایین نگه داشته شود، کافی است این نکته که هر آن چه که در نیمه پایینی ماتریس است، مثبت می باشد، را ذخیره کنیم.
  به همین ترتیب نیمه بالایی ماتریس را نیز به دو بخش چپ و راست تقسیم کرده و این تقسیم های عمودی و افقی را در هر بخش آن قدر ادامه می دهیم تا ماتریس به بخش هایی تقسیم شود که تمامی نمونه های درون آن بخش ها متعلق به یک کلاس باشد.
  به هر یک از این بخش ها، Hyper Cube می گویند:
  $
    "Hyper Cubes" = {R_1, R_2, R_3, R_4, R_5, R_6}
  $
  در نهایت کافی است که تنها مختصات این ۶ ناحیه و این که هر یک به چه کلاسی تعلق دارند را در حافظه نگه داریم.
  #tool.custom_figure(
    caption: "ماتریس داده های آموزشی که با روش QTD به ۶ ناحیه تقسیم شده اند. در نهایت تنها اطلاعات مربوط به این ۶ ناحیه نگه داشته می شوند.",
    inset: 1em,
    refrence: <image_11_02>,
  )[
    #set circle(radius: 0.95em)
    #place(
      dx: 8em,
      dy: 0.5em,
      [
        #place(dy: -0.5em, $R_1$)
        #rotate(90deg, $lr(\{, size: #3.5em)$)
      ],
    )
    #place(
      dx: 11.95em,
      dy: 0.5em,
      [
        #place(dy: -0.5em, $R_2$)
        #rotate(90deg, $lr(\{, size: #3.5em)$)
      ],
    )
    #place(
      dx: 15.9em,
      dy: 0.5em,
      [
        #place(dy: -0.5em, $R_3$)
        #rotate(90deg, $lr(\{, size: #3.5em)$)
      ],
    )
    #place(
      dx: 19.8em,
      dy: 0.5em,
      [
        #place(dy: -0.5em, $R_4$)
        #rotate(90deg, $lr(\{, size: #3.5em)$)
      ],
    )
    #v(2.5em)
    #place(
      dx: 5.25em,
      dy: 4.7em,
      [
        #place(dx: -1.5em, dy: 0.75em, $R_5$)
        $lr(\{, size: #3.5em)$
      ],
    )
    #table(
      columns: 4,
      inset: 1em,
      stroke: black,
      align: center + horizon,
      table.cell(fill: red_color.lighten(60%), circle($-$)), table.cell(
        fill: green_color.lighten(60%),
        circle($+$),
      ), table.cell(fill: blue_color.lighten(60%), circle($+$)), table.cell(
        fill: orange_color.lighten(60%),
        circle($-$),
      ),
      table.cell(fill: brown_color.lighten(60%), circle($-$)), table.cell(
        fill: brown_color.lighten(60%),
        circle($-$),
      ), table.cell(fill: blue_color.lighten(60%), circle($+$)), table.cell(
        fill: orange_color.lighten(60%),
        circle($-$),
      ),
      table.cell(fill: purple_color.lighten(60%), circle($+$)), table.cell(
        fill: purple_color.lighten(60%),
        circle($+$),
      ), table.cell(fill: purple_color.lighten(60%), circle($+$)), table.cell(
        fill: purple_color.lighten(60%),
        circle($+$),
      ),
      table.cell(fill: purple_color.lighten(60%), circle($+$)), table.cell(
        fill: purple_color.lighten(60%),
        circle($+$),
      ), table.cell(fill: purple_color.lighten(60%), circle($+$)), table.cell(
        fill: purple_color.lighten(60%),
        circle($+$),
      ),
    )
    #v(2.5em)
    #place(
      dx: 13.9em,
      dy: -8.5em,
      [
        #place(dy: 7.9em, $R_6$)
        #rotate(-90deg, $lr(\{, size: #15em)$)
      ],
    )
  ]
]

#tool.tip()[
  از الگوریتم k-NN می توان برای بررسی این که آیا مسأله مورد نظر ما به جواب می رسد یا خیر، استفاده کرد.
  به این صورت که ابتدا آن را اجرا می کنیم.
  اگر جواب خوبی داد، یعنی با مدل های پارامتری نیز ممکن است به این حد از دقت برسیم.
]

#tool.tip()[
  Hyper Parameter الگوریتم k-NN، همان k و Hyper Parameter الگوریتم r-NN، همان r است.
]

= جلسه دوازدهم
== Non-parametric Models (ادامه)
=== Artifical Neural Networks
#tool.double_section()[
  #tool.simple_context()[
    رویکردی به نام Bio-inspiration وجود دارد به این صورت که
    برای حل برخی مسأله ها می توان با نگاه به پدیده های زیستی، از آن ها ایده گرفت.
  ]
][
  #tool.definition()[
    شبکه عصبی مصنوعی، یک مدل یادگیری ماشین بدون پارامتر است که از سیستم یادگیری نورون های مغز انسان، اقتباس کرده است.
  ]
]

#tool.definition()[
  Hebbian Learning:
  دو سلولی که باید با هم فعال شوند، باید ارتباط قوی تری بین یک دیگر داشته باشند.
]

==== Artifical Neuron
#tool.definition()[
  مدلی محاسباتی است که از سلول های عصبی انسان الگو گرفته است.
  سلول عصبی مصنوعی، از تعدادی ورودی وزن دار، قسمت محاسباتی و یک خروجی تشکیل شده است.
  #tool.custom_figure(
    image("images/ML/12_01.png", width: 90%),
    caption: "ورودی های وزن دار، قسمت محاسباتی و خروجی یک سلول عصبی مصنوعی.",
    inset: 1em,
  )
  ورودی ها از سلول های مختلف دیگر، با وزن های مختلف می آیند.
  وزن ها معمولاً اعداد خیلی کوچکی هستند.
  مثلاً:
  $
    -1 <= w_1, w_2, w_3 <= 1
  $
  قسمت محاسباتی خیلی کم دستور است.
  به طوری که گاهی اوقات فقط از دو دستور جمع و تابع انتقال به شکل زیر تشکیل می شود:
  $
    v = sum w_i x_i #h(1em) , #h(1em) y = f(v)
    \
    f(v) arrow "Activation Function / Transfer Function"
  $
]

#tool.example()[
  نمونه هایی از تابع فعال سازی یا تابع انتقال:
  $
    y = "sgn"(v): "If" v >= 0 "then" y = 1 "else" y = 0
  $
  $
    y = v
  $
  $
    y = sigma(v) = 1 / (1 + e^(-v))
  $
]

#tool.question()[
  مسأله XOR با دو ورودی را با شبکه عصبی حل کنید.
]

#tool.true_answer()[
  ابتدا جدول تابع XOR را می کشیم:
  #tool.custom_figure(
    caption: "حالت های ممکن تابع XOR با دو ورودی",
    kind: table,
    inset: 1em,
  )[
    #table(
      columns: 3,
      inset: 1em,
      stroke: black,
      align: center + horizon,
      $x_1$, $x_2$, $y$,
      "0", "0", "0",
      "0", "1", "1",
      "1", "0", "1",
      "1", "1", "0",
    )
  ]

  شکل نموداری این جدول به صورت زیر می باشد:
  #tool.custom_figure(
    image("images/ML/12_02.png", width: 53%),
    caption: "نمایش تابع XOR با دو ورودی بر روی نمودار. دایره های تو پر بیانگر عدد ۱ و دایره های تو خالی بیانگر عدد ۰ هستند.",
    inset: 1em,
  )

  در نهایت تابع فعال سازی و شبکه عصبی XOR را به صورت زیر نوشته و رسم می کنیم:
  $
    v >= 0 arrow 1 , v < 0 arrow 0
  $
  #tool.custom_figure(
    image("images/ML/12_03.png"),
    caption: "پیاده سازی تابع XOR با دو ورودی به کمک شبکه عصبی",
    inset: 1em,
    refrence: <image_12_03>,
  )
  با تست شبکه عصبی بالا مشاهده می کنیم که به ازای تمامی مقادیر ممکن ورودی $x_1$ و $x_2$ خروجی درستی تولید می شود.
]

#tool.double_section()[
  #tool.tip()[
    مسأله XOR با یک خط حل نمی شود.
    هر یک از نورون های @image_12_03، یک Classifier خطی است.
    یعنی هر یک از آن ها به صورت تکی تنها می تواند مسائل خطی جدایی پذیر را حل کند.
    اما با وصل کردن آن ها به یکدیگر می توان مسأله ای که با یک خط حل نمی شود را نیز حل کرد.
  ]
][
  #tool.tip()[
    در شبکه عصبی، سلول ها با الگو و وزن خاصی کنار هم قرار گرفته می شوند تا یک مسأله پیچیده را حل کنند.
    هر چه ساختار این چینش پیچیده تر باشد، می توان مسائل پیچیده تری را حل کرد.
    #v(4.8em)
  ]
]

= جلسه سیزدهم
== شبکه های عصبی در یادگیری ماشین
=== بخش های تشکیل دهنده یک شبکه عصبی
#tool.reminder()[
  شبکه های عصبی مصنوعی برگرفته از ساختار سلول های عصبی مغز انسان هستند.
  #tool.custom_figure(
    image("images/ML/13_01.png"),
    caption: "سمت چپ نورون های مغز و سمت راست برداشت ما از آن ها را نشان می دهد.",
    inset: 1em,
  )
]

#tool.double_section()[
  #tool.tip()[
    در شبکه های عصبی، از الگوریتم و داده های آموزشی خاصی استفاده می شود تا وزن ها یاد گرفته شوند.
    قسمت $Sigma$ و Activation Function توسط ML Engineer تعیین می شود.
  ]
][
  #tool.tip()[
    در شبکه های عصبی، تابع فعال سازی یک عدد اسکالر را به عنوان ورودی می گیرد و یک عدد اسکالر را به عنوان خروجی می دهد.
    #v(1.6em)
  ]
]

#tool.tip()[
  مغز از ساختار پیچیده ای تشکیل شده است.
  اما برای شبکه های عصبی در یادگیری ماشین، مدل ساده تری که ساختاری لایه ای دارد، می سازیم:
  #tool.custom_figure(
    image("images/ML/13_02.png", width: 79%),
    caption: "شبکه عصبی طبیعی (چپ) و شبکه عصبی مصنوعی (راست).",
    inset: 1em,
  )
]

#tool.definition()[
  Net Input: ورودی خالص یک نورون را Net Input می گویند.
  $
    v = sum_(i=0)^n w_i x_i
  $
]

#tool.list()[
  انواع Activation Function ها:
  + Step Function / Hard Limit: تابع فعال سازی آن به صورت زیر است:
    $
      f(x) = cases(
        1 #h(2em) x >= 0,
        0 #h(2em) x < 0
      )
    $
    #tool.custom_figure(
      image("images/ML/13_12.png"),
      caption: [Step Function],
      inset: 1em,
    )

  + Logistic Regression / Sigmoid: تابع فعال سازی آن به صورت زیر است:
    $
      f(x) = 1 / (1 + e^(-x))
    $ <equation_13_03>
    #tool.custom_figure(
      image("images/ML/10_04.png"),
      caption: [تابع Logistic Regression که در @image_10_04 آورده شده بود.],
      inset: 1em,
    )

  + Linear Function: تابع فعال سازی آن به صورت زیر است:
    $
      f(x) = a x + b
    $

  + Identity Fucntion: تابع فعال سازی آن به صورت زیر است:
    $
      f(x) = x
    $

  + Tangent Hyperbolic: تابع فعال سازی آن به صورت زیر است:
    $
      f(x) = (e^x - e^(-x)) / (e^x + e^(-x))
    $
]

=== Basic Architectures
==== Perceptron
#tool.definition()[
  شبکه ای عصبی است که از دو لایه، شامل یک لایه ورودی و یک لایه خروجی تشکیل شده است.
  #tool.custom_figure(
    image("images/ML/13_03.png"),
    caption: "شبکه عصبی Perceptron از یک لایه ورودی و یک لایه خروجی تشکیل شده است. Constant موجود در شکل، همان Bias شبکه است.",
    inset: 1em,
  )
]

==== Logistic Regression
#tool.definition()[
  #tool.custom_figure(
    image("images/ML/13_04.png", width: 55%),
    caption: "شبکه عصبی Logistic Regression",
    inset: 1em,
  )
]

#tool.tip()[
  دقت شود که شبکه Logistic Regression با Perceptron تفاوت دارد.
  چرا که تابع شبکه Logistic Regression بر خلاف تابع شبکه Perceptron، مشتق پذیر است.
]

==== Extreme Learning Machines (ELM)
#tool.definition()[
  شبکه ای عصبی است که از سه لایه، شامل یک لایه ورودی، یک لایه میانی یا مخفی و یک لایه خروجی تشکیل شده است.
  #tool.custom_figure(
    image("images/ML/13_05.png", width: 79%),
    caption: "شبکه عصبی Extreme Learning Machines",
    inset: 1em,
  )
  در این شبکه دو مجموعه وزن $w$ و $beta$ داریم که باید مشخص شوند.
  یادگیری $beta$ ها آسان است چرا که خروجی نورونی که به آن متصل می شوند را داریم.
  از طرفی چون خروجی نورون های لایه مخفی را نداریم، نمی توانیم وزن $w$ ها را با فرآیند یادگیری به دست آوریم.
  اما خوشبختانه در این شبکه وزن $w$ ها به صورت تصادفی تعیین می شوند و نیازی به یادگیری آن ها نیست.
]

#tool.example()[
  شبکه عصبی ای به شکل زیر داریم.
  مسأله ای که این شبکه حل می کند، مسأله XOR است.
  همچنین تابع فعال سازی آن، تابع Sigmoid است.
  می خواهیم ببینیم اگر به صورت تصادفی وزن هایش را تعیین کنیم چه اتفاقی می افتد.
  #tool.custom_figure(
    image("images/ML/13_13.png", width: 95%),
    caption: "نمونه ای از یک شبکه عصبی برای حل مسأله XOR که وزن های آن به صورت تصادفی انتخاب شده اند.",
    inset: 1em,
  )
  دو بار وزن های این شبکه را به صورت تصادفی انتخاب کرده و سپس با توجه به @equation_13_03 که همان فرمول تابع فعال سازی این مسأله است، مقادیر $z_1$ و $z_2$ را در هر بار، حساب می کنیم:

  جدول زیر مقادیر $z_1$ و $z_2$ را برای وزن های زیر نشان می دهد:

  $
    w_1 = 0.5, w_2 = 0.1, w_3 = -1, w_4 = 0.2
  $
  #tool.custom_figure(
    caption: [مقدار $z_1$ و $z_2$ برای داده ها و وزن های مرتبط],
    kind: table,
    inset: 1em,
    refrence: <table_13_01>,
  )[
    #table(
      columns: 5,
      inset: 1em,
      stroke: black,
      align: center + horizon,
      $x_1$, $x_2$, $y$, $z_1$, $z_2$,
      "0", "0", "0", "0.5", "0.5",
      "0", "1", "1", "0.25", "0.94",
      "1", "0", "1", "0.63", "0.52",
      "1", "1", "0", "0.38", "0.57",
    )
  ]

  #tool.custom_figure(
    image("images/ML/13_14.png", width: 39%),
    caption: [نمودار مرتبط با @table_13_01. به کمک وزن های تصادفی، فضای نقاط مربوط به کلاس های مختلف به گونه ای تغییر می کند که می توان آن ها را با یک خط مستقیم از هم جدا کرد.],
    inset: 1em,
  )

  جدول زیر نیز مقادیر $z_1$ و $z_2$ را برای وزن های زیر نشان می دهد:
  $
    w_1 = 1, w_2 = -1, w_3 = 0.4, w_4 = -0.8
  $
  #tool.custom_figure(
    caption: [مقدار $z_1$ و $z_2$ برای داده ها و وزن های مرتبط],
    kind: table,
    inset: 1em,
    refrence: <table_13_02>,
  )[
    #table(
      columns: 5,
      inset: 1em,
      stroke: black,
      align: center + horizon,
      $x_1$, $x_2$, $y$, $z_1$, $z_2$,
      "0", "0", "0", "0.5", "0.5",
      "0", "1", "1", "0.59", "0.69",
      "1", "0", "1", "0.73", "0.4",
      "1", "1", "0", "0.8", "0.14",
    )
  ]

  #tool.custom_figure(
    image("images/ML/13_15.png", width: 39%),
    caption: [نمودار مرتبط با @table_13_02. به کمک وزن های تصادفی، فضای نقاط مربوط به کلاس های مختلف به گونه ای تغییر می کند که می توان آن ها را با یک خط مستقیم از هم جدا کرد.],
    inset: 1em,
  )
]

#tool.double_section()[
  #tool.question()[
    وظیفه لایه دوم شبکه ELM چیست؟
    #v(1.6em)
  ]
][
  #tool.true_answer()[
    این لایه وظیفه پیدا کردن خط جدا کننده کلاس ها را دارد.
  ]
]

#tool.double_section()[
  #tool.tip()[
    معماری های شبکه عصبی زیادی آمدند و رفتند.
    چرا که در مقایسه با ساختار های ساده تر شبکه عصبی، مزیت خاصی از نظر عملکرد، نداشتند.
  ]
][
  #tool.tip()[
    در شبکه ELM نورون های هر لایه، به همه نورون های لایه بعدی و قبلی، وصل می شود.
    #v(1.6em)
  ]
]

#tool.tip()[
  در شبکه ELM، تابع نورون های لایه سوم، Linear است.
  چرا که قرار است خطی که کلاس ها را از هم جدا می کند، بسازد.
  تابع فعال سازی لایه میانی، Sigmoid است.
]

==== Multilayer Perceptrons (MLP)
#tool.definition()[
  شبکه ای است که از سه لایه، شامل یک لایه ورودی، چندین لایه مخفی و یک لایه خروجی تشکیل شده است.
  در این شبکه، پردازش داده ها به صورت لایه ای است.
  به این صورت که داده ها به ترتیب از سمت چپ وارد شده، سپس خروجی آن حساب می شود، سپس لایه بعدی و لایه بعدی و ... تا لایه خروجی.
  #tool.custom_figure(
    image("images/ML/13_06.png", width: 57%),
    caption: "Multilayer Perceptron",
    inset: 1em,
  )
]

#tool.double_section()[
  #tool.tip()[
    تجربه نشان داده است که وجود بیش از یک لایه پنهان در شبکه MLP، زیاد به درد بخور نیست.
  ]
][
  #tool.tip()[
    شبکه MLP، هر چقدر لایه میانی بیشتری داشته باشد، مسائل پیچیده تری را می تواند یاد بگیرد.
  ]
]

#tool.tip()[
  در شبکه MLP، تابع لایه ورودی، تابع همانی،
  تابع لایه میانی، تابع Sigmoid یا تابع Tangent Hyperbolic و تابع لایه خروجی معمولاً تابع Linear است.
]

#tool.definition()[
  Error Propagation: در شبکه MLP ورودی و نتیجه محاسبه آن از لایه ورودی تا لایه خروجی انتشار می یابد.
  همچنین به کمک مشتق زنجیره ای، خطا از لایه خروجی به سمت لایه ورودی انتشار می یابد و محاسبه می شود و به کمک آن، وزن ها اصلاح می شوند.
  این اصلاح به کمک الگوریتم Error Propagation انجام می شود.
  #tool.custom_figure(
    image("images/ML/13_07.png"),
    caption: "Error Propagation",
    inset: 1em,
  )
]

==== Autoencoder Networks (AEN)
#tool.definition()[
  این شبکه در ساده ترین حالت از سه لایه تشکیل می شود.
  لایه ورودی، لایه میانی و لایه خروجی.
  از روی داده های ورودی، وزن ها حساب می شوند و با کمک وزن ها، خروجی لایه میانی را به همان داده های اولیه ورودی تبدیل می کند.
  به عبارتی این شبکه، داده ها را Encode می کند و برای مثال در فشرده کردن داده ها کاربرد دارد.
  #tool.custom_figure(
    image("images/ML/13_08.png", width: 61%),
    caption: "Autoencoder Networks",
    inset: 1em,
  )
]

#tool.tip()[
  این شبکه مانند شبکه MLP است.
  تنها تفاوت آن ها این است که در AEN، ورودی با خروجی یکسان است.
]

==== Deep Multilayer Perceptrons (DMLP)
#tool.definition()[
  به شبکه MLP ای که بیش از یک لایه میانی داشته باشد، شبکه DMLP می گویند.
  #tool.custom_figure(
    image("images/ML/13_09.png"),
    caption: "Deep Multilayer Perceptrons",
    inset: 1em,
  )
]

#tool.tip()[
  در عمل، به شبکه های عصبی ای که چند صد لایه میانی دارند، شبکه های عصبی عمیق می گویند.
]

==== Convolutional Neural Network (CNN)
#tool.definition()[
  شبکه عصبی ای است که چندین لایه میانی دارد و هر کدام از آن ها وظایف خاصی را انجام می دهند و Activation Function های آن ها با یکدیگر فرق می کند.
  #tool.custom_figure(
    image("images/ML/13_10.png", width: 80%),
    caption: "Convolutional Neural Network",
    inset: 1em,
  )
]

==== Recurrent Neural Network (RNN)
#tool.definition()[
  شبکه های عصبی بازگشتی، شبکه هایی وابسته به زمان هستند و در آن ها خروجی یک نورون می تواند به عنوان ورودی خود آن نورون و یا ورودی نورون های قبلی اش، تعیین شود.
  #tool.custom_figure(
    image("images/ML/13_11.png", width: 91%),
    caption: "Recurrent Neural Network",
    inset: 1em,
  )
]

#tool.tip()[
  RNN ها در مدل سازی دنباله ها مانند گفتار و سری های زمانی استفاده می شوند.
]

==== Pretrained Neural Networks (PNN)
#tool.definition()[
  در این شبکه ها یک لایه دلخواه ML Engineer به شبکه اضافه و آموزش داده می شود و بقیه لایه ها ثابت هستند.
]

= جلسه چهاردهم
== Non-parameteric Models (ادامه)
=== Decision Tree
#tool.example()[
  فرض کنید داده هایی به صورت زیر داریم.
  بانک می خواهد بداند که کدام مشتری هایش احتمالاً خواهان دریافت وام هستند.
  Default borrower به این معنی است که آیا کسی به صورت پیش فرض از بانک وام می خواهد یا خیر.

  #tool.custom_figure(
    image("images/ML/14_01.png"),
    caption: "داده های مشتری های یک بانک و درخت تصمیم مرتبط با آن.",
    inset: 1em,
  )

  از جدول بالا به صورت شهودی می توانیم به ساختار تصمیم گیری ای در سمت راست آن، به نام درخت تصمیم، برسیم.
]

#tool.double_section()[
  #tool.tip()[
    درخت تصمیم خوب، درختی است که به سرعت از ریشه به تصمیم برسد (با شرط های کمی برسد).
    یعنی درخت، پهن تر و کم عمق تر باشد.
  ]
][
  #tool.tip()[
    ویژگی خوب، ویژگی ای است که به وسیله آن زودتر به برگ برسیم و جامعه های خالص تری را ایجاد کند.
    #v(1.6em)
  ]
]

#tool.tip()[
  برای ساخت درخت تصمیم، این نکته را مد نظر قرار می دهیم که ویژگی ای که قرار است به عنوان ریشه درخت انتخاب شود، چقدر داده های ما را تمیز تقسیم می کند.
  تمیز به این معنا است که داده هایی که از تقسیم به دست می آیند، چقدر خالص اند.
  یعنی چقدر از نظر Label شبیه هم هستند.
]

#tool.example()[
  فرض کنید ویژگی هایی به نام $f_1$ و $f_2$ داریم که هر یک، دو مقدار Yes یا No را می توانند داشته باشند.
  در شکل زیر، داده ها را یک بار بر اساس $f_1$ و باری دیگر بر اساس $f_2$ تقسیم می کنیم:
  #tool.custom_figure(
    image("images/ML/14_02.png"),
    caption: [تقسیم داده ها. یک بار بر اساس $f_1$ و یک بار بر اساس $f_2$.],
    inset: 1em,
    refrence: <image_14_02>,
  )
  با توجه به شکل بالا متوجه می شویم که وقتی بر اساس ویژگی $f_2$ تقسیم را انجام می دهیم، اکثریت داده های مثبت در سمت چپ و اکثریت داده های منفی در سمت راست قرار می گیرند.
  بنابراین تقسیم داده ها بر اساس ویژگی دو بهتر است.
  در نهایت، درخت تصمیم مناسبی را خواهیم ساخت، که به وسیله آن می توانیم نمونه های جدید را دسته بندی کنیم.
  اگر چه که ممکن است مانند شکل بالا، حتی با تقسیم داده ها بر اساس ویژگی $f_2$ همچنان مقداری خطا داشته باشیم.
]

==== الگوریتم های انتخاب ویژگی برای درخت تصمیم
#tool.list()[
  الگوریتم های انتخاب ویژگی برای ساخت درخت تصمیم شامل موارد زیر هستند:
  #grid(
    columns: (1fr, 1fr)
  )[
    + Hunt's Algorithm
    + CART
  ][
    3. ID3, C4.5, C5
    + SLIQ, SPRINT
  ]
]
===== الگوریتم Hunt
#tool.definition()[
  الگوریتمی است که به صورت تصادفی ویژگی ها را انتخاب می کند.
  درختی که در این روش ایجاد می شود، درختی درست اما پر هزینه است.
]

#tool.example()[
  عملکرد الگوریتم Hunt در مثال زیر به این شکل است:
  #tool.custom_figure(
    image("images/ML/14_03.png"),
    caption: "نحوه کار الگوریتم Hunt",
    inset: 1em,
  )
  + در شروع کار (بخش a) که هنوز هیچ تقسیمی صورت نگرفته است، متوجه می شویم که در کل، ۳ داده مربوط به کلاس Yes و ۷ داده مربوط به کلاس No وجود دارد.

  + در ادامه (بخش b)، بر اساس ویژگی Home Owner، داده ها را به دو قسمت تقسیم می کنیم.
    مشاهده می شود که جمعیت سمت چپی حاصل از تقسیم، خالص است (داده های مربوط به تنها یک کلاس در آن قرار دارد).
    با جمعیتی که خالص است کاری نداریم و در ادامه سراغ جمعیت راست که ناخالص است، می رویم.

  + سپس (بخش c)، جمعیت سمت راست را بر اساس ویژگی Marital Status تقسیم می کنیم.
    این بار جمعیت سمت راست حاصل از تقسیم خالص است و در ادامه به سراغ جمعیت سمت چپ که ناخالص است می رویم.

  + در نهایت (بخش d)، جمعیت سمت چپ را بر اساس ویژگی Annual Income تقسیم می کنیم و چون این بار هر دو جمعیت حاصل از آن خالص هستند و هیچ جمعیت ناخالص دیگری وجود ندارد، الگوریتم به پایان می رسد.
]

#tool.tip()[
  در ساخت درخت های تصمیم، درخت های باینری را ترجیح می دهیم.
  چرا که درخت های باینری را می توان به سادگی با یک آرایه پیاده سازی کرد.
]

==== Binary کردن ویژگی های Continuous
#tool.example()[
  درآمد های افراد یک جامعه به ترتیب از چپ به راست در جدول زیر آمده اند:
  #tool.custom_figure(
    caption: "درآمد های افراد یک جامعه",
    kind: table,
    inset: 1em,
  )[
    #table(
      columns: 4,
      inset: 1em,
      stroke: black,
      align: center + horizon,
      "10", "12", "13", "14",
      "15", "18", "20", "30",
      "50", "100", "120",
    )
  ]

  برای این که بتوانیم بر اساس ویژگی درآمد که یک ویژگی غیر باینری است تقسیم باینری انجام دهیم، میانگین مینیمم و ماکزیمم آن را حساب می کنیم:
  $
    (10 + 120) / 2 = 65
  $
  در ادامه بر اساس این که درآمد ها بزرگ تر مساوی ۶۵ یا کوچک تر از ۶۵ هستند، درآمد ها را به دو قسمت تقسیم می کنیم.
  این روند را به همین ترتیب می توانیم ادامه دهیم تا درخت باینری مورد نظرمان ساخته شود.
  البته این که بر اساس میانگین مینیمم و ماکزیمم، تقسیم بندی را انجام دهیم هم همیشه درست نیست.
  راه حل جایگزین به صورت زیر است:

  در این مثال تک تک درآمد ها را به عنوان کلاسی جداگانه در نظر می گیریم و بر اساس آن ها تقسیم بندی دودویی را به شکل زیر انجام می دهیم:

  فرض کنید $x$ نماد داده های ورودی به درخت تصمیم است.
  بر اساس این که $x$ کدام یک از مقادیر درآمد ها را دارد، شرط های زیر را تولید می کنیم:
  $
    x <= 10 #h(1em) , #h(1em) x <= 12 #h(1em) , #h(1em) x <= 14 #h(1em) , #h(1em) dots #h(1em) , #h(1em) x <= 120
  $

  در نهایت به وسیله این شرط ها درخت تصمیم تشکیل می شود و به وسیله این درخت، نمونه های جدید طبقه بندی می شوند.
]

#tool.tip()[
  الگوریتم های انتخاب ویژگی مختلف، ویژگی هایی را انتخاب می کنند که خلوص بیشتری در تقسیم ایجاد می کنند.
]

==== روش های سنجش خلوص ویژگی ها
===== Misclassification Error
#tool.example()[
  این خطا برای @image_14_02 به صورت زیر محاسبه می شود:
  $
    "Error of" f_2 = 15 / 70 #h(1em) , #h(1em) "Error of" f_1 = 35 / 70
  $
  بنابراین $f_2$ برای تقسیم داده ها مناسب تر از $f_1$ است.
]

===== GINI Index (شکاف طبقاتی)
#tool.definition()[
  این شاخص به صورت زیر محاسبه می شود:
  $
    "GINI Index" = 1 - sum_(i=0)^(c-1) p_i (t)^2
  $
  که در آن $p_i (t)$ فراوانی کلاس $i$ ام در گره $t$ و $c$ تعداد کل کلاس ها است.
]

#tool.example()[
  فرض کنید افراد یک جامعه، یکی از حقوق های زیر را می گیرند:
  $
    "Salary" = {10, 20, 30, 40, 50}
  $
  نسبت تعداد افرادی که یکی از حقوق های بالا را می گیرند، به کل حقوق ها، به ترتیب به صورت زیر است:
  $
    "Ratio" = {0.3, 0.1, 0.1, 0.2, 0.3}
  $
  شکاف طبقاتی این جامعه به این صورت به دست می آید که ابتدا نسبت طبقات هر جامعه را به توان دو می رسانیم:
  $
    {0.09, 0.01, 0.01, 0.04, 0.09}
  $
  سپس مجموع شان را حساب می کنیم:
  $
    0.09 + 0.01 + 0.01 + 0.04 + 0.09 = 0.24
  $
  در نهایت مجموع به دست آمده را از ۱ کم می کنیم:
  $
    "شکاف طبقاتی" = 1 - 0.24 = 0.76
  $
]

#tool.tip()[
  هر چقدر جمعیت در طبقات بیشتری توزیع شده باشد، شکاف طبقاتی بیشتر است.
]

===== Entropy
#tool.definition()[
  شاخص تنوع یک جمعیت است و به صورت زیر محاسبه می شود:
  $
    "Entropy" = - sum_(i=0)^(c-1) p_i (t) log_2 p_i (t)
  $
  که در آن $p_i (t)$ فراوانی کلاس $i$ ام در گره $t$ و $c$ تعداد کل کلاس ها است.
  هر چقدر جمعیت خالص تر باشد، Entropy کمتر و هر چقدر جمعیت متنوع تر باشد، Entropy آن بیشتر است.
]

#tool.double_section()[
  #tool.tip()[
    هرچه GINI Index و Entropy به صفر نزدیک تر باشند، برای Classification بهتر اند.
  ]
][
  #tool.tip()[
    الگوریتم های #box[ID3]، C4.5 و C5 از Entropy و الگوریتم CART از GINI Index استفاده می کنند.
  ]
]

==== Gain
#tool.definition()[
  Gain مربوط به #box[Misclassification Error]، GINI Index و Entropy به این صورت محاسبه می شود که برای هر یک از این شاخص ها ابتدا شاخص جمعیت گره والد را محاسبه کرده و سپس همان شاخص را برای جمعیت های فرزندانش محاسبه می کنیم و میانگین آن ها را به دست می آوریم.
  در نهایت، میانگین به دست آمده را از شاخص جمعیت گره والد کم می کنیم.
  برای مثال Gain شاخص Entropy به شکل زیر محاسبه می شود:
  $
    "Gain"_"split" = "Entropy"(p) - sum_(i=1)^k n_i / n "Entropy"(i)
  $
  هر گره والدی که Gain بیشتری دهد، انتخاب می شود.
]

#tool.double_section()[
  #tool.list()[
    مزیت های Decision Tree:
    + ساده است.
    + Interpretable (قابل تفسیر) است.
  ]
][
  #tool.list()[
    عیب های Decision Tree:
    + Non-parameteric است.
    + هر تصمیم در درخت، بر اساس یک ویژگی گرفته می شود.
  ]
]


== Ensemble Models
#tool.definition()[
  مدل هایی هستند که از ترکیب بیش از یک مدل به وجود می آیند.
  Ensemble ها به این صورت کار می کنند که تعداد زیادی طبقه بند ساخته می شود و معمولاً از آن ها رأی گیری می کنیم.
  رأی گیری می تواند با وزن یا بدون وزن باشد.
  #tool.custom_figure(
    image("images/ML/14_04.png"),
    caption: "رویکرد کلی Ensemble Learning",
    inset: 1em,
  )
]

=== Ad Hoc Ensembles
#tool.double_section()[
  #tool.definition()[
    روش های Ad Hoc (بزن و برو):
    به راه حلی می گویند که به طور خاص برای مسأله مشخصی کاربرد دارد و نمی توان به صورت عمومی از آن حتی برای حل مسائل مشابه استفاده کرد.
    Ad Hoc Ensembles به مدل های Ensemble ای می گویند که با تکنیک Ad Hoc ساخته شده اند.
    #v(1.6em)
  ]
][
  #tool.example()[
    درخت تصمیمی ساخته ایم. تست می کنیم که اگر در هر گره آن، یک SVM قرار دهیم عملکردش بهتر می شود یا خیر. اگر بهتر شد همین ساختار را حفظ می کنیم.
    به این ترتیب بدون این که فرمول عمومی دقیق و قابل انطباق با کلی از مسائل را داشته باشیم، می توانیم به این روش، عملکرد موضوع مورد نظر را بهبود بخشیم.
  ]
]

#tool.tip()[
  یکی از دلایل استفاده از Ensemble ها این است که به وسیله آن ها می توانیم با ترکیب تعدادی طبقه بند ساده، مسائل پیچیده را حل کنیم.
]

#tool.example()[
  داده های مربوط به دو کلاس زیر را به دو روش می توان از یکدیگر جدا کرد:
  + به وسیله یک سهمی
  + به وسیله سه خط ساده
  #tool.custom_figure(
    image("images/ML/14_05.png", width: 60%),
    caption: "جدا سازی دو کلاس مختلف به کمک ۳ عدد خط در مقایسه با یک سهمی",
    inset: 1em,
  )
  به طبقه بند اول، طبقه بند Complex یا Strong می گویند.
  به طبقه بند دوم، که ترکیبی از ۳ طبقه بند ساده است، طبقه بند Weak می گویند.
]

#tool.example()[
  داده های مربوط به دو کلاس زیر را به دو روش می توان از یکدیگر جدا کرد:
  + به وسیله الگوریتم SVM
  + به وسیله الگوریتم Perceptron
  بهترین طبقه بند در شکل زیر همان خط وسط است که به وسیله SVM تشکیل می شود.
  الگوریتم Perceptron اما، بسته به نقطه شروعش، خط های متفاوتی تولید می کند.
  ۴ خط داریم که بدترین حالت های ممکن را ایجاد می کنند.
  برای این که خیال مان تا حد زیادی راحت شود که به این ۴ خط برخورد نمی کنیم، مثلاً ۴۰ بار الگوریتم Perceptron را اجرا می کنیم تا ۴۰ خط را تولید کند.
  با رأی گیری از این ۴۰ خط، به احتمال زیاد به دقت بالایی می رسیم.

  #tool.custom_figure(
    image("images/ML/14_06.png", width: 60%),
    caption: "جدا سازی دو کلاس مختلف با SVM و Perceptron",
    inset: 1em,
  )
]

=== روش های ساخت Ensemble
==== Different Data
#tool.definition()[
  در این نوع Ensemble ها، Dataset به تعدادی قسمت تقسیم می شود و هر قسمت به یک Classifier برای آموزش آن داده می شود.
  در این جا دو رویکرد در تقسیم کردن Dataset وجود دارد:
  + تقسیم سطری (Record به Record)
  + تقسیم ستونی (Feature به Feature)
]
===== الگوریتم Bagging
#tool.definition()[
  در این الگوریتم، از Dataset تعدادی Subset با اعضای تصادفی انتخاب می شود و هر یک از مدل های تشکیل دهنده Ensemble با یکی از آن ها آموزش می بیند.
]

===== الگوریتم Random Forest
#tool.example()[
  نمونه ای با ویژگی های زیر داریم:
  $
    "Features" = {x_1, x_2, x_3, dots, x_10}
  $
  در ادامه هر یک از ویژگی ها را با احتمال انتخاب شدن ۵۰٪، برای آموزش مدل، انتخاب می کنیم.
  برای مثال این ویژگی ها در نهایت انتخاب شدند:
  $
    {x_1, x_5, x_10}
  $
  سپس با ویژگی های بالا درخت مان را می سازیم.
  بعد از ساخت درخت، دوباره از مجموعه ویژگی ها، با همان احتمال، ویژگی انتخاب می کنیم و درخت دومی را می سازیم.
  این کار را تا ساخت تعداد درخت مورد نظر تکرار می کنیم.
  مثلاً ۱۰۰۰ عدد.
  هنگام تست مدل، نمونه جدید با رأی گیری از درخت هایی که ساخته شدند، کلاس بندی می شود.
]

===== الگوریتم Boosting
#tool.example()[
  Dataset ای به شکل زیر داریم.
  احتمال انتخاب شدن هر یک از نمونه ها در ستون دوم نوشته شده است.
  به روش Random Forest تعدادی از نمونه ها را انتخاب می کنیم و با آن ها یک درخت تصمیم می سازیم.
  به کمک این درخت، کل Train Data را Label می زنیم و بررسی می کنیم که کدام داده ها را درست و کدام شان را اشتباه دسته بندی کرده است.
  این موارد در ستون Error مشخص شده اند.
  اگر طبقه بندی درست صورت گرفته باشد، مقدار ۰ و در غیر این صورت مقدار ۱ در این ستون قرار می گیرد.
  سپس دوباره تعدادی از نمونه ها را انتخاب می کنیم تا درخت بعدی را بسازیم.
  اما برخلاف الگوریتم Bagging، در این جا مجموعه نمونه هایی که از مجموعه اصلی نمونه ها می خواهیم انتخاب کنیم، لزوماً احتمال یکسانی برای انتخاب شدن ندارند.
  به این صورت که نمونه هایی که به اشتباه دسته بندی شدند (Error = 1)، شانس بیشتری برای انتخاب شدن برای ساخت درخت جدید خواهند داشت.
  به این صورت که شانس آن هایی که در مرحله قبل به اشتباه دسته بندی شدند را برای این مرحله مثلاً ۲ برابر می کنیم.
  اگر احتمال های جدید را با هم جمع کنیم، متوجه می شویم که مجموع آن ها ۱/۳ می شود که از ۱ بیشتر است.
  برای حل این مشکل آن ها را نرمال می کنیم.
  به این صورت که هر کدام از احتمال ها را تقسیم بر ۱/۳ می کنیم.
  به این ترتیب نمونه های جدید برای آموزش درخت انتخاب می شوند و این مراحل را برای درخت های جدید تکرار می کنیم (PBC = Probability of Being Chosen).
  #tool.custom_figure(
    caption: "نمونه های یک جمعیت و احتمال انتخاب شدن آن ها",
    kind: table,
    inset: 1em,
  )[
    #table(
      columns: 5,
      inset: 1em,
      stroke: black,
      align: center + horizon,
      "Instance", "PBC\n#1", "Error\n#1", "PBC\n#2", "Normalized PBC\n#2",
      "A", $display(1 / 10)$, $0$, $display(1 / 10)$, $display(1 / 13)$,
      "B", $display(1 / 10)$, $0$, $display(1 / 10)$, $display(1 / 13)$,
      "C", $display(1 / 10)$, $1$, $display(2 / 10)$, $display(2 / 13)$,
      "D", $display(1 / 10)$, $1$, $display(2 / 10)$, $display(2 / 13)$,
      "E", $display(1 / 10)$, $0$, $display(1 / 10)$, $display(1 / 13)$,
      "F", $display(1 / 10)$, $0$, $display(1 / 10)$, $display(1 / 13)$,
      "G", $display(1 / 10)$, $0$, $display(1 / 10)$, $display(1 / 13)$,
      "H", $display(1 / 10)$, $0$, $display(1 / 10)$, $display(1 / 13)$,
      "I", $display(1 / 10)$, $1$, $display(2 / 10)$, $display(2 / 13)$,
      "J", $display(1 / 10)$, $0$, $display(1 / 10)$, $display(1 / 13)$,
    )
  ]
]

#tool.tip()[
  از نظر این که احتمال انتخاب شدن مجدد نمونه ها چگونه تعیین می شود، الگوریتم های Boosting متفاوتی وجود دارند.
  از جمله #box[AdaBoost]، GentleBoost و XGBoost.
]

==== Different Architecture (Model)
#tool.definition()[
  این نوع Ensemble ها، از تعدادی Classifier مختلف تشکیل می شوند.
  برای مثال، Ensemble ای که از یک درخت تصمیم، شبکه عصبی و SVM، که هر یک به طور مستقل از روی کل داده های آموزشی ساخته شده اند، تشکیل شده است.
]
==== Different Training Parameters
#tool.definition()[
  این نوع Ensemble ها، از مدل های یکسان اما با پارامتر های متفاوت تشکیل می شوند.
]

= جلسه پانزدهم
== Unsupervised Learning
#tool.simple_context()[
  از این جلسه تا تعدادی جلسه دیگر، الگوریتم های یادگیری بدون نظارت زیر درس داده خواهند شد:
  #grid(columns: (1fr, 1.5fr))[
    1. Clustering
    3. Association Analysis
  ][
    2. Distribution Estimation
    4. Anomaly Detection (Data Cleaning)
  ]
]

=== Clustering
#tool.question()[
  تعدادی نمونه در دو کلاس به صورت زیر داریم. آن ها را طبقه بندی کنید.
  #tool.custom_figure(
    image("images/ML/15_01.png", width: 85%),
    caption: [نمونه های مربوط به دو کلاس $C_1$ و $C_2$],
    inset: 1em,
  )
]
#tool.true_answer()[
  با طبقه بند های درخت و شبکه عصبی نیز می توان این سؤال را حل کرد اما برای مسائلی که فضای نمونه پیچیده ای دارند، می توان از رویکرد Ensemble استفاده کرد.
  Ensemble را به دو روش زیر می توان ساخت:
  + Input Space Partitioning:
    در این روش، فضای نمونه را بدون توجه به توزیع داده ها، به چند بخش در محور مختصات تقسیم می کنیم.
    سپس برای هر یک از این بخش ها یک طبقه بند می سازیم.
    بدی این روش در مقایسه با روش Clustering این است که برای ناحیه هایی که خالی هستند نیز باید تصمیم گیری کنیم.
    #tool.custom_figure(
      image("images/ML/15_02.png", width: 92%),
      caption: "ساخت Ensemble با تکنیک Input Space Partitioning",
      inset: 1em,
    )
  + Clustering (خوشه بندی):
    در این روش، محل تجمع داده ها را تشخیص می دهیم.
    داده هایی که بهم نزدیک اند در یک خوشه دسته بندی می شوند.
    سپس برای هر خوشه یک مدل جدید یاد می گیریم.
    مانند وقتی که از سمت و ارتفاع بالا به یک شهر نگاه می کنیم، محله های مختلف آن را می توانیم ببینیم.
    #tool.custom_figure(
      image("images/ML/15_03.png", width: 92%),
      caption: "ساخت Ensemble با تکنیک Clustering",
      inset: 1em,
    )
]

#tool.tip()[
  الگوریتم های خوشه بندی و پیدا کردن محل تجمع، معمولاً الگوریتم هایی Semi-automatic (نیمه خودکار) هستند.
  به این معنا که خود ML Engineer باید اطلاعاتی را به الگوریتم بدهد تا الگوریتم محل دقیق خوشه ها را مشخص کند.
]

==== K-Means
#tool.definition()[
  الگوریتم K-Means یک الگوریتم خوشه بندی است و به این شکل اجرا می شود:
  + Random Assignment:
    الگوریتم K-Means، ابتدا مراکز محل های تجمع اولیه را به صورت تصادفی انتخاب می کند.
    سپس هر یک از داده ها به مرکزی که به آن نزدیک تر است، اختصاص داده می شود.

  + اصلاح مراکز خوشه ها:
    در این مرحله، مختصات مراکز خوشه ها اصلاح می شود.
    به این صورت که میانگین هر خوشه فعلی حساب می شود و سپس داده ها در خوشه ای قرار می گیرند که به میانگین آن خوشه نزدیک ترند.

  + تکرار گام ۲ تا رسیدن به همگرایی و یا رسیدن به تعداد Iteration مورد نظر.
]

#tool.example()[
  می خواهیم داده های زیر را به وسیله الگوریتم K-Means خوشه بندی کنیم:
  $
    A = {-1, 0, 0, 1, 2, 7, 5, 8, 9, 5, 6}
  $
  این الگوریتم دو ورودی می گیرد:
  داده ها و اطلاعات کمکی (تعداد خوشه ها).
  ML Engineer حدس می زند که این داده ها مربوط به ۲ خوشه هستند و تعداد خوشه ها را به الگوریتم می دهد.
  یکی از راه های حدس زدن تعداد خوشه ها، رسم داده ها بر روی نمودار است.
  #tool.custom_figure(
    image("images/ML/15_04.png"),
    caption: "با توجه به نمودار داده ها می توان دریافت که داده ها در نزدیکی ۰ و ۶ تجمع پیدا کرده اند.",
    inset: 1em,
  )
  در این مثال فرض کنید شانسی، بدترین انتخاب ممکن انجام می شود.
  $
    \
    a_1 &= 8 &&arrow {-1, 0, 0, 1, 2, 5, 5, 6, 7, 8} &&arrow "Mean" = 33 / 10 &&= 3.3
    \
    a_2 &= 9 &&arrow {9} &&arrow "Mean" = 9 / 1 &&= 9
    \ #place(dx: 27.1em, line(length: 100%, stroke: (dash: "densely-dashed"))) \
    a_1 &= 3.3 &&arrow {-1, 0, 0, 1, 2, 5, 5, 6} &&arrow "Mean" = 18 / 8 &&= 2.25
    \
    a_2 &= 9 &&arrow {7, 8, 9} &&arrow "Mean" = 24 / 3 &&= 8
    \ #place(dx: 27.1em, line(length: 100%, stroke: (dash: "densely-dashed"))) \
    a_1 &= 2.25 &&arrow {-1, 0, 0, 1, 2, 5, 5} &&arrow "Mean" = 12 / 7 &&tilde.eq 1.7
    \
    a_2 &= 8 &&arrow {6, 7, 8, 9} &&arrow "Mean" = 30 / 4 &&= 7.5
    \ #place(dx: 27.1em, line(length: 100%, stroke: (dash: "densely-dashed"))) \
    a_1 &= 1.7 &&arrow #text(dir: ltr, fill: red_color)[{-1, 0, 0, 1, 2}] &&arrow "Mean" = 2 / 5 &&= #text(dir: ltr, fill: red_color)[0.4]
    \
    a_2 &= 7.5 &&arrow #text(dir: ltr, fill: blue_color)[{5, 5, 6, 7, 8, 9}] &&arrow "Mean" = 40 / 6 &&tilde.eq #text(dir: ltr, fill: blue_color)[6.6]
    \ #place(dx: 27.1em, line(length: 100%, stroke: (dash: "densely-dashed"))) \
    a_1 &= 0.4 &&arrow #text(dir: ltr, fill: red_color)[{-1, 0, 0, 1, 2}] &&arrow "Mean" = 2 / 5 &&= #text(dir: ltr, fill: red_color)[0.4]
    \
    a_2 &= 6.6 &&arrow #text(dir: ltr, fill: blue_color)[{5, 5, 6, 7, 8, 9}] &&arrow "Mean" = 40 / 6 &&tilde.eq #text(dir: ltr, fill: blue_color)[6.6]
  $
  با توجه به این که دو بخش آخر معادله های بالا یکسان اند (به لحاظ دسته بندی داده ها و یا میانگین آن ها)، پس الگوریتم به همگرایی رسیده است و داده ها را در ۲ خوشه تقسیم بندی کرده است.
]

#tool.tip()[
  K-Means الگوریتمی Iterative و Non-deterministic است.
]

=== Distribution Estimation
#tool.definition()[
  Distribution Estimation برای تخمین توزیع داده ها استفاده می شود.
  به این صورت که فرض می کنیم تک تک داده هایی که داریم هر یک می توانند مرکز یک توزیع نرمال باشند.
  نحوه عملکرد Distribution Estimation به این صورت است که به تعداد داده ها توزیع نرمال با مرکزیت هر یک از آن ها می سازیم و در نهایت این توزیع ها را با یک دیگر جمع می کنیم و توزیع نهایی را به دست می آوریم.
]

#tool.example()[
  Distribution Estimation در حل مسائلی که با K-Means حل می شوند، با دادن بینش به ما کمک می کند.
  برای حل مثال قبل به این روش، فرض می کنیم که داده ها از توزیع نرمالی به دست آمده اند.
  ابتدا تابع توزیع تک تک داده ها را به شکل زیر بر روی نمودار رسم می کنیم که میانگین هر یک از آن ها برابر با مقدار آن داده است ($-1, 0, dots, 9$).
  در ادامه نمودار جدیدی که حاصل جمع نمودار تک تک توابع است می کشیم.
  به این صورت که قسمت هایی که بر روی یک دیگر افتاده اند، با هم جمع می شوند:
  #tool.custom_figure(
    image("images/ML/15_05.jpg"),
    caption: "نمودار های توزیع داده ها و نمودار حاصل جمع آن ها",
    inset: 1em,
  )
  با نگاه به نمودار حاصل جمع، ML Engineer متوجه می شود که دو قله بزرگ، یکی در نقطه ۰ و دیگری در نقطه ۵، در آن وجود دارد.
  با توجه به این موضوع، بهتر است مرکز اولیه خوشه ها در این نقاط باشند.

  به این ترتیب الگوریتم K-Means به صورت زیر شروع می شود:
  $
    a_1 &= 0 &&arrow #text(dir: ltr, fill: red_color)[{-1, 0, 0, 1, 2}] &&arrow "Mean" = 2 / 5 &&tilde.eq #text(dir: ltr, fill: red_color)[0.4]
    \
    a_2 &= 5 &&arrow #text(dir: ltr, fill: blue_color)[{5, 5, 6, 7, 8, 9}] &&arrow "Mean" = 40 / 6 &&tilde.eq #text(dir: ltr, fill: blue_color)[6.6]
  $
  و چون از مثال قبل می دانیم خوشه های بالا جواب نهایی هستند، Iteration دوم که از آن متوجه همگرایی می شویم، دیگر در این مثال آورده نشده است.

  در این روش تنها با ۲ بار تکرار به جواب نهایی رسیدیم.
]

#tool.tip()[
  الگوریتم K-Means به انتخاب مراکز اولیه حساس است.
]

#tool.tip()[
  در الگوریتم K-Means، داده ها همیشه این گونه نیستند که با یک بینش بتوان مقدار مناسب برای مراکز اولیه آن ها را حدس زد.
  در این حالت، برای مثال اگر قرار است دو مرکز را انتخاب کنیم، عدد اول را به صورت تصادفی انتخاب می کنیم.
  سپس برای انتخاب عدد دوم، دورترین عدد نسبت به آن را انتخاب می کنیم.
  این کار باعث می شود که الگوریتم سریع تر به همگرایی برسد.
]

#tool.example()[
  داده هایی به شکل زیر داریم و می خواهیم آن ها را دسته بندی کنیم:
  #tool.custom_figure(
    image("images/ML/15_06.png", width: 80%),
    caption: "داده هایی متعلق به ۳ کلاس مختلف",
    inset: 1em,
  )
  با مشاهده نمودار بالا به این نتیجه می رسیم که داده ها در ۳ گروه قرار گرفته اند.
  بنابراین ۳ مرکز را انتخاب می کنیم.
  سپس به کمک الگوریتم تقسیم بر اساس عمود منصف، صفحه را به ۳ خوشه، افراز می کنیم.
  هر نمونه متعلق به خوشه ای خواهد بود که به آن نزدیک تر است.
  فرض کنید ۳ مرکزی که انتخاب می کنیم، مراکز بدی هستند:
  #tool.custom_figure(
    image("images/ML/15_07.png", width: 80%),
    caption: "Iteration اول K-Means",
    inset: 1em,
  )
  در ادامه باید مراکز خوشه ها را با توجه به اعضای شان، به دست آوریم.
  یعنی نقطه مرکزی بین نمونه های هر خوشه را حساب کنیم.
  سپس دوباره به کمک الگوریتم تقسیم بر اساس عمود منصف، صفحه را به ۳ بخش تقسیم می کنیم و داده ها را در خوشه های جدید دسته بندی می کنیم:
  #tool.custom_figure(
    image("images/ML/15_08.png", width: 80%),
    caption: "Iteration دوم K-Means",
    inset: 1em,
  )
]

=== ایراد K-Means
#tool.tip()[
  K-Means همیشه برای خوشه بندی مناسب نیست.
]

#tool.example()[
  K-Means در مواردی مانند حالت زیر به مشکل می خورد. چرا که مرز بین خوشه ها را تنها با رسم عمود منصف فاصله مرکز خوشه ها، محاسبه می کند:
  #tool.custom_figure(
    image("images/ML/15_09.png", width: 45%),
    caption: "خوشه بندی اشتباه توسط الگوریتم K-Means",
    inset: 1em,
  )

  و یا در حالتی که دو خوشه به شکل زیر داریم:
  #tool.custom_figure(
    image("images/ML/15_10.png", width: 55%),
    caption: "خوشه بندی اشتباه توسط الگوریتم K-Means",
    inset: 1em,
  )
]

==== Silhouette and Clustering Score
#tool.definition()[
  فرض کنید ۳ خوشه به شکل زیر داریم.
  نمونه ای به نام $x_i$ را درون یکی از خوشه ها در نظر می گیریم.
  اگر به میانگین فاصله این نمونه با نمونه های هم خوشه اش، $a$ و به میانگین فاصله این نمونه با نمونه های نزدیک ترین خوشه دیگر، $b$ بگوییم:
  #tool.custom_figure(
    image("images/ML/15_11.png", width: 95%),
    caption: [نمونه $x_i$ به همراه میانگین فاصله های $a$ و $b$],
    inset: 1em,
  )
  آن گاه کیفیت خوشه بندی تک نمونه $x_i$، که به آن Silhouette Score مربوط به $x_i$ می گوییم، به صورت زیر تعریف می شود:
  $
    "Silhouette Score for" x_i arrow s_i = (b - a) / max(a, b)
  $
  که در آن دوست داریم $b$ بزرگ تر و $a$ کوچک تر باشد.

  برای ارزیابی خوشه بندی، معیار Clustering Score به صورت زیر تعریف می شود:
  $
    "Clustering Score" = (sum_i s_i) / N
  $
]

#tool.double_section()[
  #tool.tip()[
    Silhouette Score نمونه هایی که خوب خوشه بندی شده اند بزرگ، و نمونه هایی که پرت اند، کوچک است.
  ]
][
  #tool.tip()[
    الگوریتم K-Means به Noise حساس است.
    #v(1.6em)
  ]
]

==== تشخیص Noise در K-Means
#tool.definition()[
  یکی از روش های تشخیص Noise در الگوریتم K-Means، این است که Range یا محدوده ای از Silhouette Score را به عنوان محدوده Valid و محدوده مکمل آن را به عنوان محدوده Invalid در نظر می گیریم.

  کد این الگوریتم تشخیص Noise، به صورت زیر است:
  #tool.custom_figure(caption: "کد یک الگوریتم تشخیص Noise", kind: raw, inset: 1em)[
    ```
    // <<<Part 1>>>
    // First Sort all 's_i' in a decreasing order. That is:
    // s_1 >= s_2 >= s_3 >= ... >= s_n
    sort s_1, s_2, ..., s_N
    // Calculate the sum of all 's_i' and assign it to 's'.
    s = sum_of(s_i)
    // Calculate each 's_i' share. Consequently the sum of
    // this set is equal to 1.
    s_1 = (s_1 / s) , s_2 = (s_2 / s), ..., s_N = (s_N / s)

    // <<<Part 2>>>
    t = 0, i = 0
    // Increase 'i' until we reach to the 95% of scores
    while (t < 0.95) {
      i = i + 1
      t = t + s_i
    }
    // Now 'i' refers to the index of the first sample
    // which it's score is in the 5% of the lowest scores.
    // Now we can say that each sample 'x'
    // from index 'i' to 'N', is a NOISE!!!
    noises = x_(i+1), x_(i+2), ..., x_N
    ```
  ]
]

#tool.tip()[
  دقت شود که در الگوریتم تشخیص Noise بالا، نمونه هایی که Score شان جزو ۵٪ کمترین Score ها بود را پیدا و به عنوان Noise تعیین کردیم و نه ۵٪ از نمونه هایی که داریم.
]

#colbreak()
#colbreak()
#align(center + horizon)[
  #block(
    stroke: (thickness: 0.2em, paint: black, dash: "densely-dashed"),
    inset: (top: 0.5em, rest: 1em),
    radius: 1em,
    clip: true,
  )[
    #image("assets/images/work_in_progress.png", width: 10em, height: 10em, fit: "contain")
  ]
]